{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EGG synthesis\n",
    "\n",
    "Model: Transformer might not be necessary, since the input and output are of the same length. A simple feed-forward network might be enough.\n",
    "       1D CNN for freq-based feature, hybrid with LSTM for temporal features.\n",
    "\n",
    "X: (a)raw audio signal, 16kHz, (batch_size, time_frames)\n",
    "   (b)spectrograms, 16kHz, (batch_size, frequency_bins, time_frames)\n",
    "   (c)MFCCs,  16kHz, (batch_size, frequency_bins, time_frames)\n",
    "Y: (a) EGG signal waveform, 16kHz\n",
    "   (b) metrics, 50Hz\n",
    "   (c) Fourier descriptors, 50Hz\n",
    "\n",
    "Loss function: MSE works fine with test, but not others\n",
    "               Cosine similarity works fine with mapping the shape, but not the amplitude\n",
    "\n",
    "Comments:\n",
    "adds band filter to filter out the higher freqs.\n",
    "noise reduction of EGG\n",
    "add checkpoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import models\n",
    "from utils import *\n",
    "import scipy.signal\n",
    "import importlib\n",
    "importlib.reload(models)\n",
    "from models import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "samplerate = 16000\n",
    "num_epochs = 300\n",
    "hidden_size = 256\n",
    "second_hidden_size = 256\n",
    "third_hidden_size = 256\n",
    "learning_rate = 0.001\n",
    "# the f0 range is from 50 to 500 Hz, it should cover the longest f0 in the dataset, so 50Hz=0.02s\n",
    "segment_length_in_seconds = 0.02\n",
    "# noise level\n",
    "segment_length_in_samples = int(segment_length_in_seconds * samplerate)\n",
    "batch_size = 1\n",
    "representation_type = 'Mel'\n",
    "\n",
    "# Parameters for the band-pass filter\n",
    "lowcut = 50.0  # Low frequency cut-off in Hz\n",
    "highcut = 3000.0  # High frequency cut-off in Hz\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data set building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset\n",
    "dataset = VoiceDataset(segment_length_in_samples)\n",
    "# 1.load files, audio and EGG, choose the file type to load\n",
    "wav_data = dataset.load_dataset('F01', samplerate)\n",
    "# 2.consider representation, and segment the data\n",
    "dataset.preprocess(wav_data, denoise=False, preprocess_type = representation_type)\n",
    "# 3.other preprocess\n",
    "# ...\n",
    "\n",
    "train_segments, val_segments, test_segments = dataset.split_data(train_ratio=0.7, val_ratio=0.15)\n",
    "\n",
    "# create the dataloader\n",
    "train_loader = DataLoader(train_segments, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_segments, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_segments, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# check the shape and number of the input, target\n",
    "for i, (input_tensor, target_tensor) in enumerate(train_loader):\n",
    "    print(input_tensor.shape)\n",
    "    print(target_tensor.shape)\n",
    "    print(f\"Total number of batches: {len(train_loader)}\")\n",
    "    print(f\"Total number of samples: {len(train_loader.dataset)}\")\n",
    "    break\n",
    "\n",
    "# # plot the input and target mel spectrogram\n",
    "plt.figure()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(input_tensor[2].numpy(), aspect='auto')\n",
    "plt.title('Input Mel spectrogram')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(target_tensor[2].numpy(), aspect='auto')\n",
    "plt.title('Target Mel spectrogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mel spectrogram\n",
    "class Seq2SeqLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob):\n",
    "        super(Seq2SeqLSTM, self).__init__()\n",
    "        self.encoder = nn.LSTM(input_size, hidden_size, num_layers, batch_first=False)\n",
    "        self.decoder = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=False) \n",
    "        self.fc = nn.Linear(hidden_size, output_size)  # Maps hidden state to output size (Mel frequency bands)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # Maps fc output to decoder input size (1)\n",
    "        self.decoder_input_layer = nn.Linear(output_size, hidden_size)  # Correct the mapping size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input to [seq_len, batch_size, input_size]\n",
    "        x = x.transpose(0, 1)\n",
    "\n",
    "        # Encoding\n",
    "        encoder_outputs, (hidden, cell) = self.encoder(x)\n",
    "\n",
    "        # Prepare the first input to the decoder which will be the last hidden state of the encoder\n",
    "        decoder_input = hidden[-1]  # Take the last layer's hidden state for all batches\n",
    "\n",
    "        # Initialize the decoder hidden state as the last encoder hidden state\n",
    "        decoder_hidden = hidden\n",
    "        decoder_cell = cell\n",
    "\n",
    "        # Decoding\n",
    "        decoder_outputs = []\n",
    "        for t in range(x.size(0)):  # Iterate over time steps\n",
    "            # Decode step by step\n",
    "            decoder_output, (decoder_hidden, decoder_cell) = self.decoder(\n",
    "                decoder_input.unsqueeze(0), (decoder_hidden, decoder_cell))\n",
    "            out = self.fc(self.dropout(decoder_output.squeeze(0)))\n",
    "            decoder_outputs.append(out)\n",
    "            # Transform the output size to match the decoder input size using the decoder input layer\n",
    "            decoder_input = self.decoder_input_layer(out)\n",
    "\n",
    "        # Stack outputs along the sequence dimension\n",
    "        outputs = torch.stack(decoder_outputs, dim=0).transpose(0, 1)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEL spectrogram training\n",
    "model = Seq2SeqLSTM(input_size=n_mels, hidden_size=hidden_size, num_layers=3, output_size=n_mels, dropout_prob=0.2)\n",
    "\n",
    "# Move the model to the appropriate device (e.g., CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "# Early stopping parameters\n",
    "best_val_loss = float('inf')\n",
    "patience = 20\n",
    "patience_counter = 0\n",
    "\n",
    "# Lists for storing metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "lr_rates = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Logging shapes for the first epoch\n",
    "        if epoch == 0 and i == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Batch {i + 1}: Input Shape - {inputs.shape}, Target Shape - {targets.shape}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, targets).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # Learning rate scheduler step and log current LR\n",
    "    scheduler.step(avg_val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    lr_rates.append(current_lr)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Learning Rate: {current_lr}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title(\"Losses\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(lr_rates, label='Learning Rate')\n",
    "plt.title(\"Learning Rate\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"LR\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets).item()\n",
    "        print(f\"Test Loss: {loss:.4f}\")\n",
    "\n",
    "# plot the random predicted wav for visualization\n",
    "plt.figure(figsize=(16, 4))\n",
    "random_index = random.randint(0, len(outputs) - 1)\n",
    "plt.plot(outputs[random_index].cpu().numpy())\n",
    "plt.title('Predicted')\n",
    "plt.show()\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(targets[random_index].cpu().numpy())\n",
    "plt.title('Target')\n",
    "plt.show()\n",
    "\n",
    "# close plt\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'outputs' is your predicted Mel spectrogram in dB with shape [batch_size, n_mels, time_steps]\n",
    "# Convert it back to the linear scale\n",
    "mel_spec_predicted = librosa.db_to_power(outputs[0].cpu().numpy())\n",
    "\n",
    "# Inverse Mel transformation\n",
    "stft_predicted = librosa.feature.inverse.mel_to_stft(mel_spec_predicted)\n",
    "\n",
    "# Apply Griffin-Lim algorithm to reconstruct the phase information\n",
    "waveform_predicted = librosa.griffinlim(stft_predicted)\n",
    "\n",
    "# Plot the predicted waveform for visualization\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(waveform_predicted)\n",
    "plt.title('Predicted Waveform')\n",
    "plt.show()\n",
    "\n",
    "# The same steps would apply to the target if it's also a Mel spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "# predict\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "for inputs, targets in test_loader:\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        test_loss += criterion(outputs, targets).item()\n",
    "test_loss /= len(test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "# turn to original wav\n",
    "outputs = outputs.detach().numpy()\n",
    "targets = targets.detach().numpy()\n",
    "outputs = outputs.reshape(-1)\n",
    "targets = targets.reshape(-1)\n",
    "\n",
    "# draw the waveform\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(outputs[0:300], label='output')\n",
    "plt.plot(targets[0:300], label='target')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearson correlation for target and output\n",
    "from scipy.stats import pearsonr\n",
    "corr, _ = pearsonr(outputs, targets)\n",
    "print('Pearsons correlation: %.3f' % corr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "A2E",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
