{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Conda\\envs\\HiFi\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0, Loss: 0.09333836287260056\n",
      "Epoch 0, Iteration 10, Loss: 0.03941719979047775\n",
      "Epoch 0, Iteration 20, Loss: 0.019642498344182968\n",
      "Epoch 0, Iteration 30, Loss: 0.11357631534337997\n",
      "Epoch 0, Iteration 40, Loss: 0.07542413473129272\n",
      "Epoch 0, Iteration 50, Loss: 0.05155150592327118\n",
      "Epoch 0, Iteration 60, Loss: 0.08039388060569763\n",
      "Epoch 0, Iteration 70, Loss: 0.05904949828982353\n",
      "Epoch 0, Iteration 80, Loss: 0.05293215066194534\n",
      "Epoch 0, Iteration 90, Loss: 0.0347016304731369\n",
      "Epoch 0, Iteration 100, Loss: 0.06848762184381485\n",
      "Epoch 0, Iteration 110, Loss: 0.0261222030967474\n",
      "Epoch 0, Iteration 120, Loss: 0.051893219351768494\n",
      "Epoch 0, Iteration 130, Loss: 0.07656091451644897\n",
      "Epoch 0, Iteration 140, Loss: 0.04726842790842056\n",
      "Epoch 0, Iteration 150, Loss: 0.02082134410738945\n",
      "Epoch 0, Iteration 160, Loss: 0.09959287941455841\n",
      "Epoch 0, Iteration 170, Loss: 0.05152162164449692\n",
      "Epoch 0, Iteration 180, Loss: 0.09237469732761383\n",
      "Epoch 0, Iteration 190, Loss: 0.04784032329916954\n",
      "Epoch 0, Iteration 200, Loss: 0.040918413549661636\n",
      "Epoch 0, Iteration 210, Loss: 0.027003780007362366\n",
      "Epoch 0, Iteration 220, Loss: 0.0478593073785305\n",
      "Epoch 0, Iteration 230, Loss: 0.03832640126347542\n",
      "Epoch 0, Iteration 240, Loss: 0.04219018667936325\n",
      "Epoch 0, Iteration 250, Loss: 0.0430767685174942\n",
      "Epoch 0, Iteration 260, Loss: 0.04141722247004509\n",
      "Epoch 0, Iteration 270, Loss: 0.04193321242928505\n",
      "Epoch 0, Iteration 280, Loss: 0.04723969101905823\n",
      "Epoch 0, Iteration 290, Loss: 0.047836851328611374\n",
      "Epoch 0, Iteration 300, Loss: 0.05466163903474808\n",
      "Epoch 0, Iteration 310, Loss: 0.052864670753479004\n",
      "Epoch 0, Iteration 320, Loss: 0.026199931278824806\n",
      "Epoch 0, Iteration 330, Loss: 0.033075399696826935\n",
      "Epoch 0, Iteration 340, Loss: 0.07214284688234329\n",
      "Epoch 0, Iteration 350, Loss: 0.024989889934659004\n",
      "Epoch 0, Iteration 360, Loss: 0.024991396814584732\n",
      "Epoch 0, Iteration 370, Loss: 0.04181157797574997\n",
      "Epoch 0, Iteration 380, Loss: 0.04549437016248703\n",
      "Epoch 0, Iteration 390, Loss: 0.03806475177407265\n",
      "Epoch 0, Iteration 400, Loss: 0.03974373638629913\n",
      "Epoch 0, Iteration 410, Loss: 0.049247004091739655\n",
      "Epoch 0, Iteration 420, Loss: 0.042513638734817505\n",
      "Epoch 0, Iteration 430, Loss: 0.023379897698760033\n",
      "Epoch 0, Iteration 440, Loss: 0.03221504017710686\n",
      "Epoch 0, Iteration 450, Loss: 0.040865037590265274\n",
      "Epoch 0, Iteration 460, Loss: 0.05444274842739105\n",
      "Epoch 0, Iteration 470, Loss: 0.04071137309074402\n",
      "Epoch 0, Iteration 480, Loss: 0.021281812340021133\n",
      "Epoch 0, Iteration 490, Loss: 0.04038441181182861\n",
      "Epoch 0, Iteration 500, Loss: 0.05392405763268471\n",
      "Epoch 0, Iteration 510, Loss: 0.027428606525063515\n",
      "Epoch 0, Iteration 520, Loss: 0.04380091279745102\n",
      "Epoch 0, Iteration 530, Loss: 0.046663396060466766\n",
      "Epoch 0, Iteration 540, Loss: 0.08527103066444397\n",
      "Epoch 0, Iteration 550, Loss: 0.044700175523757935\n",
      "Epoch 0, Iteration 560, Loss: 0.03632579371333122\n",
      "Epoch 0, Iteration 570, Loss: 0.04703858494758606\n",
      "Epoch 0, Iteration 580, Loss: 0.03362123295664787\n",
      "Epoch 0, Iteration 590, Loss: 0.04826009273529053\n",
      "Epoch 0, Iteration 600, Loss: 0.05019020661711693\n",
      "Epoch 0, Iteration 610, Loss: 0.054778192192316055\n",
      "Epoch 0, Iteration 620, Loss: 0.054372843354940414\n",
      "Epoch 0, Iteration 630, Loss: 0.08234865963459015\n",
      "Epoch 0, Iteration 640, Loss: 0.03853993862867355\n",
      "Epoch 0, Iteration 650, Loss: 0.0761970803141594\n",
      "Epoch 0, Iteration 660, Loss: 0.06493846327066422\n",
      "Epoch 0, Iteration 670, Loss: 0.04343988373875618\n",
      "Epoch 0, Iteration 680, Loss: 0.05233580619096756\n",
      "Epoch 0, Iteration 690, Loss: 0.026492983102798462\n",
      "Epoch 0, Iteration 700, Loss: 0.038627732545137405\n",
      "Epoch 0, Iteration 710, Loss: 0.04101070016622543\n",
      "Epoch 0, Iteration 720, Loss: 0.07075424492359161\n",
      "Epoch 0, Iteration 730, Loss: 0.026266643777489662\n",
      "Epoch 0, Validation Loss: 0.044058682680453945\n",
      "Validation loss decreased (inf --> 0.044059). Saving model...\n",
      "Epoch 1, Iteration 0, Loss: 0.0665271133184433\n",
      "Epoch 1, Iteration 10, Loss: 0.042979490011930466\n",
      "Epoch 1, Iteration 20, Loss: 0.03740306571125984\n",
      "Epoch 1, Iteration 30, Loss: 0.058855969458818436\n",
      "Epoch 1, Iteration 40, Loss: 0.08007512986660004\n",
      "Epoch 1, Iteration 50, Loss: 0.06077175214886665\n",
      "Epoch 1, Iteration 60, Loss: 0.0734153613448143\n",
      "Epoch 1, Iteration 70, Loss: 0.04053778201341629\n",
      "Epoch 1, Iteration 80, Loss: 0.0780075192451477\n",
      "Epoch 1, Iteration 90, Loss: 0.02412966452538967\n",
      "Epoch 1, Iteration 100, Loss: 0.04120331630110741\n",
      "Epoch 1, Iteration 110, Loss: 0.05875939875841141\n",
      "Epoch 1, Iteration 120, Loss: 0.04708979278802872\n",
      "Epoch 1, Iteration 130, Loss: 0.06452770531177521\n",
      "Epoch 1, Iteration 140, Loss: 0.11438565701246262\n",
      "Epoch 1, Iteration 150, Loss: 0.0665489137172699\n",
      "Epoch 1, Iteration 160, Loss: 0.07813849300146103\n",
      "Epoch 1, Iteration 170, Loss: 0.022937124595046043\n",
      "Epoch 1, Iteration 180, Loss: 0.0795677974820137\n",
      "Epoch 1, Iteration 190, Loss: 0.08038691431283951\n",
      "Epoch 1, Iteration 200, Loss: 0.040121614933013916\n",
      "Epoch 1, Iteration 210, Loss: 0.06442872434854507\n",
      "Epoch 1, Iteration 220, Loss: 0.04891267046332359\n",
      "Epoch 1, Iteration 230, Loss: 0.04961501434445381\n",
      "Epoch 1, Iteration 240, Loss: 0.03760416805744171\n",
      "Epoch 1, Iteration 250, Loss: 0.0507495291531086\n",
      "Epoch 1, Iteration 260, Loss: 0.049301840364933014\n",
      "Epoch 1, Iteration 270, Loss: 0.03730068728327751\n",
      "Epoch 1, Iteration 280, Loss: 0.056694742292165756\n",
      "Epoch 1, Iteration 290, Loss: 0.07480808347463608\n",
      "Epoch 1, Iteration 300, Loss: 0.0791662186384201\n",
      "Epoch 1, Iteration 310, Loss: 0.04112301766872406\n",
      "Epoch 1, Iteration 320, Loss: 0.034119896590709686\n",
      "Epoch 1, Iteration 330, Loss: 0.055351145565509796\n",
      "Epoch 1, Iteration 340, Loss: 0.0440039187669754\n",
      "Epoch 1, Iteration 350, Loss: 0.024165870621800423\n",
      "Epoch 1, Iteration 360, Loss: 0.02520328387618065\n",
      "Epoch 1, Iteration 370, Loss: 0.03125317394733429\n",
      "Epoch 1, Iteration 380, Loss: 0.072535440325737\n",
      "Epoch 1, Iteration 390, Loss: 0.05173376947641373\n",
      "Epoch 1, Iteration 400, Loss: 0.030498463660478592\n",
      "Epoch 1, Iteration 410, Loss: 0.05422721430659294\n",
      "Epoch 1, Iteration 420, Loss: 0.06264130026102066\n",
      "Epoch 1, Iteration 430, Loss: 0.027670659124851227\n",
      "Epoch 1, Iteration 440, Loss: 0.07430560886859894\n",
      "Epoch 1, Iteration 450, Loss: 0.04881144315004349\n",
      "Epoch 1, Iteration 460, Loss: 0.04380248114466667\n",
      "Epoch 1, Iteration 470, Loss: 0.044336624443531036\n",
      "Epoch 1, Iteration 480, Loss: 0.11260677129030228\n",
      "Epoch 1, Iteration 490, Loss: 0.0923953428864479\n",
      "Epoch 1, Iteration 500, Loss: 0.06298220902681351\n",
      "Epoch 1, Iteration 510, Loss: 0.037200335413217545\n",
      "Epoch 1, Iteration 520, Loss: 0.027970122173428535\n",
      "Epoch 1, Iteration 530, Loss: 0.03558068722486496\n",
      "Epoch 1, Iteration 540, Loss: 0.038060810416936874\n",
      "Epoch 1, Iteration 550, Loss: 0.029790803790092468\n",
      "Epoch 1, Iteration 560, Loss: 0.03391058370471001\n",
      "Epoch 1, Iteration 570, Loss: 0.08391083031892776\n",
      "Epoch 1, Iteration 580, Loss: 0.03525729849934578\n",
      "Epoch 1, Iteration 590, Loss: 0.02612033300101757\n",
      "Epoch 1, Iteration 600, Loss: 0.038648590445518494\n",
      "Epoch 1, Iteration 610, Loss: 0.06536542624235153\n",
      "Epoch 1, Iteration 620, Loss: 0.026650285348296165\n",
      "Epoch 1, Iteration 630, Loss: 0.06433456391096115\n",
      "Epoch 1, Iteration 640, Loss: 0.02185428887605667\n",
      "Epoch 1, Iteration 650, Loss: 0.049313388764858246\n",
      "Epoch 1, Iteration 660, Loss: 0.08428030461072922\n",
      "Epoch 1, Iteration 670, Loss: 0.031609807163476944\n",
      "Epoch 1, Iteration 680, Loss: 0.04337635263800621\n",
      "Epoch 1, Iteration 690, Loss: 0.05736264958977699\n",
      "Epoch 1, Iteration 700, Loss: 0.03647122532129288\n",
      "Epoch 1, Iteration 710, Loss: 0.041161395609378815\n",
      "Epoch 1, Iteration 720, Loss: 0.048169538378715515\n",
      "Epoch 1, Iteration 730, Loss: 0.05100136622786522\n",
      "Epoch 1, Validation Loss: 0.04377392640985225\n",
      "Validation loss decreased (0.044059 --> 0.043774). Saving model...\n",
      "Epoch 2, Iteration 0, Loss: 0.05497872829437256\n",
      "Epoch 2, Iteration 10, Loss: 0.03205066919326782\n",
      "Epoch 2, Iteration 20, Loss: 0.04097209498286247\n",
      "Epoch 2, Iteration 30, Loss: 0.034937381744384766\n",
      "Epoch 2, Iteration 40, Loss: 0.07819060236215591\n",
      "Epoch 2, Iteration 50, Loss: 0.029366808012127876\n",
      "Epoch 2, Iteration 60, Loss: 0.024982381612062454\n",
      "Epoch 2, Iteration 70, Loss: 0.050510358065366745\n",
      "Epoch 2, Iteration 80, Loss: 0.05988968536257744\n",
      "Epoch 2, Iteration 90, Loss: 0.024441592395305634\n",
      "Epoch 2, Iteration 100, Loss: 0.0485941581428051\n",
      "Epoch 2, Iteration 110, Loss: 0.06392883509397507\n",
      "Epoch 2, Iteration 120, Loss: 0.023863056674599648\n",
      "Epoch 2, Iteration 130, Loss: 0.07304151356220245\n",
      "Epoch 2, Iteration 140, Loss: 0.04283160716295242\n",
      "Epoch 2, Iteration 150, Loss: 0.05188163369894028\n",
      "Epoch 2, Iteration 160, Loss: 0.05377891659736633\n",
      "Epoch 2, Iteration 170, Loss: 0.0611080676317215\n",
      "Epoch 2, Iteration 180, Loss: 0.029801735654473305\n",
      "Epoch 2, Iteration 190, Loss: 0.045422621071338654\n",
      "Epoch 2, Iteration 200, Loss: 0.03233550861477852\n",
      "Epoch 2, Iteration 210, Loss: 0.06641007214784622\n",
      "Epoch 2, Iteration 220, Loss: 0.05884932726621628\n",
      "Epoch 2, Iteration 230, Loss: 0.0869714617729187\n",
      "Epoch 2, Iteration 240, Loss: 0.028286106884479523\n",
      "Epoch 2, Iteration 250, Loss: 0.028542086482048035\n",
      "Epoch 2, Iteration 260, Loss: 0.03311733156442642\n",
      "Epoch 2, Iteration 270, Loss: 0.030916890129446983\n",
      "Epoch 2, Iteration 280, Loss: 0.060715146362781525\n",
      "Epoch 2, Iteration 290, Loss: 0.04888942092657089\n",
      "Epoch 2, Iteration 300, Loss: 0.033673569560050964\n",
      "Epoch 2, Iteration 310, Loss: 0.04095487669110298\n",
      "Epoch 2, Iteration 320, Loss: 0.04053601622581482\n",
      "Epoch 2, Iteration 330, Loss: 0.06306501477956772\n",
      "Epoch 2, Iteration 340, Loss: 0.04469667747616768\n",
      "Epoch 2, Iteration 350, Loss: 0.07647736370563507\n",
      "Epoch 2, Iteration 360, Loss: 0.01799243688583374\n",
      "Epoch 2, Iteration 370, Loss: 0.0390368290245533\n",
      "Epoch 2, Iteration 380, Loss: 0.055129777640104294\n",
      "Epoch 2, Iteration 390, Loss: 0.04303827881813049\n",
      "Epoch 2, Iteration 400, Loss: 0.0748264491558075\n",
      "Epoch 2, Iteration 410, Loss: 0.03010299988090992\n",
      "Epoch 2, Iteration 420, Loss: 0.04568976163864136\n",
      "Epoch 2, Iteration 430, Loss: 0.05969426780939102\n",
      "Epoch 2, Iteration 440, Loss: 0.03856887295842171\n",
      "Epoch 2, Iteration 450, Loss: 0.015934627503156662\n",
      "Epoch 2, Iteration 460, Loss: 0.07129783928394318\n",
      "Epoch 2, Iteration 470, Loss: 0.0394345223903656\n",
      "Epoch 2, Iteration 480, Loss: 0.027803411707282066\n",
      "Epoch 2, Iteration 490, Loss: 0.052290238440036774\n",
      "Epoch 2, Iteration 500, Loss: 0.03937210515141487\n",
      "Epoch 2, Iteration 510, Loss: 0.041257865726947784\n",
      "Epoch 2, Iteration 520, Loss: 0.08402996510267258\n",
      "Epoch 2, Iteration 530, Loss: 0.05838770419359207\n",
      "Epoch 2, Iteration 540, Loss: 0.05263277515769005\n",
      "Epoch 2, Iteration 550, Loss: 0.022461047396063805\n",
      "Epoch 2, Iteration 560, Loss: 0.0554635189473629\n",
      "Epoch 2, Iteration 570, Loss: 0.051547955721616745\n",
      "Epoch 2, Iteration 580, Loss: 0.03995310515165329\n",
      "Epoch 2, Iteration 590, Loss: 0.04434531182050705\n",
      "Epoch 2, Iteration 600, Loss: 0.0275849811732769\n",
      "Epoch 2, Iteration 610, Loss: 0.0212139543145895\n",
      "Epoch 2, Iteration 620, Loss: 0.03978506848216057\n",
      "Epoch 2, Iteration 630, Loss: 0.0738639235496521\n",
      "Epoch 2, Iteration 640, Loss: 0.04556746035814285\n",
      "Epoch 2, Iteration 650, Loss: 0.08886023610830307\n",
      "Epoch 2, Iteration 660, Loss: 0.0483999066054821\n",
      "Epoch 2, Iteration 670, Loss: 0.06654727458953857\n",
      "Epoch 2, Iteration 680, Loss: 0.01854480430483818\n",
      "Epoch 2, Iteration 690, Loss: 0.05823223665356636\n",
      "Epoch 2, Iteration 700, Loss: 0.04572156071662903\n",
      "Epoch 2, Iteration 710, Loss: 0.04102194681763649\n",
      "Epoch 2, Iteration 720, Loss: 0.05005939304828644\n",
      "Epoch 2, Iteration 730, Loss: 0.04025115445256233\n",
      "Epoch 2, Validation Loss: 0.043671158213249364\n",
      "Validation loss decreased (0.043774 --> 0.043671). Saving model...\n",
      "Epoch 3, Iteration 0, Loss: 0.03754310682415962\n",
      "Epoch 3, Iteration 10, Loss: 0.11849098652601242\n",
      "Epoch 3, Iteration 20, Loss: 0.03196222335100174\n",
      "Epoch 3, Iteration 30, Loss: 0.031212853267788887\n",
      "Epoch 3, Iteration 40, Loss: 0.019969066604971886\n",
      "Epoch 3, Iteration 50, Loss: 0.03953840956091881\n",
      "Epoch 3, Iteration 60, Loss: 0.02163870632648468\n",
      "Epoch 3, Iteration 70, Loss: 0.030754778534173965\n",
      "Epoch 3, Iteration 80, Loss: 0.052818700671195984\n",
      "Epoch 3, Iteration 90, Loss: 0.03706343472003937\n",
      "Epoch 3, Iteration 100, Loss: 0.02363881655037403\n",
      "Epoch 3, Iteration 110, Loss: 0.025571981444954872\n",
      "Epoch 3, Iteration 120, Loss: 0.09207471460103989\n",
      "Epoch 3, Iteration 130, Loss: 0.077675461769104\n",
      "Epoch 3, Iteration 140, Loss: 0.0505126528441906\n",
      "Epoch 3, Iteration 150, Loss: 0.02912641502916813\n",
      "Epoch 3, Iteration 160, Loss: 0.0183181781321764\n",
      "Epoch 3, Iteration 170, Loss: 0.02884344384074211\n",
      "Epoch 3, Iteration 180, Loss: 0.081121064722538\n",
      "Epoch 3, Iteration 190, Loss: 0.04709131643176079\n",
      "Epoch 3, Iteration 200, Loss: 0.03836745768785477\n",
      "Epoch 3, Iteration 210, Loss: 0.03372909873723984\n",
      "Epoch 3, Iteration 220, Loss: 0.030200591310858727\n",
      "Epoch 3, Iteration 230, Loss: 0.047997601330280304\n",
      "Epoch 3, Iteration 240, Loss: 0.026033110916614532\n",
      "Epoch 3, Iteration 250, Loss: 0.02083120308816433\n",
      "Epoch 3, Iteration 260, Loss: 0.03876794874668121\n",
      "Epoch 3, Iteration 270, Loss: 0.03390876203775406\n",
      "Epoch 3, Iteration 280, Loss: 0.05243127420544624\n",
      "Epoch 3, Iteration 290, Loss: 0.052786413580179214\n",
      "Epoch 3, Iteration 300, Loss: 0.06172557920217514\n",
      "Epoch 3, Iteration 310, Loss: 0.04790455102920532\n",
      "Epoch 3, Iteration 320, Loss: 0.03372049331665039\n",
      "Epoch 3, Iteration 330, Loss: 0.02508850023150444\n",
      "Epoch 3, Iteration 340, Loss: 0.06166393309831619\n",
      "Epoch 3, Iteration 350, Loss: 0.041599173098802567\n",
      "Epoch 3, Iteration 360, Loss: 0.053515203297138214\n",
      "Epoch 3, Iteration 370, Loss: 0.06869853287935257\n",
      "Epoch 3, Iteration 380, Loss: 0.048550188541412354\n",
      "Epoch 3, Iteration 390, Loss: 0.04424140974879265\n",
      "Epoch 3, Iteration 400, Loss: 0.02999766729772091\n",
      "Epoch 3, Iteration 410, Loss: 0.025737926363945007\n",
      "Epoch 3, Iteration 420, Loss: 0.021522944793105125\n",
      "Epoch 3, Iteration 430, Loss: 0.028470903635025024\n",
      "Epoch 3, Iteration 440, Loss: 0.13375984132289886\n",
      "Epoch 3, Iteration 450, Loss: 0.03593869507312775\n",
      "Epoch 3, Iteration 460, Loss: 0.040504660457372665\n",
      "Epoch 3, Iteration 470, Loss: 0.04395516216754913\n",
      "Epoch 3, Iteration 480, Loss: 0.030358953401446342\n",
      "Epoch 3, Iteration 490, Loss: 0.04472740739583969\n",
      "Epoch 3, Iteration 500, Loss: 0.051659777760505676\n",
      "Epoch 3, Iteration 510, Loss: 0.04609312489628792\n",
      "Epoch 3, Iteration 520, Loss: 0.04089706391096115\n",
      "Epoch 3, Iteration 530, Loss: 0.030436255037784576\n",
      "Epoch 3, Iteration 540, Loss: 0.0445483922958374\n",
      "Epoch 3, Iteration 550, Loss: 0.0297558531165123\n",
      "Epoch 3, Iteration 560, Loss: 0.05385490506887436\n",
      "Epoch 3, Iteration 570, Loss: 0.02631649374961853\n",
      "Epoch 3, Iteration 580, Loss: 0.04777226969599724\n",
      "Epoch 3, Iteration 590, Loss: 0.03699028491973877\n",
      "Epoch 3, Iteration 600, Loss: 0.07354199886322021\n",
      "Epoch 3, Iteration 610, Loss: 0.023950932547450066\n",
      "Epoch 3, Iteration 620, Loss: 0.030831919983029366\n",
      "Epoch 3, Iteration 630, Loss: 0.031220195814967155\n",
      "Epoch 3, Iteration 640, Loss: 0.10796572268009186\n",
      "Epoch 3, Iteration 650, Loss: 0.038308799266815186\n",
      "Epoch 3, Iteration 660, Loss: 0.04466244950890541\n",
      "Epoch 3, Iteration 670, Loss: 0.04715579375624657\n",
      "Epoch 3, Iteration 680, Loss: 0.07149399071931839\n",
      "Epoch 3, Iteration 690, Loss: 0.10750080645084381\n",
      "Epoch 3, Iteration 700, Loss: 0.037680335342884064\n",
      "Epoch 3, Iteration 710, Loss: 0.027559930458664894\n",
      "Epoch 3, Iteration 720, Loss: 0.030320649966597557\n",
      "Epoch 3, Iteration 730, Loss: 0.046983134001493454\n",
      "Epoch 3, Validation Loss: 0.043014692314698\n",
      "Validation loss decreased (0.043671 --> 0.043015). Saving model...\n",
      "Epoch 4, Iteration 0, Loss: 0.043032456189394\n",
      "Epoch 4, Iteration 10, Loss: 0.052604611963033676\n",
      "Epoch 4, Iteration 20, Loss: 0.033836424350738525\n",
      "Epoch 4, Iteration 30, Loss: 0.030291512608528137\n",
      "Epoch 4, Iteration 40, Loss: 0.03359275311231613\n",
      "Epoch 4, Iteration 50, Loss: 0.03241593390703201\n",
      "Epoch 4, Iteration 60, Loss: 0.027537042275071144\n",
      "Epoch 4, Iteration 70, Loss: 0.08905373513698578\n",
      "Epoch 4, Iteration 80, Loss: 0.07502331584692001\n",
      "Epoch 4, Iteration 90, Loss: 0.027539098635315895\n",
      "Epoch 4, Iteration 100, Loss: 0.057071562856435776\n",
      "Epoch 4, Iteration 110, Loss: 0.05307076871395111\n",
      "Epoch 4, Iteration 120, Loss: 0.06922880560159683\n",
      "Epoch 4, Iteration 130, Loss: 0.04927244782447815\n",
      "Epoch 4, Iteration 140, Loss: 0.023694511502981186\n",
      "Epoch 4, Iteration 150, Loss: 0.07821293920278549\n",
      "Epoch 4, Iteration 160, Loss: 0.03653276711702347\n",
      "Epoch 4, Iteration 170, Loss: 0.049038972705602646\n",
      "Epoch 4, Iteration 180, Loss: 0.05325796827673912\n",
      "Epoch 4, Iteration 190, Loss: 0.0760141909122467\n",
      "Epoch 4, Iteration 200, Loss: 0.028969749808311462\n",
      "Epoch 4, Iteration 210, Loss: 0.05001062527298927\n",
      "Epoch 4, Iteration 220, Loss: 0.04506094753742218\n",
      "Epoch 4, Iteration 230, Loss: 0.03735505789518356\n",
      "Epoch 4, Iteration 240, Loss: 0.07222514599561691\n",
      "Epoch 4, Iteration 250, Loss: 0.03143663331866264\n",
      "Epoch 4, Iteration 260, Loss: 0.02275432087481022\n",
      "Epoch 4, Iteration 270, Loss: 0.03714007884263992\n",
      "Epoch 4, Iteration 280, Loss: 0.05785394087433815\n",
      "Epoch 4, Iteration 290, Loss: 0.05418199300765991\n",
      "Epoch 4, Iteration 300, Loss: 0.057311009615659714\n",
      "Epoch 4, Iteration 310, Loss: 0.03890715539455414\n",
      "Epoch 4, Iteration 320, Loss: 0.048010919243097305\n",
      "Epoch 4, Iteration 330, Loss: 0.031505975872278214\n",
      "Epoch 4, Iteration 340, Loss: 0.058538805693387985\n",
      "Epoch 4, Iteration 350, Loss: 0.05247480794787407\n",
      "Epoch 4, Iteration 360, Loss: 0.0864526554942131\n",
      "Epoch 4, Iteration 370, Loss: 0.04371014982461929\n",
      "Epoch 4, Iteration 380, Loss: 0.04299397021532059\n",
      "Epoch 4, Iteration 390, Loss: 0.08201660215854645\n",
      "Epoch 4, Iteration 400, Loss: 0.030786285176873207\n",
      "Epoch 4, Iteration 410, Loss: 0.04216378554701805\n",
      "Epoch 4, Iteration 420, Loss: 0.0444280207157135\n",
      "Epoch 4, Iteration 430, Loss: 0.05004560202360153\n",
      "Epoch 4, Iteration 440, Loss: 0.03069571778178215\n",
      "Epoch 4, Iteration 450, Loss: 0.01946781575679779\n",
      "Epoch 4, Iteration 460, Loss: 0.03773804381489754\n",
      "Epoch 4, Iteration 470, Loss: 0.05113501101732254\n",
      "Epoch 4, Iteration 480, Loss: 0.04286747798323631\n",
      "Epoch 4, Iteration 490, Loss: 0.03722439706325531\n",
      "Epoch 4, Iteration 500, Loss: 0.05347532778978348\n",
      "Epoch 4, Iteration 510, Loss: 0.06415404379367828\n",
      "Epoch 4, Iteration 520, Loss: 0.03833716735243797\n",
      "Epoch 4, Iteration 530, Loss: 0.01984458416700363\n",
      "Epoch 4, Iteration 540, Loss: 0.05933424085378647\n",
      "Epoch 4, Iteration 550, Loss: 0.039973270148038864\n",
      "Epoch 4, Iteration 560, Loss: 0.03280940651893616\n",
      "Epoch 4, Iteration 570, Loss: 0.0604378767311573\n",
      "Epoch 4, Iteration 580, Loss: 0.0542561374604702\n",
      "Epoch 4, Iteration 590, Loss: 0.03515966236591339\n",
      "Epoch 4, Iteration 600, Loss: 0.05063575506210327\n",
      "Epoch 4, Iteration 610, Loss: 0.03721226006746292\n",
      "Epoch 4, Iteration 620, Loss: 0.03542220592498779\n",
      "Epoch 4, Iteration 630, Loss: 0.02750174142420292\n",
      "Epoch 4, Iteration 640, Loss: 0.018126042559742928\n",
      "Epoch 4, Iteration 650, Loss: 0.04655854031443596\n",
      "Epoch 4, Iteration 660, Loss: 0.05507923290133476\n",
      "Epoch 4, Iteration 670, Loss: 0.03616943210363388\n",
      "Epoch 4, Iteration 680, Loss: 0.05680558830499649\n",
      "Epoch 4, Iteration 690, Loss: 0.03812059387564659\n",
      "Epoch 4, Iteration 700, Loss: 0.038698434829711914\n",
      "Epoch 4, Iteration 710, Loss: 0.05268709734082222\n",
      "Epoch 4, Iteration 720, Loss: 0.03645831719040871\n",
      "Epoch 4, Iteration 730, Loss: 0.05341988429427147\n",
      "Epoch 4, Validation Loss: 0.042633750435450805\n",
      "Validation loss decreased (0.043015 --> 0.042634). Saving model...\n",
      "Epoch 5, Iteration 0, Loss: 0.058140940964221954\n",
      "Epoch 5, Iteration 10, Loss: 0.03139553219079971\n",
      "Epoch 5, Iteration 20, Loss: 0.03801055997610092\n",
      "Epoch 5, Iteration 30, Loss: 0.018438415601849556\n",
      "Epoch 5, Iteration 40, Loss: 0.02510860003530979\n",
      "Epoch 5, Iteration 50, Loss: 0.031523723155260086\n",
      "Epoch 5, Iteration 60, Loss: 0.04951520264148712\n",
      "Epoch 5, Iteration 70, Loss: 0.07117284834384918\n",
      "Epoch 5, Iteration 80, Loss: 0.05498587340116501\n",
      "Epoch 5, Iteration 90, Loss: 0.032332129776477814\n",
      "Epoch 5, Iteration 100, Loss: 0.035069357603788376\n",
      "Epoch 5, Iteration 110, Loss: 0.10557420551776886\n",
      "Epoch 5, Iteration 120, Loss: 0.030077431350946426\n",
      "Epoch 5, Iteration 130, Loss: 0.05503937974572182\n",
      "Epoch 5, Iteration 140, Loss: 0.0369463749229908\n",
      "Epoch 5, Iteration 150, Loss: 0.017609696835279465\n",
      "Epoch 5, Iteration 160, Loss: 0.05251404270529747\n",
      "Epoch 5, Iteration 170, Loss: 0.04446423053741455\n",
      "Epoch 5, Iteration 180, Loss: 0.04720251262187958\n",
      "Epoch 5, Iteration 190, Loss: 0.02342425473034382\n",
      "Epoch 5, Iteration 200, Loss: 0.035472333431243896\n",
      "Epoch 5, Iteration 210, Loss: 0.03978964313864708\n",
      "Epoch 5, Iteration 220, Loss: 0.05384427309036255\n",
      "Epoch 5, Iteration 230, Loss: 0.0794047936797142\n",
      "Epoch 5, Iteration 240, Loss: 0.026821117848157883\n",
      "Epoch 5, Iteration 250, Loss: 0.03679945319890976\n",
      "Epoch 5, Iteration 260, Loss: 0.06400108337402344\n",
      "Epoch 5, Iteration 270, Loss: 0.02702784352004528\n",
      "Epoch 5, Iteration 280, Loss: 0.03181999921798706\n",
      "Epoch 5, Iteration 290, Loss: 0.03798659145832062\n",
      "Epoch 5, Iteration 300, Loss: 0.03227929770946503\n",
      "Epoch 5, Iteration 310, Loss: 0.05489393696188927\n",
      "Epoch 5, Iteration 320, Loss: 0.04624994471669197\n",
      "Epoch 5, Iteration 330, Loss: 0.02872052788734436\n",
      "Epoch 5, Iteration 340, Loss: 0.0510125458240509\n",
      "Epoch 5, Iteration 350, Loss: 0.028132399544119835\n",
      "Epoch 5, Iteration 360, Loss: 0.03741389513015747\n",
      "Epoch 5, Iteration 370, Loss: 0.05543409287929535\n",
      "Epoch 5, Iteration 380, Loss: 0.08041215687990189\n",
      "Epoch 5, Iteration 390, Loss: 0.02674742601811886\n",
      "Epoch 5, Iteration 400, Loss: 0.05403873324394226\n",
      "Epoch 5, Iteration 410, Loss: 0.03262471780180931\n",
      "Epoch 5, Iteration 420, Loss: 0.049322761595249176\n",
      "Epoch 5, Iteration 430, Loss: 0.054243870079517365\n",
      "Epoch 5, Iteration 440, Loss: 0.03993559628725052\n",
      "Epoch 5, Iteration 450, Loss: 0.035110458731651306\n",
      "Epoch 5, Iteration 460, Loss: 0.06398830562829971\n",
      "Epoch 5, Iteration 470, Loss: 0.04544401913881302\n",
      "Epoch 5, Iteration 480, Loss: 0.04880763590335846\n",
      "Epoch 5, Iteration 490, Loss: 0.030906660482287407\n",
      "Epoch 5, Iteration 500, Loss: 0.06310539692640305\n",
      "Epoch 5, Iteration 510, Loss: 0.03684033080935478\n",
      "Epoch 5, Iteration 520, Loss: 0.02828110195696354\n",
      "Epoch 5, Iteration 530, Loss: 0.06789634376764297\n",
      "Epoch 5, Iteration 540, Loss: 0.035050809383392334\n",
      "Epoch 5, Iteration 550, Loss: 0.046219829469919205\n",
      "Epoch 5, Iteration 560, Loss: 0.05223159119486809\n",
      "Epoch 5, Iteration 570, Loss: 0.07536297291517258\n",
      "Epoch 5, Iteration 580, Loss: 0.0725679025053978\n",
      "Epoch 5, Iteration 590, Loss: 0.037077970802783966\n",
      "Epoch 5, Iteration 600, Loss: 0.06145145744085312\n",
      "Epoch 5, Iteration 610, Loss: 0.06645239144563675\n",
      "Epoch 5, Iteration 620, Loss: 0.08664081990718842\n",
      "Epoch 5, Iteration 630, Loss: 0.048259563744068146\n",
      "Epoch 5, Iteration 640, Loss: 0.037438251078128815\n",
      "Epoch 5, Iteration 650, Loss: 0.04653447866439819\n",
      "Epoch 5, Iteration 660, Loss: 0.03888677805662155\n",
      "Epoch 5, Iteration 670, Loss: 0.049030035734176636\n",
      "Epoch 5, Iteration 680, Loss: 0.053242772817611694\n",
      "Epoch 5, Iteration 690, Loss: 0.023458611220121384\n",
      "Epoch 5, Iteration 700, Loss: 0.059279195964336395\n",
      "Epoch 5, Iteration 710, Loss: 0.04008097946643829\n",
      "Epoch 5, Iteration 720, Loss: 0.039307065308094025\n",
      "Epoch 5, Iteration 730, Loss: 0.04742007330060005\n",
      "Epoch 5, Validation Loss: 0.042227454837816564\n",
      "Validation loss decreased (0.042634 --> 0.042227). Saving model...\n",
      "Epoch 6, Iteration 0, Loss: 0.03220567852258682\n",
      "Epoch 6, Iteration 10, Loss: 0.062046367675065994\n",
      "Epoch 6, Iteration 20, Loss: 0.04133019223809242\n",
      "Epoch 6, Iteration 30, Loss: 0.04953616484999657\n",
      "Epoch 6, Iteration 40, Loss: 0.05257907509803772\n",
      "Epoch 6, Iteration 50, Loss: 0.017073124647140503\n",
      "Epoch 6, Iteration 60, Loss: 0.04182593896985054\n",
      "Epoch 6, Iteration 70, Loss: 0.040460605174303055\n",
      "Epoch 6, Iteration 80, Loss: 0.056879088282585144\n",
      "Epoch 6, Iteration 90, Loss: 0.03190275654196739\n",
      "Epoch 6, Iteration 100, Loss: 0.027835512533783913\n",
      "Epoch 6, Iteration 110, Loss: 0.031595099717378616\n",
      "Epoch 6, Iteration 120, Loss: 0.07414303719997406\n",
      "Epoch 6, Iteration 130, Loss: 0.042562346905469894\n",
      "Epoch 6, Iteration 140, Loss: 0.03042185865342617\n",
      "Epoch 6, Iteration 150, Loss: 0.03450654447078705\n",
      "Epoch 6, Iteration 160, Loss: 0.053181152790784836\n",
      "Epoch 6, Iteration 170, Loss: 0.06299076974391937\n",
      "Epoch 6, Iteration 180, Loss: 0.03938205912709236\n",
      "Epoch 6, Iteration 190, Loss: 0.029072191566228867\n",
      "Epoch 6, Iteration 200, Loss: 0.0395597480237484\n",
      "Epoch 6, Iteration 210, Loss: 0.03664623945951462\n",
      "Epoch 6, Iteration 220, Loss: 0.033176690340042114\n",
      "Epoch 6, Iteration 230, Loss: 0.0523156002163887\n",
      "Epoch 6, Iteration 240, Loss: 0.04506046697497368\n",
      "Epoch 6, Iteration 250, Loss: 0.04800214245915413\n",
      "Epoch 6, Iteration 260, Loss: 0.028793584555387497\n",
      "Epoch 6, Iteration 270, Loss: 0.04634104669094086\n",
      "Epoch 6, Iteration 280, Loss: 0.04090502858161926\n",
      "Epoch 6, Iteration 290, Loss: 0.028766369447112083\n",
      "Epoch 6, Iteration 300, Loss: 0.049271635711193085\n",
      "Epoch 6, Iteration 310, Loss: 0.036104343831539154\n",
      "Epoch 6, Iteration 320, Loss: 0.04156791791319847\n",
      "Epoch 6, Iteration 330, Loss: 0.032097991555929184\n",
      "Epoch 6, Iteration 340, Loss: 0.059129342436790466\n",
      "Epoch 6, Iteration 350, Loss: 0.06941764801740646\n",
      "Epoch 6, Iteration 360, Loss: 0.0404876209795475\n",
      "Epoch 6, Iteration 370, Loss: 0.04532367363572121\n",
      "Epoch 6, Iteration 380, Loss: 0.04530045762658119\n",
      "Epoch 6, Iteration 390, Loss: 0.04358600080013275\n",
      "Epoch 6, Iteration 400, Loss: 0.05647053197026253\n",
      "Epoch 6, Iteration 410, Loss: 0.07664274424314499\n",
      "Epoch 6, Iteration 420, Loss: 0.029103776440024376\n",
      "Epoch 6, Iteration 430, Loss: 0.039174314588308334\n",
      "Epoch 6, Iteration 440, Loss: 0.1279343217611313\n",
      "Epoch 6, Iteration 450, Loss: 0.030458170920610428\n",
      "Epoch 6, Iteration 460, Loss: 0.04017702490091324\n",
      "Epoch 6, Iteration 470, Loss: 0.029546931385993958\n",
      "Epoch 6, Iteration 480, Loss: 0.026649560779333115\n",
      "Epoch 6, Iteration 490, Loss: 0.06519878655672073\n",
      "Epoch 6, Iteration 500, Loss: 0.061131224036216736\n",
      "Epoch 6, Iteration 510, Loss: 0.03254185989499092\n",
      "Epoch 6, Iteration 520, Loss: 0.10493222624063492\n",
      "Epoch 6, Iteration 530, Loss: 0.040138550102710724\n",
      "Epoch 6, Iteration 540, Loss: 0.04052295535802841\n",
      "Epoch 6, Iteration 550, Loss: 0.030330901965498924\n",
      "Epoch 6, Iteration 560, Loss: 0.03686422482132912\n",
      "Epoch 6, Iteration 570, Loss: 0.04562653601169586\n",
      "Epoch 6, Iteration 580, Loss: 0.03963050618767738\n",
      "Epoch 6, Iteration 590, Loss: 0.02913963794708252\n",
      "Epoch 6, Iteration 600, Loss: 0.03381877392530441\n",
      "Epoch 6, Iteration 610, Loss: 0.050654955208301544\n",
      "Epoch 6, Iteration 620, Loss: 0.03569893166422844\n",
      "Epoch 6, Iteration 630, Loss: 0.036328040063381195\n",
      "Epoch 6, Iteration 640, Loss: 0.05682936683297157\n",
      "Epoch 6, Iteration 650, Loss: 0.02478143200278282\n",
      "Epoch 6, Iteration 660, Loss: 0.05726175382733345\n",
      "Epoch 6, Iteration 670, Loss: 0.032297637313604355\n",
      "Epoch 6, Iteration 680, Loss: 0.026736143976449966\n",
      "Epoch 6, Iteration 690, Loss: 0.08340045809745789\n",
      "Epoch 6, Iteration 700, Loss: 0.02918880805373192\n",
      "Epoch 6, Iteration 710, Loss: 0.0579545833170414\n",
      "Epoch 6, Iteration 720, Loss: 0.04450327157974243\n",
      "Epoch 6, Iteration 730, Loss: 0.030916234478354454\n",
      "Epoch 6, Validation Loss: 0.043069955103261316\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 7, Iteration 0, Loss: 0.05160987377166748\n",
      "Epoch 7, Iteration 10, Loss: 0.025387194007635117\n",
      "Epoch 7, Iteration 20, Loss: 0.0319456048309803\n",
      "Epoch 7, Iteration 30, Loss: 0.032832443714141846\n",
      "Epoch 7, Iteration 40, Loss: 0.032694946974515915\n",
      "Epoch 7, Iteration 50, Loss: 0.10316425561904907\n",
      "Epoch 7, Iteration 60, Loss: 0.04903470352292061\n",
      "Epoch 7, Iteration 70, Loss: 0.024011408910155296\n",
      "Epoch 7, Iteration 80, Loss: 0.04173478111624718\n",
      "Epoch 7, Iteration 90, Loss: 0.042901452630758286\n",
      "Epoch 7, Iteration 100, Loss: 0.05825041979551315\n",
      "Epoch 7, Iteration 110, Loss: 0.04776180908083916\n",
      "Epoch 7, Iteration 120, Loss: 0.050796300172805786\n",
      "Epoch 7, Iteration 130, Loss: 0.04095565155148506\n",
      "Epoch 7, Iteration 140, Loss: 0.03861862048506737\n",
      "Epoch 7, Iteration 150, Loss: 0.029550304636359215\n",
      "Epoch 7, Iteration 160, Loss: 0.05791221186518669\n",
      "Epoch 7, Iteration 170, Loss: 0.037360142916440964\n",
      "Epoch 7, Iteration 180, Loss: 0.026804137974977493\n",
      "Epoch 7, Iteration 190, Loss: 0.03089865669608116\n",
      "Epoch 7, Iteration 200, Loss: 0.06057463958859444\n",
      "Epoch 7, Iteration 210, Loss: 0.03325764834880829\n",
      "Epoch 7, Iteration 220, Loss: 0.05693585053086281\n",
      "Epoch 7, Iteration 230, Loss: 0.04810813441872597\n",
      "Epoch 7, Iteration 240, Loss: 0.03165508806705475\n",
      "Epoch 7, Iteration 250, Loss: 0.0480518713593483\n",
      "Epoch 7, Iteration 260, Loss: 0.0333360880613327\n",
      "Epoch 7, Iteration 270, Loss: 0.043263304978609085\n",
      "Epoch 7, Iteration 280, Loss: 0.04905999079346657\n",
      "Epoch 7, Iteration 290, Loss: 0.03872188180685043\n",
      "Epoch 7, Iteration 300, Loss: 0.04297811910510063\n",
      "Epoch 7, Iteration 310, Loss: 0.032349005341529846\n",
      "Epoch 7, Iteration 320, Loss: 0.05929051339626312\n",
      "Epoch 7, Iteration 330, Loss: 0.05038626864552498\n",
      "Epoch 7, Iteration 340, Loss: 0.02756410464644432\n",
      "Epoch 7, Iteration 350, Loss: 0.061449289321899414\n",
      "Epoch 7, Iteration 360, Loss: 0.057572752237319946\n",
      "Epoch 7, Iteration 370, Loss: 0.032610055059194565\n",
      "Epoch 7, Iteration 380, Loss: 0.053938720375299454\n",
      "Epoch 7, Iteration 390, Loss: 0.02617160975933075\n",
      "Epoch 7, Iteration 400, Loss: 0.04924352839589119\n",
      "Epoch 7, Iteration 410, Loss: 0.07730988413095474\n",
      "Epoch 7, Iteration 420, Loss: 0.0423152893781662\n",
      "Epoch 7, Iteration 430, Loss: 0.022208046168088913\n",
      "Epoch 7, Iteration 440, Loss: 0.030126992613077164\n",
      "Epoch 7, Iteration 450, Loss: 0.06068236008286476\n",
      "Epoch 7, Iteration 460, Loss: 0.046827152371406555\n",
      "Epoch 7, Iteration 470, Loss: 0.04996286332607269\n",
      "Epoch 7, Iteration 480, Loss: 0.07156703621149063\n",
      "Epoch 7, Iteration 490, Loss: 0.043915312737226486\n",
      "Epoch 7, Iteration 500, Loss: 0.03761642426252365\n",
      "Epoch 7, Iteration 510, Loss: 0.05318522825837135\n",
      "Epoch 7, Iteration 520, Loss: 0.06324771046638489\n",
      "Epoch 7, Iteration 530, Loss: 0.04062474146485329\n",
      "Epoch 7, Iteration 540, Loss: 0.019051462411880493\n",
      "Epoch 7, Iteration 550, Loss: 0.03827625513076782\n",
      "Epoch 7, Iteration 560, Loss: 0.039816565811634064\n",
      "Epoch 7, Iteration 570, Loss: 0.04685317352414131\n",
      "Epoch 7, Iteration 580, Loss: 0.04124334454536438\n",
      "Epoch 7, Iteration 590, Loss: 0.036958057433366776\n",
      "Epoch 7, Iteration 600, Loss: 0.03195233643054962\n",
      "Epoch 7, Iteration 610, Loss: 0.03791353479027748\n",
      "Epoch 7, Iteration 620, Loss: 0.03835810720920563\n",
      "Epoch 7, Iteration 630, Loss: 0.05494581162929535\n",
      "Epoch 7, Iteration 640, Loss: 0.04346015676856041\n",
      "Epoch 7, Iteration 650, Loss: 0.029646359384059906\n",
      "Epoch 7, Iteration 660, Loss: 0.04102902114391327\n",
      "Epoch 7, Iteration 670, Loss: 0.032329022884368896\n",
      "Epoch 7, Iteration 680, Loss: 0.024228869006037712\n",
      "Epoch 7, Iteration 690, Loss: 0.04149512201547623\n",
      "Epoch 7, Iteration 700, Loss: 0.027649205178022385\n",
      "Epoch 7, Iteration 710, Loss: 0.017026983201503754\n",
      "Epoch 7, Iteration 720, Loss: 0.039125073701143265\n",
      "Epoch 7, Iteration 730, Loss: 0.027455395087599754\n",
      "Epoch 7, Validation Loss: 0.04187966109779866\n",
      "Validation loss decreased (0.042227 --> 0.041880). Saving model...\n",
      "Epoch 8, Iteration 0, Loss: 0.0925440862774849\n",
      "Epoch 8, Iteration 10, Loss: 0.052846286445856094\n",
      "Epoch 8, Iteration 20, Loss: 0.034400638192892075\n",
      "Epoch 8, Iteration 30, Loss: 0.029404167085886\n",
      "Epoch 8, Iteration 40, Loss: 0.040326617658138275\n",
      "Epoch 8, Iteration 50, Loss: 0.055232394486665726\n",
      "Epoch 8, Iteration 60, Loss: 0.0177520252764225\n",
      "Epoch 8, Iteration 70, Loss: 0.025684373453259468\n",
      "Epoch 8, Iteration 80, Loss: 0.043145328760147095\n",
      "Epoch 8, Iteration 90, Loss: 0.03292848542332649\n",
      "Epoch 8, Iteration 100, Loss: 0.05321401730179787\n",
      "Epoch 8, Iteration 110, Loss: 0.0347488597035408\n",
      "Epoch 8, Iteration 120, Loss: 0.03354375436902046\n",
      "Epoch 8, Iteration 130, Loss: 0.06457694619894028\n",
      "Epoch 8, Iteration 140, Loss: 0.05697270855307579\n",
      "Epoch 8, Iteration 150, Loss: 0.051399338990449905\n",
      "Epoch 8, Iteration 160, Loss: 0.023221731185913086\n",
      "Epoch 8, Iteration 170, Loss: 0.08158840984106064\n",
      "Epoch 8, Iteration 180, Loss: 0.044703930616378784\n",
      "Epoch 8, Iteration 190, Loss: 0.03746219351887703\n",
      "Epoch 8, Iteration 200, Loss: 0.047031935304403305\n",
      "Epoch 8, Iteration 210, Loss: 0.022543149068951607\n",
      "Epoch 8, Iteration 220, Loss: 0.04862089827656746\n",
      "Epoch 8, Iteration 230, Loss: 0.034667741507291794\n",
      "Epoch 8, Iteration 240, Loss: 0.020483922213315964\n",
      "Epoch 8, Iteration 250, Loss: 0.02476629801094532\n",
      "Epoch 8, Iteration 260, Loss: 0.023648658767342567\n",
      "Epoch 8, Iteration 270, Loss: 0.02714095450937748\n",
      "Epoch 8, Iteration 280, Loss: 0.041458386927843094\n",
      "Epoch 8, Iteration 290, Loss: 0.027588987722992897\n",
      "Epoch 8, Iteration 300, Loss: 0.04642225801944733\n",
      "Epoch 8, Iteration 310, Loss: 0.07008358091115952\n",
      "Epoch 8, Iteration 320, Loss: 0.024753926321864128\n",
      "Epoch 8, Iteration 330, Loss: 0.016490329056978226\n",
      "Epoch 8, Iteration 340, Loss: 0.031237319111824036\n",
      "Epoch 8, Iteration 350, Loss: 0.04834369942545891\n",
      "Epoch 8, Iteration 360, Loss: 0.032421015202999115\n",
      "Epoch 8, Iteration 370, Loss: 0.04183907061815262\n",
      "Epoch 8, Iteration 380, Loss: 0.058525968343019485\n",
      "Epoch 8, Iteration 390, Loss: 0.053930316120386124\n",
      "Epoch 8, Iteration 400, Loss: 0.044905539602041245\n",
      "Epoch 8, Iteration 410, Loss: 0.042439088225364685\n",
      "Epoch 8, Iteration 420, Loss: 0.07106758654117584\n",
      "Epoch 8, Iteration 430, Loss: 0.02403252199292183\n",
      "Epoch 8, Iteration 440, Loss: 0.02338576875627041\n",
      "Epoch 8, Iteration 450, Loss: 0.03315548971295357\n",
      "Epoch 8, Iteration 460, Loss: 0.057031601667404175\n",
      "Epoch 8, Iteration 470, Loss: 0.04194817319512367\n",
      "Epoch 8, Iteration 480, Loss: 0.055794522166252136\n",
      "Epoch 8, Iteration 490, Loss: 0.04771486297249794\n",
      "Epoch 8, Iteration 500, Loss: 0.03933437168598175\n",
      "Epoch 8, Iteration 510, Loss: 0.049203842878341675\n",
      "Epoch 8, Iteration 520, Loss: 0.0342419371008873\n",
      "Epoch 8, Iteration 530, Loss: 0.049846261739730835\n",
      "Epoch 8, Iteration 540, Loss: 0.053376633673906326\n",
      "Epoch 8, Iteration 550, Loss: 0.04848738759756088\n",
      "Epoch 8, Iteration 560, Loss: 0.02890699915587902\n",
      "Epoch 8, Iteration 570, Loss: 0.045820653438568115\n",
      "Epoch 8, Iteration 580, Loss: 0.0222630612552166\n",
      "Epoch 8, Iteration 590, Loss: 0.02506631426513195\n",
      "Epoch 8, Iteration 600, Loss: 0.04961013048887253\n",
      "Epoch 8, Iteration 610, Loss: 0.04146791249513626\n",
      "Epoch 8, Iteration 620, Loss: 0.03798497095704079\n",
      "Epoch 8, Iteration 630, Loss: 0.022822625935077667\n",
      "Epoch 8, Iteration 640, Loss: 0.028556862846016884\n",
      "Epoch 8, Iteration 650, Loss: 0.0387282595038414\n",
      "Epoch 8, Iteration 660, Loss: 0.05123302340507507\n",
      "Epoch 8, Iteration 670, Loss: 0.05564642697572708\n",
      "Epoch 8, Iteration 680, Loss: 0.03386273235082626\n",
      "Epoch 8, Iteration 690, Loss: 0.03990793228149414\n",
      "Epoch 8, Iteration 700, Loss: 0.05329612269997597\n",
      "Epoch 8, Iteration 710, Loss: 0.021157581359148026\n",
      "Epoch 8, Iteration 720, Loss: 0.039166223257780075\n",
      "Epoch 8, Iteration 730, Loss: 0.021374385803937912\n",
      "Epoch 8, Validation Loss: 0.041926388355457915\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 9, Iteration 0, Loss: 0.05190784111618996\n",
      "Epoch 9, Iteration 10, Loss: 0.0272782314568758\n",
      "Epoch 9, Iteration 20, Loss: 0.024479445070028305\n",
      "Epoch 9, Iteration 30, Loss: 0.04164251685142517\n",
      "Epoch 9, Iteration 40, Loss: 0.05234112590551376\n",
      "Epoch 9, Iteration 50, Loss: 0.06079918146133423\n",
      "Epoch 9, Iteration 60, Loss: 0.027517244219779968\n",
      "Epoch 9, Iteration 70, Loss: 0.030577262863516808\n",
      "Epoch 9, Iteration 80, Loss: 0.03408895060420036\n",
      "Epoch 9, Iteration 90, Loss: 0.043772947043180466\n",
      "Epoch 9, Iteration 100, Loss: 0.055033598095178604\n",
      "Epoch 9, Iteration 110, Loss: 0.019807353615760803\n",
      "Epoch 9, Iteration 120, Loss: 0.05020242929458618\n",
      "Epoch 9, Iteration 130, Loss: 0.03213077038526535\n",
      "Epoch 9, Iteration 140, Loss: 0.05532457306981087\n",
      "Epoch 9, Iteration 150, Loss: 0.05699556693434715\n",
      "Epoch 9, Iteration 160, Loss: 0.05878655984997749\n",
      "Epoch 9, Iteration 170, Loss: 0.022843139246106148\n",
      "Epoch 9, Iteration 180, Loss: 0.020307568833231926\n",
      "Epoch 9, Iteration 190, Loss: 0.025152523070573807\n",
      "Epoch 9, Iteration 200, Loss: 0.02932620793581009\n",
      "Epoch 9, Iteration 210, Loss: 0.045614320784807205\n",
      "Epoch 9, Iteration 220, Loss: 0.05955981835722923\n",
      "Epoch 9, Iteration 230, Loss: 0.033478252589702606\n",
      "Epoch 9, Iteration 240, Loss: 0.04432523623108864\n",
      "Epoch 9, Iteration 250, Loss: 0.04497142508625984\n",
      "Epoch 9, Iteration 260, Loss: 0.09454499185085297\n",
      "Epoch 9, Iteration 270, Loss: 0.052408043295145035\n",
      "Epoch 9, Iteration 280, Loss: 0.04809734225273132\n",
      "Epoch 9, Iteration 290, Loss: 0.02535991370677948\n",
      "Epoch 9, Iteration 300, Loss: 0.03925108537077904\n",
      "Epoch 9, Iteration 310, Loss: 0.0323757603764534\n",
      "Epoch 9, Iteration 320, Loss: 0.06807044893503189\n",
      "Epoch 9, Iteration 330, Loss: 0.05543184652924538\n",
      "Epoch 9, Iteration 340, Loss: 0.036087267100811005\n",
      "Epoch 9, Iteration 350, Loss: 0.0355089046061039\n",
      "Epoch 9, Iteration 360, Loss: 0.11450738459825516\n",
      "Epoch 9, Iteration 370, Loss: 0.042914774268865585\n",
      "Epoch 9, Iteration 380, Loss: 0.035066861659288406\n",
      "Epoch 9, Iteration 390, Loss: 0.056131456047296524\n",
      "Epoch 9, Iteration 400, Loss: 0.057850610464811325\n",
      "Epoch 9, Iteration 410, Loss: 0.05184086784720421\n",
      "Epoch 9, Iteration 420, Loss: 0.043038658797740936\n",
      "Epoch 9, Iteration 430, Loss: 0.0819496288895607\n",
      "Epoch 9, Iteration 440, Loss: 0.04723351076245308\n",
      "Epoch 9, Iteration 450, Loss: 0.03998637571930885\n",
      "Epoch 9, Iteration 460, Loss: 0.039160873740911484\n",
      "Epoch 9, Iteration 470, Loss: 0.04341782629489899\n",
      "Epoch 9, Iteration 480, Loss: 0.032325565814971924\n",
      "Epoch 9, Iteration 490, Loss: 0.05056437849998474\n",
      "Epoch 9, Iteration 500, Loss: 0.039380379021167755\n",
      "Epoch 9, Iteration 510, Loss: 0.025856606662273407\n",
      "Epoch 9, Iteration 520, Loss: 0.051179975271224976\n",
      "Epoch 9, Iteration 530, Loss: 0.06760473549365997\n",
      "Epoch 9, Iteration 540, Loss: 0.015514298342168331\n",
      "Epoch 9, Iteration 550, Loss: 0.05546819418668747\n",
      "Epoch 9, Iteration 560, Loss: 0.02438257448375225\n",
      "Epoch 9, Iteration 570, Loss: 0.03796917200088501\n",
      "Epoch 9, Iteration 580, Loss: 0.03677432984113693\n",
      "Epoch 9, Iteration 590, Loss: 0.033837780356407166\n",
      "Epoch 9, Iteration 600, Loss: 0.05724306404590607\n",
      "Epoch 9, Iteration 610, Loss: 0.04389263316988945\n",
      "Epoch 9, Iteration 620, Loss: 0.04633186385035515\n",
      "Epoch 9, Iteration 630, Loss: 0.04008213430643082\n",
      "Epoch 9, Iteration 640, Loss: 0.033205609768629074\n",
      "Epoch 9, Iteration 650, Loss: 0.019423644989728928\n",
      "Epoch 9, Iteration 660, Loss: 0.035824064165353775\n",
      "Epoch 9, Iteration 670, Loss: 0.06627589464187622\n",
      "Epoch 9, Iteration 680, Loss: 0.06771025061607361\n",
      "Epoch 9, Iteration 690, Loss: 0.026651611551642418\n",
      "Epoch 9, Iteration 700, Loss: 0.07694470882415771\n",
      "Epoch 9, Iteration 710, Loss: 0.03987818956375122\n",
      "Epoch 9, Iteration 720, Loss: 0.023732289671897888\n",
      "Epoch 9, Iteration 730, Loss: 0.03361135721206665\n",
      "Epoch 9, Validation Loss: 0.0416592543175363\n",
      "Validation loss decreased (0.041880 --> 0.041659). Saving model...\n",
      "Epoch 10, Iteration 0, Loss: 0.05336868762969971\n",
      "Epoch 10, Iteration 10, Loss: 0.03827694430947304\n",
      "Epoch 10, Iteration 20, Loss: 0.035173200070858\n",
      "Epoch 10, Iteration 30, Loss: 0.02135266363620758\n",
      "Epoch 10, Iteration 40, Loss: 0.02671593613922596\n",
      "Epoch 10, Iteration 50, Loss: 0.029441509395837784\n",
      "Epoch 10, Iteration 60, Loss: 0.04808083921670914\n",
      "Epoch 10, Iteration 70, Loss: 0.02492866851389408\n",
      "Epoch 10, Iteration 80, Loss: 0.03545810282230377\n",
      "Epoch 10, Iteration 90, Loss: 0.08271807432174683\n",
      "Epoch 10, Iteration 100, Loss: 0.038812048733234406\n",
      "Epoch 10, Iteration 110, Loss: 0.02982589602470398\n",
      "Epoch 10, Iteration 120, Loss: 0.052281711250543594\n",
      "Epoch 10, Iteration 130, Loss: 0.06688964366912842\n",
      "Epoch 10, Iteration 140, Loss: 0.05347621813416481\n",
      "Epoch 10, Iteration 150, Loss: 0.050895996391773224\n",
      "Epoch 10, Iteration 160, Loss: 0.0236964114010334\n",
      "Epoch 10, Iteration 170, Loss: 0.022498780861496925\n",
      "Epoch 10, Iteration 180, Loss: 0.0315590426325798\n",
      "Epoch 10, Iteration 190, Loss: 0.06028321385383606\n",
      "Epoch 10, Iteration 200, Loss: 0.017398683354258537\n",
      "Epoch 10, Iteration 210, Loss: 0.03801038861274719\n",
      "Epoch 10, Iteration 220, Loss: 0.03314460441470146\n",
      "Epoch 10, Iteration 230, Loss: 0.04931878671050072\n",
      "Epoch 10, Iteration 240, Loss: 0.04038187488913536\n",
      "Epoch 10, Iteration 250, Loss: 0.05741148442029953\n",
      "Epoch 10, Iteration 260, Loss: 0.02542155049741268\n",
      "Epoch 10, Iteration 270, Loss: 0.034080784767866135\n",
      "Epoch 10, Iteration 280, Loss: 0.033594828099012375\n",
      "Epoch 10, Iteration 290, Loss: 0.034654829651117325\n",
      "Epoch 10, Iteration 300, Loss: 0.06989774107933044\n",
      "Epoch 10, Iteration 310, Loss: 0.01998789608478546\n",
      "Epoch 10, Iteration 320, Loss: 0.029121872037649155\n",
      "Epoch 10, Iteration 330, Loss: 0.07928632944822311\n",
      "Epoch 10, Iteration 340, Loss: 0.039540231227874756\n",
      "Epoch 10, Iteration 350, Loss: 0.041488371789455414\n",
      "Epoch 10, Iteration 360, Loss: 0.057594750076532364\n",
      "Epoch 10, Iteration 370, Loss: 0.04585232213139534\n",
      "Epoch 10, Iteration 380, Loss: 0.04314504191279411\n",
      "Epoch 10, Iteration 390, Loss: 0.021898768842220306\n",
      "Epoch 10, Iteration 400, Loss: 0.04020781069993973\n",
      "Epoch 10, Iteration 410, Loss: 0.05316928029060364\n",
      "Epoch 10, Iteration 420, Loss: 0.022797729820013046\n",
      "Epoch 10, Iteration 430, Loss: 0.05525953695178032\n",
      "Epoch 10, Iteration 440, Loss: 0.04085911810398102\n",
      "Epoch 10, Iteration 450, Loss: 0.04607468843460083\n",
      "Epoch 10, Iteration 460, Loss: 0.07291942834854126\n",
      "Epoch 10, Iteration 470, Loss: 0.051604900509119034\n",
      "Epoch 10, Iteration 480, Loss: 0.06742963939905167\n",
      "Epoch 10, Iteration 490, Loss: 0.08418349176645279\n",
      "Epoch 10, Iteration 500, Loss: 0.021650521084666252\n",
      "Epoch 10, Iteration 510, Loss: 0.040372539311647415\n",
      "Epoch 10, Iteration 520, Loss: 0.05002322793006897\n",
      "Epoch 10, Iteration 530, Loss: 0.0672750324010849\n",
      "Epoch 10, Iteration 540, Loss: 0.0589122548699379\n",
      "Epoch 10, Iteration 550, Loss: 0.03608503192663193\n",
      "Epoch 10, Iteration 560, Loss: 0.01404297724366188\n",
      "Epoch 10, Iteration 570, Loss: 0.02073013037443161\n",
      "Epoch 10, Iteration 580, Loss: 0.04810226336121559\n",
      "Epoch 10, Iteration 590, Loss: 0.02610062249004841\n",
      "Epoch 10, Iteration 600, Loss: 0.05682161822915077\n",
      "Epoch 10, Iteration 610, Loss: 0.03610207512974739\n",
      "Epoch 10, Iteration 620, Loss: 0.041468530893325806\n",
      "Epoch 10, Iteration 630, Loss: 0.012487825937569141\n",
      "Epoch 10, Iteration 640, Loss: 0.03180549666285515\n",
      "Epoch 10, Iteration 650, Loss: 0.03461723029613495\n",
      "Epoch 10, Iteration 660, Loss: 0.06978022307157516\n",
      "Epoch 10, Iteration 670, Loss: 0.07384015619754791\n",
      "Epoch 10, Iteration 680, Loss: 0.04239514842629433\n",
      "Epoch 10, Iteration 690, Loss: 0.0627792701125145\n",
      "Epoch 10, Iteration 700, Loss: 0.047820109874010086\n",
      "Epoch 10, Iteration 710, Loss: 0.04494568705558777\n",
      "Epoch 10, Iteration 720, Loss: 0.06803286075592041\n",
      "Epoch 10, Iteration 730, Loss: 0.057360678911209106\n",
      "Epoch 10, Validation Loss: 0.04144677373013743\n",
      "Validation loss decreased (0.041659 --> 0.041447). Saving model...\n",
      "Epoch 11, Iteration 0, Loss: 0.04261743649840355\n",
      "Epoch 11, Iteration 10, Loss: 0.05884629860520363\n",
      "Epoch 11, Iteration 20, Loss: 0.01192731224000454\n",
      "Epoch 11, Iteration 30, Loss: 0.044808730483055115\n",
      "Epoch 11, Iteration 40, Loss: 0.023046264424920082\n",
      "Epoch 11, Iteration 50, Loss: 0.03226959705352783\n",
      "Epoch 11, Iteration 60, Loss: 0.03386510908603668\n",
      "Epoch 11, Iteration 70, Loss: 0.07612436264753342\n",
      "Epoch 11, Iteration 80, Loss: 0.04717119783163071\n",
      "Epoch 11, Iteration 90, Loss: 0.023579619824886322\n",
      "Epoch 11, Iteration 100, Loss: 0.022171510383486748\n",
      "Epoch 11, Iteration 110, Loss: 0.022845333442091942\n",
      "Epoch 11, Iteration 120, Loss: 0.03643345832824707\n",
      "Epoch 11, Iteration 130, Loss: 0.025616543367505074\n",
      "Epoch 11, Iteration 140, Loss: 0.03264964371919632\n",
      "Epoch 11, Iteration 150, Loss: 0.03558992221951485\n",
      "Epoch 11, Iteration 160, Loss: 0.03461183235049248\n",
      "Epoch 11, Iteration 170, Loss: 0.04764509201049805\n",
      "Epoch 11, Iteration 180, Loss: 0.038397885859012604\n",
      "Epoch 11, Iteration 190, Loss: 0.05890773609280586\n",
      "Epoch 11, Iteration 200, Loss: 0.022017549723386765\n",
      "Epoch 11, Iteration 210, Loss: 0.039040934294462204\n",
      "Epoch 11, Iteration 220, Loss: 0.043268993496894836\n",
      "Epoch 11, Iteration 230, Loss: 0.062129441648721695\n",
      "Epoch 11, Iteration 240, Loss: 0.059185855090618134\n",
      "Epoch 11, Iteration 250, Loss: 0.03769749402999878\n",
      "Epoch 11, Iteration 260, Loss: 0.05177122727036476\n",
      "Epoch 11, Iteration 270, Loss: 0.03294769302010536\n",
      "Epoch 11, Iteration 280, Loss: 0.015787819400429726\n",
      "Epoch 11, Iteration 290, Loss: 0.0914120152592659\n",
      "Epoch 11, Iteration 300, Loss: 0.03290896490216255\n",
      "Epoch 11, Iteration 310, Loss: 0.03202061355113983\n",
      "Epoch 11, Iteration 320, Loss: 0.03607475012540817\n",
      "Epoch 11, Iteration 330, Loss: 0.04047606885433197\n",
      "Epoch 11, Iteration 340, Loss: 0.025918005034327507\n",
      "Epoch 11, Iteration 350, Loss: 0.047549761831760406\n",
      "Epoch 11, Iteration 360, Loss: 0.06657407432794571\n",
      "Epoch 11, Iteration 370, Loss: 0.04673580080270767\n",
      "Epoch 11, Iteration 380, Loss: 0.05280660092830658\n",
      "Epoch 11, Iteration 390, Loss: 0.049303747713565826\n",
      "Epoch 11, Iteration 400, Loss: 0.04837549850344658\n",
      "Epoch 11, Iteration 410, Loss: 0.025719350203871727\n",
      "Epoch 11, Iteration 420, Loss: 0.038949139416217804\n",
      "Epoch 11, Iteration 430, Loss: 0.07337723672389984\n",
      "Epoch 11, Iteration 440, Loss: 0.04234076291322708\n",
      "Epoch 11, Iteration 450, Loss: 0.04011491686105728\n",
      "Epoch 11, Iteration 460, Loss: 0.04182133451104164\n",
      "Epoch 11, Iteration 470, Loss: 0.07386601716279984\n",
      "Epoch 11, Iteration 480, Loss: 0.04332190006971359\n",
      "Epoch 11, Iteration 490, Loss: 0.03190647065639496\n",
      "Epoch 11, Iteration 500, Loss: 0.03980783745646477\n",
      "Epoch 11, Iteration 510, Loss: 0.041329413652420044\n",
      "Epoch 11, Iteration 520, Loss: 0.03349694609642029\n",
      "Epoch 11, Iteration 530, Loss: 0.019430065527558327\n",
      "Epoch 11, Iteration 540, Loss: 0.04998515546321869\n",
      "Epoch 11, Iteration 550, Loss: 0.057086020708084106\n",
      "Epoch 11, Iteration 560, Loss: 0.019863924011588097\n",
      "Epoch 11, Iteration 570, Loss: 0.046929873526096344\n",
      "Epoch 11, Iteration 580, Loss: 0.03591737151145935\n",
      "Epoch 11, Iteration 590, Loss: 0.037080805748701096\n",
      "Epoch 11, Iteration 600, Loss: 0.05150400102138519\n",
      "Epoch 11, Iteration 610, Loss: 0.03265583887696266\n",
      "Epoch 11, Iteration 620, Loss: 0.03522508591413498\n",
      "Epoch 11, Iteration 630, Loss: 0.03433289751410484\n",
      "Epoch 11, Iteration 640, Loss: 0.044836681336164474\n",
      "Epoch 11, Iteration 650, Loss: 0.04674992710351944\n",
      "Epoch 11, Iteration 660, Loss: 0.02804974839091301\n",
      "Epoch 11, Iteration 670, Loss: 0.04926322400569916\n",
      "Epoch 11, Iteration 680, Loss: 0.040395185351371765\n",
      "Epoch 11, Iteration 690, Loss: 0.032484009861946106\n",
      "Epoch 11, Iteration 700, Loss: 0.030026275664567947\n",
      "Epoch 11, Iteration 710, Loss: 0.017770543694496155\n",
      "Epoch 11, Iteration 720, Loss: 0.0336899533867836\n",
      "Epoch 11, Iteration 730, Loss: 0.021812964230775833\n",
      "Epoch 11, Validation Loss: 0.04144371894147733\n",
      "Validation loss decreased (0.041447 --> 0.041444). Saving model...\n",
      "Epoch 12, Iteration 0, Loss: 0.060016930103302\n",
      "Epoch 12, Iteration 10, Loss: 0.04629091918468475\n",
      "Epoch 12, Iteration 20, Loss: 0.06055030971765518\n",
      "Epoch 12, Iteration 30, Loss: 0.07078114151954651\n",
      "Epoch 12, Iteration 40, Loss: 0.052189331501722336\n",
      "Epoch 12, Iteration 50, Loss: 0.03450062870979309\n",
      "Epoch 12, Iteration 60, Loss: 0.07628597319126129\n",
      "Epoch 12, Iteration 70, Loss: 0.06512479484081268\n",
      "Epoch 12, Iteration 80, Loss: 0.03896070271730423\n",
      "Epoch 12, Iteration 90, Loss: 0.08158683031797409\n",
      "Epoch 12, Iteration 100, Loss: 0.044778089970350266\n",
      "Epoch 12, Iteration 110, Loss: 0.028203081339597702\n",
      "Epoch 12, Iteration 120, Loss: 0.036396466195583344\n",
      "Epoch 12, Iteration 130, Loss: 0.04762043058872223\n",
      "Epoch 12, Iteration 140, Loss: 0.04293670132756233\n",
      "Epoch 12, Iteration 150, Loss: 0.028747588396072388\n",
      "Epoch 12, Iteration 160, Loss: 0.04799465462565422\n",
      "Epoch 12, Iteration 170, Loss: 0.052301883697509766\n",
      "Epoch 12, Iteration 180, Loss: 0.04981550574302673\n",
      "Epoch 12, Iteration 190, Loss: 0.03390035778284073\n",
      "Epoch 12, Iteration 200, Loss: 0.060501035302877426\n",
      "Epoch 12, Iteration 210, Loss: 0.02107440121471882\n",
      "Epoch 12, Iteration 220, Loss: 0.03963300585746765\n",
      "Epoch 12, Iteration 230, Loss: 0.03523770719766617\n",
      "Epoch 12, Iteration 240, Loss: 0.038274239748716354\n",
      "Epoch 12, Iteration 250, Loss: 0.027941793203353882\n",
      "Epoch 12, Iteration 260, Loss: 0.030737245455384254\n",
      "Epoch 12, Iteration 270, Loss: 0.036902692168951035\n",
      "Epoch 12, Iteration 280, Loss: 0.02303246408700943\n",
      "Epoch 12, Iteration 290, Loss: 0.030034301802515984\n",
      "Epoch 12, Iteration 300, Loss: 0.03700913116335869\n",
      "Epoch 12, Iteration 310, Loss: 0.06154691055417061\n",
      "Epoch 12, Iteration 320, Loss: 0.02484290488064289\n",
      "Epoch 12, Iteration 330, Loss: 0.019838925451040268\n",
      "Epoch 12, Iteration 340, Loss: 0.05217355862259865\n",
      "Epoch 12, Iteration 350, Loss: 0.03444825857877731\n",
      "Epoch 12, Iteration 360, Loss: 0.05367954075336456\n",
      "Epoch 12, Iteration 370, Loss: 0.01841789111495018\n",
      "Epoch 12, Iteration 380, Loss: 0.06882959604263306\n",
      "Epoch 12, Iteration 390, Loss: 0.029197335243225098\n",
      "Epoch 12, Iteration 400, Loss: 0.03532470762729645\n",
      "Epoch 12, Iteration 410, Loss: 0.0341847687959671\n",
      "Epoch 12, Iteration 420, Loss: 0.039419833570718765\n",
      "Epoch 12, Iteration 430, Loss: 0.05657646805047989\n",
      "Epoch 12, Iteration 440, Loss: 0.03729897737503052\n",
      "Epoch 12, Iteration 450, Loss: 0.024849841371178627\n",
      "Epoch 12, Iteration 460, Loss: 0.024329794570803642\n",
      "Epoch 12, Iteration 470, Loss: 0.04617020860314369\n",
      "Epoch 12, Iteration 480, Loss: 0.05959296226501465\n",
      "Epoch 12, Iteration 490, Loss: 0.049269676208496094\n",
      "Epoch 12, Iteration 500, Loss: 0.04242020100355148\n",
      "Epoch 12, Iteration 510, Loss: 0.05007036402821541\n",
      "Epoch 12, Iteration 520, Loss: 0.037601884454488754\n",
      "Epoch 12, Iteration 530, Loss: 0.03672775998711586\n",
      "Epoch 12, Iteration 540, Loss: 0.0327516607940197\n",
      "Epoch 12, Iteration 550, Loss: 0.046740010380744934\n",
      "Epoch 12, Iteration 560, Loss: 0.03622516244649887\n",
      "Epoch 12, Iteration 570, Loss: 0.029233232140541077\n",
      "Epoch 12, Iteration 580, Loss: 0.0511450432240963\n",
      "Epoch 12, Iteration 590, Loss: 0.03928380459547043\n",
      "Epoch 12, Iteration 600, Loss: 0.02855731174349785\n",
      "Epoch 12, Iteration 610, Loss: 0.03635500371456146\n",
      "Epoch 12, Iteration 620, Loss: 0.05453938990831375\n",
      "Epoch 12, Iteration 630, Loss: 0.02615213580429554\n",
      "Epoch 12, Iteration 640, Loss: 0.047487713396549225\n",
      "Epoch 12, Iteration 650, Loss: 0.04824076220393181\n",
      "Epoch 12, Iteration 660, Loss: 0.03658388555049896\n",
      "Epoch 12, Iteration 670, Loss: 0.053298771381378174\n",
      "Epoch 12, Iteration 680, Loss: 0.0464244969189167\n",
      "Epoch 12, Iteration 690, Loss: 0.05158378928899765\n",
      "Epoch 12, Iteration 700, Loss: 0.02692035399377346\n",
      "Epoch 12, Iteration 710, Loss: 0.09664639830589294\n",
      "Epoch 12, Iteration 720, Loss: 0.04045858606696129\n",
      "Epoch 12, Iteration 730, Loss: 0.0613630972802639\n",
      "Epoch 12, Validation Loss: 0.04152738865788864\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 13, Iteration 0, Loss: 0.06694339215755463\n",
      "Epoch 13, Iteration 10, Loss: 0.043132293969392776\n",
      "Epoch 13, Iteration 20, Loss: 0.024477846920490265\n",
      "Epoch 13, Iteration 30, Loss: 0.040726110339164734\n",
      "Epoch 13, Iteration 40, Loss: 0.021609656512737274\n",
      "Epoch 13, Iteration 50, Loss: 0.03751248121261597\n",
      "Epoch 13, Iteration 60, Loss: 0.04333188384771347\n",
      "Epoch 13, Iteration 70, Loss: 0.030048882588744164\n",
      "Epoch 13, Iteration 80, Loss: 0.02510896325111389\n",
      "Epoch 13, Iteration 90, Loss: 0.03826062008738518\n",
      "Epoch 13, Iteration 100, Loss: 0.06065798178315163\n",
      "Epoch 13, Iteration 110, Loss: 0.08458257466554642\n",
      "Epoch 13, Iteration 120, Loss: 0.04048711806535721\n",
      "Epoch 13, Iteration 130, Loss: 0.04896683990955353\n",
      "Epoch 13, Iteration 140, Loss: 0.03071422129869461\n",
      "Epoch 13, Iteration 150, Loss: 0.07119454443454742\n",
      "Epoch 13, Iteration 160, Loss: 0.022607894614338875\n",
      "Epoch 13, Iteration 170, Loss: 0.025999242439866066\n",
      "Epoch 13, Iteration 180, Loss: 0.03244025632739067\n",
      "Epoch 13, Iteration 190, Loss: 0.059970129281282425\n",
      "Epoch 13, Iteration 200, Loss: 0.04266037419438362\n",
      "Epoch 13, Iteration 210, Loss: 0.040483277291059494\n",
      "Epoch 13, Iteration 220, Loss: 0.07988714426755905\n",
      "Epoch 13, Iteration 230, Loss: 0.06579594314098358\n",
      "Epoch 13, Iteration 240, Loss: 0.03284331411123276\n",
      "Epoch 13, Iteration 250, Loss: 0.040862973779439926\n",
      "Epoch 13, Iteration 260, Loss: 0.027505693957209587\n",
      "Epoch 13, Iteration 270, Loss: 0.032963816076517105\n",
      "Epoch 13, Iteration 280, Loss: 0.04631444066762924\n",
      "Epoch 13, Iteration 290, Loss: 0.03403967618942261\n",
      "Epoch 13, Iteration 300, Loss: 0.03743279352784157\n",
      "Epoch 13, Iteration 310, Loss: 0.029876092448830605\n",
      "Epoch 13, Iteration 320, Loss: 0.03148355334997177\n",
      "Epoch 13, Iteration 330, Loss: 0.03632665425539017\n",
      "Epoch 13, Iteration 340, Loss: 0.01337771862745285\n",
      "Epoch 13, Iteration 350, Loss: 0.03022747114300728\n",
      "Epoch 13, Iteration 360, Loss: 0.013210930861532688\n",
      "Epoch 13, Iteration 370, Loss: 0.01575417071580887\n",
      "Epoch 13, Iteration 380, Loss: 0.10433132201433182\n",
      "Epoch 13, Iteration 390, Loss: 0.022527743130922318\n",
      "Epoch 13, Iteration 400, Loss: 0.032344743609428406\n",
      "Epoch 13, Iteration 410, Loss: 0.03149352967739105\n",
      "Epoch 13, Iteration 420, Loss: 0.044218309223651886\n",
      "Epoch 13, Iteration 430, Loss: 0.017302514985203743\n",
      "Epoch 13, Iteration 440, Loss: 0.0303647480905056\n",
      "Epoch 13, Iteration 450, Loss: 0.05024116486310959\n",
      "Epoch 13, Iteration 460, Loss: 0.03309748321771622\n",
      "Epoch 13, Iteration 470, Loss: 0.04297209158539772\n",
      "Epoch 13, Iteration 480, Loss: 0.10276741534471512\n",
      "Epoch 13, Iteration 490, Loss: 0.039229027926921844\n",
      "Epoch 13, Iteration 500, Loss: 0.04826291650533676\n",
      "Epoch 13, Iteration 510, Loss: 0.03352475166320801\n",
      "Epoch 13, Iteration 520, Loss: 0.030851704999804497\n",
      "Epoch 13, Iteration 530, Loss: 0.032320696860551834\n",
      "Epoch 13, Iteration 540, Loss: 0.04409162327647209\n",
      "Epoch 13, Iteration 550, Loss: 0.05122609809041023\n",
      "Epoch 13, Iteration 560, Loss: 0.045740239322185516\n",
      "Epoch 13, Iteration 570, Loss: 0.022304203361272812\n",
      "Epoch 13, Iteration 580, Loss: 0.0366106815636158\n",
      "Epoch 13, Iteration 590, Loss: 0.058447763323783875\n",
      "Epoch 13, Iteration 600, Loss: 0.04306289926171303\n",
      "Epoch 13, Iteration 610, Loss: 0.04236963391304016\n",
      "Epoch 13, Iteration 620, Loss: 0.03405896946787834\n",
      "Epoch 13, Iteration 630, Loss: 0.05139783024787903\n",
      "Epoch 13, Iteration 640, Loss: 0.03359019756317139\n",
      "Epoch 13, Iteration 650, Loss: 0.05272897705435753\n",
      "Epoch 13, Iteration 660, Loss: 0.10660327970981598\n",
      "Epoch 13, Iteration 670, Loss: 0.026590483263134956\n",
      "Epoch 13, Iteration 680, Loss: 0.04291899874806404\n",
      "Epoch 13, Iteration 690, Loss: 0.042484037578105927\n",
      "Epoch 13, Iteration 700, Loss: 0.0623306930065155\n",
      "Epoch 13, Iteration 710, Loss: 0.03245033323764801\n",
      "Epoch 13, Iteration 720, Loss: 0.07670635730028152\n",
      "Epoch 13, Iteration 730, Loss: 0.0392732210457325\n",
      "Epoch 13, Validation Loss: 0.04143527224052535\n",
      "Validation loss decreased (0.041444 --> 0.041435). Saving model...\n",
      "Epoch 14, Iteration 0, Loss: 0.03544439747929573\n",
      "Epoch 14, Iteration 10, Loss: 0.05575289949774742\n",
      "Epoch 14, Iteration 20, Loss: 0.020576801151037216\n",
      "Epoch 14, Iteration 30, Loss: 0.049490753561258316\n",
      "Epoch 14, Iteration 40, Loss: 0.05037223547697067\n",
      "Epoch 14, Iteration 50, Loss: 0.03716005012392998\n",
      "Epoch 14, Iteration 60, Loss: 0.038618944585323334\n",
      "Epoch 14, Iteration 70, Loss: 0.01859748736023903\n",
      "Epoch 14, Iteration 80, Loss: 0.05132606625556946\n",
      "Epoch 14, Iteration 90, Loss: 0.041568201035261154\n",
      "Epoch 14, Iteration 100, Loss: 0.04966820031404495\n",
      "Epoch 14, Iteration 110, Loss: 0.037321776151657104\n",
      "Epoch 14, Iteration 120, Loss: 0.0833350270986557\n",
      "Epoch 14, Iteration 130, Loss: 0.07699795812368393\n",
      "Epoch 14, Iteration 140, Loss: 0.017206937074661255\n",
      "Epoch 14, Iteration 150, Loss: 0.03422004356980324\n",
      "Epoch 14, Iteration 160, Loss: 0.0436931736767292\n",
      "Epoch 14, Iteration 170, Loss: 0.02545710653066635\n",
      "Epoch 14, Iteration 180, Loss: 0.05978328734636307\n",
      "Epoch 14, Iteration 190, Loss: 0.029915397986769676\n",
      "Epoch 14, Iteration 200, Loss: 0.04531974345445633\n",
      "Epoch 14, Iteration 210, Loss: 0.0771578848361969\n",
      "Epoch 14, Iteration 220, Loss: 0.041946154087781906\n",
      "Epoch 14, Iteration 230, Loss: 0.044218048453330994\n",
      "Epoch 14, Iteration 240, Loss: 0.04001409187912941\n",
      "Epoch 14, Iteration 250, Loss: 0.05417041480541229\n",
      "Epoch 14, Iteration 260, Loss: 0.10633596777915955\n",
      "Epoch 14, Iteration 270, Loss: 0.038351383060216904\n",
      "Epoch 14, Iteration 280, Loss: 0.039649710059165955\n",
      "Epoch 14, Iteration 290, Loss: 0.040316931903362274\n",
      "Epoch 14, Iteration 300, Loss: 0.03133530914783478\n",
      "Epoch 14, Iteration 310, Loss: 0.02328442968428135\n",
      "Epoch 14, Iteration 320, Loss: 0.04790142923593521\n",
      "Epoch 14, Iteration 330, Loss: 0.034904398024082184\n",
      "Epoch 14, Iteration 340, Loss: 0.05750385671854019\n",
      "Epoch 14, Iteration 350, Loss: 0.023974532261490822\n",
      "Epoch 14, Iteration 360, Loss: 0.04416375607252121\n",
      "Epoch 14, Iteration 370, Loss: 0.03925521671772003\n",
      "Epoch 14, Iteration 380, Loss: 0.046747710555791855\n",
      "Epoch 14, Iteration 390, Loss: 0.0627506822347641\n",
      "Epoch 14, Iteration 400, Loss: 0.028770573437213898\n",
      "Epoch 14, Iteration 410, Loss: 0.03594197705388069\n",
      "Epoch 14, Iteration 420, Loss: 0.027962129563093185\n",
      "Epoch 14, Iteration 430, Loss: 0.03864174708724022\n",
      "Epoch 14, Iteration 440, Loss: 0.038147710263729095\n",
      "Epoch 14, Iteration 450, Loss: 0.06782371550798416\n",
      "Epoch 14, Iteration 460, Loss: 0.03424382209777832\n",
      "Epoch 14, Iteration 470, Loss: 0.010250763967633247\n",
      "Epoch 14, Iteration 480, Loss: 0.037977464497089386\n",
      "Epoch 14, Iteration 490, Loss: 0.028566662222146988\n",
      "Epoch 14, Iteration 500, Loss: 0.04611287638545036\n",
      "Epoch 14, Iteration 510, Loss: 0.04008008912205696\n",
      "Epoch 14, Iteration 520, Loss: 0.048509858548641205\n",
      "Epoch 14, Iteration 530, Loss: 0.042443688958883286\n",
      "Epoch 14, Iteration 540, Loss: 0.030006011947989464\n",
      "Epoch 14, Iteration 550, Loss: 0.07453802227973938\n",
      "Epoch 14, Iteration 560, Loss: 0.047848936170339584\n",
      "Epoch 14, Iteration 570, Loss: 0.10994120687246323\n",
      "Epoch 14, Iteration 580, Loss: 0.017560597509145737\n",
      "Epoch 14, Iteration 590, Loss: 0.0258232019841671\n",
      "Epoch 14, Iteration 600, Loss: 0.03131476789712906\n",
      "Epoch 14, Iteration 610, Loss: 0.03082709200680256\n",
      "Epoch 14, Iteration 620, Loss: 0.0484064519405365\n",
      "Epoch 14, Iteration 630, Loss: 0.028606170788407326\n",
      "Epoch 14, Iteration 640, Loss: 0.10146642476320267\n",
      "Epoch 14, Iteration 650, Loss: 0.02459115907549858\n",
      "Epoch 14, Iteration 660, Loss: 0.03339951112866402\n",
      "Epoch 14, Iteration 670, Loss: 0.035113222897052765\n",
      "Epoch 14, Iteration 680, Loss: 0.05272575467824936\n",
      "Epoch 14, Iteration 690, Loss: 0.037047211080789566\n",
      "Epoch 14, Iteration 700, Loss: 0.05817153677344322\n",
      "Epoch 14, Iteration 710, Loss: 0.04199952259659767\n",
      "Epoch 14, Iteration 720, Loss: 0.07555903494358063\n",
      "Epoch 14, Iteration 730, Loss: 0.04462936148047447\n",
      "Epoch 14, Validation Loss: 0.04139937260998008\n",
      "Validation loss decreased (0.041435 --> 0.041399). Saving model...\n",
      "Epoch 15, Iteration 0, Loss: 0.05794175714254379\n",
      "Epoch 15, Iteration 10, Loss: 0.030888963490724564\n",
      "Epoch 15, Iteration 20, Loss: 0.04461810737848282\n",
      "Epoch 15, Iteration 30, Loss: 0.10518892854452133\n",
      "Epoch 15, Iteration 40, Loss: 0.04788793995976448\n",
      "Epoch 15, Iteration 50, Loss: 0.051218193024396896\n",
      "Epoch 15, Iteration 60, Loss: 0.053232938051223755\n",
      "Epoch 15, Iteration 70, Loss: 0.023963939398527145\n",
      "Epoch 15, Iteration 80, Loss: 0.060690853744745255\n",
      "Epoch 15, Iteration 90, Loss: 0.07286802679300308\n",
      "Epoch 15, Iteration 100, Loss: 0.05120311304926872\n",
      "Epoch 15, Iteration 110, Loss: 0.05290893465280533\n",
      "Epoch 15, Iteration 120, Loss: 0.01654384657740593\n",
      "Epoch 15, Iteration 130, Loss: 0.0202932208776474\n",
      "Epoch 15, Iteration 140, Loss: 0.03928160294890404\n",
      "Epoch 15, Iteration 150, Loss: 0.016344120725989342\n",
      "Epoch 15, Iteration 160, Loss: 0.04543812572956085\n",
      "Epoch 15, Iteration 170, Loss: 0.0548451766371727\n",
      "Epoch 15, Iteration 180, Loss: 0.046729572117328644\n",
      "Epoch 15, Iteration 190, Loss: 0.036588720977306366\n",
      "Epoch 15, Iteration 200, Loss: 0.054117392748594284\n",
      "Epoch 15, Iteration 210, Loss: 0.08563634753227234\n",
      "Epoch 15, Iteration 220, Loss: 0.029376855120062828\n",
      "Epoch 15, Iteration 230, Loss: 0.024679021909832954\n",
      "Epoch 15, Iteration 240, Loss: 0.03353876620531082\n",
      "Epoch 15, Iteration 250, Loss: 0.0461222343146801\n",
      "Epoch 15, Iteration 260, Loss: 0.06532777100801468\n",
      "Epoch 15, Iteration 270, Loss: 0.04319293797016144\n",
      "Epoch 15, Iteration 280, Loss: 0.03592175245285034\n",
      "Epoch 15, Iteration 290, Loss: 0.025584813207387924\n",
      "Epoch 15, Iteration 300, Loss: 0.05616091191768646\n",
      "Epoch 15, Iteration 310, Loss: 0.04956696555018425\n",
      "Epoch 15, Iteration 320, Loss: 0.05764881521463394\n",
      "Epoch 15, Iteration 330, Loss: 0.05237306281924248\n",
      "Epoch 15, Iteration 340, Loss: 0.04198523238301277\n",
      "Epoch 15, Iteration 350, Loss: 0.0349850058555603\n",
      "Epoch 15, Iteration 360, Loss: 0.05215873941779137\n",
      "Epoch 15, Iteration 370, Loss: 0.03552892431616783\n",
      "Epoch 15, Iteration 380, Loss: 0.06674709171056747\n",
      "Epoch 15, Iteration 390, Loss: 0.0492691770195961\n",
      "Epoch 15, Iteration 400, Loss: 0.044740933924913406\n",
      "Epoch 15, Iteration 410, Loss: 0.03494269773364067\n",
      "Epoch 15, Iteration 420, Loss: 0.0476042740046978\n",
      "Epoch 15, Iteration 430, Loss: 0.06456131488084793\n",
      "Epoch 15, Iteration 440, Loss: 0.035663262009620667\n",
      "Epoch 15, Iteration 450, Loss: 0.05848084017634392\n",
      "Epoch 15, Iteration 460, Loss: 0.02797183208167553\n",
      "Epoch 15, Iteration 470, Loss: 0.055201828479766846\n",
      "Epoch 15, Iteration 480, Loss: 0.06347967684268951\n",
      "Epoch 15, Iteration 490, Loss: 0.08041997253894806\n",
      "Epoch 15, Iteration 500, Loss: 0.04607374221086502\n",
      "Epoch 15, Iteration 510, Loss: 0.0692308247089386\n",
      "Epoch 15, Iteration 520, Loss: 0.0658600777387619\n",
      "Epoch 15, Iteration 530, Loss: 0.03541433811187744\n",
      "Epoch 15, Iteration 540, Loss: 0.055117350071668625\n",
      "Epoch 15, Iteration 550, Loss: 0.05484297499060631\n",
      "Epoch 15, Iteration 560, Loss: 0.042827386409044266\n",
      "Epoch 15, Iteration 570, Loss: 0.02016601338982582\n",
      "Epoch 15, Iteration 580, Loss: 0.043309297412633896\n",
      "Epoch 15, Iteration 590, Loss: 0.056342460215091705\n",
      "Epoch 15, Iteration 600, Loss: 0.04887598007917404\n",
      "Epoch 15, Iteration 610, Loss: 0.031506139785051346\n",
      "Epoch 15, Iteration 620, Loss: 0.015097077935934067\n",
      "Epoch 15, Iteration 630, Loss: 0.03109338879585266\n",
      "Epoch 15, Iteration 640, Loss: 0.03899536654353142\n",
      "Epoch 15, Iteration 650, Loss: 0.06203953176736832\n",
      "Epoch 15, Iteration 660, Loss: 0.024113604798913002\n",
      "Epoch 15, Iteration 670, Loss: 0.06769872456789017\n",
      "Epoch 15, Iteration 680, Loss: 0.09535693377256393\n",
      "Epoch 15, Iteration 690, Loss: 0.08149407804012299\n",
      "Epoch 15, Iteration 700, Loss: 0.06528817862272263\n",
      "Epoch 15, Iteration 710, Loss: 0.029497258365154266\n",
      "Epoch 15, Iteration 720, Loss: 0.04293323680758476\n",
      "Epoch 15, Iteration 730, Loss: 0.06274638324975967\n",
      "Epoch 15, Validation Loss: 0.04129967595572057\n",
      "Validation loss decreased (0.041399 --> 0.041300). Saving model...\n",
      "Epoch 16, Iteration 0, Loss: 0.04863075911998749\n",
      "Epoch 16, Iteration 10, Loss: 0.026188597083091736\n",
      "Epoch 16, Iteration 20, Loss: 0.02687332034111023\n",
      "Epoch 16, Iteration 30, Loss: 0.098323754966259\n",
      "Epoch 16, Iteration 40, Loss: 0.049369603395462036\n",
      "Epoch 16, Iteration 50, Loss: 0.028431780636310577\n",
      "Epoch 16, Iteration 60, Loss: 0.12388116121292114\n",
      "Epoch 16, Iteration 70, Loss: 0.02709602564573288\n",
      "Epoch 16, Iteration 80, Loss: 0.032078199088573456\n",
      "Epoch 16, Iteration 90, Loss: 0.02942337840795517\n",
      "Epoch 16, Iteration 100, Loss: 0.05993814021348953\n",
      "Epoch 16, Iteration 110, Loss: 0.04711461439728737\n",
      "Epoch 16, Iteration 120, Loss: 0.025813521817326546\n",
      "Epoch 16, Iteration 130, Loss: 0.06104365736246109\n",
      "Epoch 16, Iteration 140, Loss: 0.03674774244427681\n",
      "Epoch 16, Iteration 150, Loss: 0.01806621439754963\n",
      "Epoch 16, Iteration 160, Loss: 0.045149821788072586\n",
      "Epoch 16, Iteration 170, Loss: 0.027376310899853706\n",
      "Epoch 16, Iteration 180, Loss: 0.012127307243645191\n",
      "Epoch 16, Iteration 190, Loss: 0.025690501555800438\n",
      "Epoch 16, Iteration 200, Loss: 0.043866027146577835\n",
      "Epoch 16, Iteration 210, Loss: 0.03350093960762024\n",
      "Epoch 16, Iteration 220, Loss: 0.11645665019750595\n",
      "Epoch 16, Iteration 230, Loss: 0.0437801368534565\n",
      "Epoch 16, Iteration 240, Loss: 0.045905113220214844\n",
      "Epoch 16, Iteration 250, Loss: 0.06752544641494751\n",
      "Epoch 16, Iteration 260, Loss: 0.03410736471414566\n",
      "Epoch 16, Iteration 270, Loss: 0.029424970969557762\n",
      "Epoch 16, Iteration 280, Loss: 0.0464150533080101\n",
      "Epoch 16, Iteration 290, Loss: 0.02066360041499138\n",
      "Epoch 16, Iteration 300, Loss: 0.06006985157728195\n",
      "Epoch 16, Iteration 310, Loss: 0.03786866366863251\n",
      "Epoch 16, Iteration 320, Loss: 0.049315501004457474\n",
      "Epoch 16, Iteration 330, Loss: 0.04525580257177353\n",
      "Epoch 16, Iteration 340, Loss: 0.038918979465961456\n",
      "Epoch 16, Iteration 350, Loss: 0.040471237152814865\n",
      "Epoch 16, Iteration 360, Loss: 0.022584479302167892\n",
      "Epoch 16, Iteration 370, Loss: 0.01510553527623415\n",
      "Epoch 16, Iteration 380, Loss: 0.043872710317373276\n",
      "Epoch 16, Iteration 390, Loss: 0.015811411663889885\n",
      "Epoch 16, Iteration 400, Loss: 0.04169999808073044\n",
      "Epoch 16, Iteration 410, Loss: 0.04419979825615883\n",
      "Epoch 16, Iteration 420, Loss: 0.028978392481803894\n",
      "Epoch 16, Iteration 430, Loss: 0.05491776019334793\n",
      "Epoch 16, Iteration 440, Loss: 0.03423316031694412\n",
      "Epoch 16, Iteration 450, Loss: 0.04640910029411316\n",
      "Epoch 16, Iteration 460, Loss: 0.017113955691456795\n",
      "Epoch 16, Iteration 470, Loss: 0.05083765462040901\n",
      "Epoch 16, Iteration 480, Loss: 0.04820019379258156\n",
      "Epoch 16, Iteration 490, Loss: 0.02874702773988247\n",
      "Epoch 16, Iteration 500, Loss: 0.04994811862707138\n",
      "Epoch 16, Iteration 510, Loss: 0.022114191204309464\n",
      "Epoch 16, Iteration 520, Loss: 0.02309105172753334\n",
      "Epoch 16, Iteration 530, Loss: 0.0591290257871151\n",
      "Epoch 16, Iteration 540, Loss: 0.06778988987207413\n",
      "Epoch 16, Iteration 550, Loss: 0.05351919308304787\n",
      "Epoch 16, Iteration 560, Loss: 0.05096780136227608\n",
      "Epoch 16, Iteration 570, Loss: 0.025479942560195923\n",
      "Epoch 16, Iteration 580, Loss: 0.03914082050323486\n",
      "Epoch 16, Iteration 590, Loss: 0.04847711697220802\n",
      "Epoch 16, Iteration 600, Loss: 0.019282210618257523\n",
      "Epoch 16, Iteration 610, Loss: 0.04907709360122681\n",
      "Epoch 16, Iteration 620, Loss: 0.03271636366844177\n",
      "Epoch 16, Iteration 630, Loss: 0.0506412535905838\n",
      "Epoch 16, Iteration 640, Loss: 0.03322188928723335\n",
      "Epoch 16, Iteration 650, Loss: 0.04296283423900604\n",
      "Epoch 16, Iteration 660, Loss: 0.06072254478931427\n",
      "Epoch 16, Iteration 670, Loss: 0.032773103564977646\n",
      "Epoch 16, Iteration 680, Loss: 0.052763547748327255\n",
      "Epoch 16, Iteration 690, Loss: 0.07158046960830688\n",
      "Epoch 16, Iteration 700, Loss: 0.06993353366851807\n",
      "Epoch 16, Iteration 710, Loss: 0.0444110743701458\n",
      "Epoch 16, Iteration 720, Loss: 0.0654362291097641\n",
      "Epoch 16, Iteration 730, Loss: 0.02163727581501007\n",
      "Epoch 16, Validation Loss: 0.04142156017579786\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 17, Iteration 0, Loss: 0.03143312782049179\n",
      "Epoch 17, Iteration 10, Loss: 0.03604075685143471\n",
      "Epoch 17, Iteration 20, Loss: 0.043839212507009506\n",
      "Epoch 17, Iteration 30, Loss: 0.06503404676914215\n",
      "Epoch 17, Iteration 40, Loss: 0.0568196140229702\n",
      "Epoch 17, Iteration 50, Loss: 0.05676839500665665\n",
      "Epoch 17, Iteration 60, Loss: 0.026273546740412712\n",
      "Epoch 17, Iteration 70, Loss: 0.03565552458167076\n",
      "Epoch 17, Iteration 80, Loss: 0.03595063090324402\n",
      "Epoch 17, Iteration 90, Loss: 0.03237922117114067\n",
      "Epoch 17, Iteration 100, Loss: 0.046618517488241196\n",
      "Epoch 17, Iteration 110, Loss: 0.034359294921159744\n",
      "Epoch 17, Iteration 120, Loss: 0.035242710262537\n",
      "Epoch 17, Iteration 130, Loss: 0.025699229910969734\n",
      "Epoch 17, Iteration 140, Loss: 0.03604399785399437\n",
      "Epoch 17, Iteration 150, Loss: 0.03231654688715935\n",
      "Epoch 17, Iteration 160, Loss: 0.02113250643014908\n",
      "Epoch 17, Iteration 170, Loss: 0.047916751354932785\n",
      "Epoch 17, Iteration 180, Loss: 0.034937042742967606\n",
      "Epoch 17, Iteration 190, Loss: 0.030599534511566162\n",
      "Epoch 17, Iteration 200, Loss: 0.02182668447494507\n",
      "Epoch 17, Iteration 210, Loss: 0.02345552295446396\n",
      "Epoch 17, Iteration 220, Loss: 0.03881620243191719\n",
      "Epoch 17, Iteration 230, Loss: 0.05219889432191849\n",
      "Epoch 17, Iteration 240, Loss: 0.05254223942756653\n",
      "Epoch 17, Iteration 250, Loss: 0.036059897392988205\n",
      "Epoch 17, Iteration 260, Loss: 0.03776710480451584\n",
      "Epoch 17, Iteration 270, Loss: 0.04098856821656227\n",
      "Epoch 17, Iteration 280, Loss: 0.09116843342781067\n",
      "Epoch 17, Iteration 290, Loss: 0.06013822928071022\n",
      "Epoch 17, Iteration 300, Loss: 0.09243403375148773\n",
      "Epoch 17, Iteration 310, Loss: 0.04582521319389343\n",
      "Epoch 17, Iteration 320, Loss: 0.04289865493774414\n",
      "Epoch 17, Iteration 330, Loss: 0.02670259401202202\n",
      "Epoch 17, Iteration 340, Loss: 0.06678219884634018\n",
      "Epoch 17, Iteration 350, Loss: 0.047386545687913895\n",
      "Epoch 17, Iteration 360, Loss: 0.03664710745215416\n",
      "Epoch 17, Iteration 370, Loss: 0.0662536770105362\n",
      "Epoch 17, Iteration 380, Loss: 0.015445016324520111\n",
      "Epoch 17, Iteration 390, Loss: 0.046887628734111786\n",
      "Epoch 17, Iteration 400, Loss: 0.024270232766866684\n",
      "Epoch 17, Iteration 410, Loss: 0.030477281659841537\n",
      "Epoch 17, Iteration 420, Loss: 0.017719460651278496\n",
      "Epoch 17, Iteration 430, Loss: 0.03339717537164688\n",
      "Epoch 17, Iteration 440, Loss: 0.03122876212000847\n",
      "Epoch 17, Iteration 450, Loss: 0.028729042038321495\n",
      "Epoch 17, Iteration 460, Loss: 0.03707578778266907\n",
      "Epoch 17, Iteration 470, Loss: 0.023037303239107132\n",
      "Epoch 17, Iteration 480, Loss: 0.10593628883361816\n",
      "Epoch 17, Iteration 490, Loss: 0.03917195647954941\n",
      "Epoch 17, Iteration 500, Loss: 0.03154272213578224\n",
      "Epoch 17, Iteration 510, Loss: 0.035394854843616486\n",
      "Epoch 17, Iteration 520, Loss: 0.04019200801849365\n",
      "Epoch 17, Iteration 530, Loss: 0.01567792519927025\n",
      "Epoch 17, Iteration 540, Loss: 0.026803813874721527\n",
      "Epoch 17, Iteration 550, Loss: 0.026488790288567543\n",
      "Epoch 17, Iteration 560, Loss: 0.03869974613189697\n",
      "Epoch 17, Iteration 570, Loss: 0.03445233404636383\n",
      "Epoch 17, Iteration 580, Loss: 0.03284253925085068\n",
      "Epoch 17, Iteration 590, Loss: 0.06214575096964836\n",
      "Epoch 17, Iteration 600, Loss: 0.061696622520685196\n",
      "Epoch 17, Iteration 610, Loss: 0.017445815727114677\n",
      "Epoch 17, Iteration 620, Loss: 0.05566967651247978\n",
      "Epoch 17, Iteration 630, Loss: 0.04727243632078171\n",
      "Epoch 17, Iteration 640, Loss: 0.02639632485806942\n",
      "Epoch 17, Iteration 650, Loss: 0.07364639639854431\n",
      "Epoch 17, Iteration 660, Loss: 0.052682455629110336\n",
      "Epoch 17, Iteration 670, Loss: 0.0484500527381897\n",
      "Epoch 17, Iteration 680, Loss: 0.0952501893043518\n",
      "Epoch 17, Iteration 690, Loss: 0.07499712705612183\n",
      "Epoch 17, Iteration 700, Loss: 0.021640272811055183\n",
      "Epoch 17, Iteration 710, Loss: 0.04528730362653732\n",
      "Epoch 17, Iteration 720, Loss: 0.040299832820892334\n",
      "Epoch 17, Iteration 730, Loss: 0.03256281837821007\n",
      "Epoch 17, Validation Loss: 0.04129278433063756\n",
      "Validation loss decreased (0.041300 --> 0.041293). Saving model...\n",
      "Epoch 18, Iteration 0, Loss: 0.030808987095952034\n",
      "Epoch 18, Iteration 10, Loss: 0.04511301964521408\n",
      "Epoch 18, Iteration 20, Loss: 0.03277028724551201\n",
      "Epoch 18, Iteration 30, Loss: 0.03349709510803223\n",
      "Epoch 18, Iteration 40, Loss: 0.029973553493618965\n",
      "Epoch 18, Iteration 50, Loss: 0.02623693086206913\n",
      "Epoch 18, Iteration 60, Loss: 0.0640050619840622\n",
      "Epoch 18, Iteration 70, Loss: 0.046714019030332565\n",
      "Epoch 18, Iteration 80, Loss: 0.01679186522960663\n",
      "Epoch 18, Iteration 90, Loss: 0.037763260304927826\n",
      "Epoch 18, Iteration 100, Loss: 0.0319552905857563\n",
      "Epoch 18, Iteration 110, Loss: 0.0451788529753685\n",
      "Epoch 18, Iteration 120, Loss: 0.0465649850666523\n",
      "Epoch 18, Iteration 130, Loss: 0.06984235346317291\n",
      "Epoch 18, Iteration 140, Loss: 0.05013539269566536\n",
      "Epoch 18, Iteration 150, Loss: 0.05253923311829567\n",
      "Epoch 18, Iteration 160, Loss: 0.06799674779176712\n",
      "Epoch 18, Iteration 170, Loss: 0.0249804500490427\n",
      "Epoch 18, Iteration 180, Loss: 0.07460113614797592\n",
      "Epoch 18, Iteration 190, Loss: 0.0549139678478241\n",
      "Epoch 18, Iteration 200, Loss: 0.05186230316758156\n",
      "Epoch 18, Iteration 210, Loss: 0.057030558586120605\n",
      "Epoch 18, Iteration 220, Loss: 0.04706339165568352\n",
      "Epoch 18, Iteration 230, Loss: 0.036034129559993744\n",
      "Epoch 18, Iteration 240, Loss: 0.035882215946912766\n",
      "Epoch 18, Iteration 250, Loss: 0.032998472452163696\n",
      "Epoch 18, Iteration 260, Loss: 0.039780620485544205\n",
      "Epoch 18, Iteration 270, Loss: 0.056527890264987946\n",
      "Epoch 18, Iteration 280, Loss: 0.03632749989628792\n",
      "Epoch 18, Iteration 290, Loss: 0.06359502673149109\n",
      "Epoch 18, Iteration 300, Loss: 0.08363940566778183\n",
      "Epoch 18, Iteration 310, Loss: 0.03898262977600098\n",
      "Epoch 18, Iteration 320, Loss: 0.029171593487262726\n",
      "Epoch 18, Iteration 330, Loss: 0.036305125802755356\n",
      "Epoch 18, Iteration 340, Loss: 0.025262942537665367\n",
      "Epoch 18, Iteration 350, Loss: 0.06103605777025223\n",
      "Epoch 18, Iteration 360, Loss: 0.07596105337142944\n",
      "Epoch 18, Iteration 370, Loss: 0.0444478802382946\n",
      "Epoch 18, Iteration 380, Loss: 0.07438907772302628\n",
      "Epoch 18, Iteration 390, Loss: 0.021758683025836945\n",
      "Epoch 18, Iteration 400, Loss: 0.07061087340116501\n",
      "Epoch 18, Iteration 410, Loss: 0.04732329398393631\n",
      "Epoch 18, Iteration 420, Loss: 0.09098885208368301\n",
      "Epoch 18, Iteration 430, Loss: 0.0539221316576004\n",
      "Epoch 18, Iteration 440, Loss: 0.01939503662288189\n",
      "Epoch 18, Iteration 450, Loss: 0.04381609335541725\n",
      "Epoch 18, Iteration 460, Loss: 0.0507940948009491\n",
      "Epoch 18, Iteration 470, Loss: 0.038332659751176834\n",
      "Epoch 18, Iteration 480, Loss: 0.06590993702411652\n",
      "Epoch 18, Iteration 490, Loss: 0.03022127039730549\n",
      "Epoch 18, Iteration 500, Loss: 0.03700358048081398\n",
      "Epoch 18, Iteration 510, Loss: 0.05597560107707977\n",
      "Epoch 18, Iteration 520, Loss: 0.06508434563875198\n",
      "Epoch 18, Iteration 530, Loss: 0.058014098554849625\n",
      "Epoch 18, Iteration 540, Loss: 0.07495739310979843\n",
      "Epoch 18, Iteration 550, Loss: 0.040771521627902985\n",
      "Epoch 18, Iteration 560, Loss: 0.08044399321079254\n",
      "Epoch 18, Iteration 570, Loss: 0.05532658472657204\n",
      "Epoch 18, Iteration 580, Loss: 0.056882914155721664\n",
      "Epoch 18, Iteration 590, Loss: 0.0517052598297596\n",
      "Epoch 18, Iteration 600, Loss: 0.02794296108186245\n",
      "Epoch 18, Iteration 610, Loss: 0.06521762162446976\n",
      "Epoch 18, Iteration 620, Loss: 0.01819644682109356\n",
      "Epoch 18, Iteration 630, Loss: 0.041851915419101715\n",
      "Epoch 18, Iteration 640, Loss: 0.08236617594957352\n",
      "Epoch 18, Iteration 650, Loss: 0.04015686735510826\n",
      "Epoch 18, Iteration 660, Loss: 0.05538121983408928\n",
      "Epoch 18, Iteration 670, Loss: 0.031316593289375305\n",
      "Epoch 18, Iteration 680, Loss: 0.06969629973173141\n",
      "Epoch 18, Iteration 690, Loss: 0.032933786511421204\n",
      "Epoch 18, Iteration 700, Loss: 0.04280983656644821\n",
      "Epoch 18, Iteration 710, Loss: 0.02312091924250126\n",
      "Epoch 18, Iteration 720, Loss: 0.03906260430812836\n",
      "Epoch 18, Iteration 730, Loss: 0.07712913304567337\n",
      "Epoch 18, Validation Loss: 0.04132552027864301\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 19, Iteration 0, Loss: 0.04564040154218674\n",
      "Epoch 19, Iteration 10, Loss: 0.02893621101975441\n",
      "Epoch 19, Iteration 20, Loss: 0.04295939952135086\n",
      "Epoch 19, Iteration 30, Loss: 0.07001926004886627\n",
      "Epoch 19, Iteration 40, Loss: 0.09654570370912552\n",
      "Epoch 19, Iteration 50, Loss: 0.03269689157605171\n",
      "Epoch 19, Iteration 60, Loss: 0.035213034600019455\n",
      "Epoch 19, Iteration 70, Loss: 0.05244035646319389\n",
      "Epoch 19, Iteration 80, Loss: 0.04484379291534424\n",
      "Epoch 19, Iteration 90, Loss: 0.03005583956837654\n",
      "Epoch 19, Iteration 100, Loss: 0.08043670654296875\n",
      "Epoch 19, Iteration 110, Loss: 0.08428393304347992\n",
      "Epoch 19, Iteration 120, Loss: 0.04533105716109276\n",
      "Epoch 19, Iteration 130, Loss: 0.047977905720472336\n",
      "Epoch 19, Iteration 140, Loss: 0.05724888667464256\n",
      "Epoch 19, Iteration 150, Loss: 0.0521121621131897\n",
      "Epoch 19, Iteration 160, Loss: 0.05453299358487129\n",
      "Epoch 19, Iteration 170, Loss: 0.04532694071531296\n",
      "Epoch 19, Iteration 180, Loss: 0.043324898928403854\n",
      "Epoch 19, Iteration 190, Loss: 0.08737098425626755\n",
      "Epoch 19, Iteration 200, Loss: 0.06507925689220428\n",
      "Epoch 19, Iteration 210, Loss: 0.05044927820563316\n",
      "Epoch 19, Iteration 220, Loss: 0.02521304227411747\n",
      "Epoch 19, Iteration 230, Loss: 0.026541216298937798\n",
      "Epoch 19, Iteration 240, Loss: 0.022554675117135048\n",
      "Epoch 19, Iteration 250, Loss: 0.04922430217266083\n",
      "Epoch 19, Iteration 260, Loss: 0.014292455278337002\n",
      "Epoch 19, Iteration 270, Loss: 0.06430025398731232\n",
      "Epoch 19, Iteration 280, Loss: 0.04629955813288689\n",
      "Epoch 19, Iteration 290, Loss: 0.040242187678813934\n",
      "Epoch 19, Iteration 300, Loss: 0.059669408947229385\n",
      "Epoch 19, Iteration 310, Loss: 0.04259053245186806\n",
      "Epoch 19, Iteration 320, Loss: 0.02301628701388836\n",
      "Epoch 19, Iteration 330, Loss: 0.09558742493391037\n",
      "Epoch 19, Iteration 340, Loss: 0.05313105508685112\n",
      "Epoch 19, Iteration 350, Loss: 0.05689341202378273\n",
      "Epoch 19, Iteration 360, Loss: 0.05229967460036278\n",
      "Epoch 19, Iteration 370, Loss: 0.043605972081422806\n",
      "Epoch 19, Iteration 380, Loss: 0.02459116093814373\n",
      "Epoch 19, Iteration 390, Loss: 0.03578130528330803\n",
      "Epoch 19, Iteration 400, Loss: 0.0826193317770958\n",
      "Epoch 19, Iteration 410, Loss: 0.04380332678556442\n",
      "Epoch 19, Iteration 420, Loss: 0.024502241984009743\n",
      "Epoch 19, Iteration 430, Loss: 0.031028661876916885\n",
      "Epoch 19, Iteration 440, Loss: 0.048840757459402084\n",
      "Epoch 19, Iteration 450, Loss: 0.08723011612892151\n",
      "Epoch 19, Iteration 460, Loss: 0.06918554753065109\n",
      "Epoch 19, Iteration 470, Loss: 0.023709693923592567\n",
      "Epoch 19, Iteration 480, Loss: 0.03373514860868454\n",
      "Epoch 19, Iteration 490, Loss: 0.051722630858421326\n",
      "Epoch 19, Iteration 500, Loss: 0.041590746492147446\n",
      "Epoch 19, Iteration 510, Loss: 0.05619493126869202\n",
      "Epoch 19, Iteration 520, Loss: 0.0825137048959732\n",
      "Epoch 19, Iteration 530, Loss: 0.015179003588855267\n",
      "Epoch 19, Iteration 540, Loss: 0.01849536970257759\n",
      "Epoch 19, Iteration 550, Loss: 0.06285063922405243\n",
      "Epoch 19, Iteration 560, Loss: 0.038069263100624084\n",
      "Epoch 19, Iteration 570, Loss: 0.06992542743682861\n",
      "Epoch 19, Iteration 580, Loss: 0.03413281589746475\n",
      "Epoch 19, Iteration 590, Loss: 0.04758632928133011\n",
      "Epoch 19, Iteration 600, Loss: 0.03564945608377457\n",
      "Epoch 19, Iteration 610, Loss: 0.05972444266080856\n",
      "Epoch 19, Iteration 620, Loss: 0.05337214097380638\n",
      "Epoch 19, Iteration 630, Loss: 0.03991547226905823\n",
      "Epoch 19, Iteration 640, Loss: 0.047454383224248886\n",
      "Epoch 19, Iteration 650, Loss: 0.10056716203689575\n",
      "Epoch 19, Iteration 660, Loss: 0.04364690184593201\n",
      "Epoch 19, Iteration 670, Loss: 0.046714842319488525\n",
      "Epoch 19, Iteration 680, Loss: 0.04043067619204521\n",
      "Epoch 19, Iteration 690, Loss: 0.05567466840147972\n",
      "Epoch 19, Iteration 700, Loss: 0.07116539031267166\n",
      "Epoch 19, Iteration 710, Loss: 0.0632690042257309\n",
      "Epoch 19, Iteration 720, Loss: 0.030089806765317917\n",
      "Epoch 19, Iteration 730, Loss: 0.0634903758764267\n",
      "Epoch 19, Validation Loss: 0.04126035976831032\n",
      "Validation loss decreased (0.041293 --> 0.041260). Saving model...\n",
      "Epoch 20, Iteration 0, Loss: 0.0489223450422287\n",
      "Epoch 20, Iteration 10, Loss: 0.057368457317352295\n",
      "Epoch 20, Iteration 20, Loss: 0.04556041210889816\n",
      "Epoch 20, Iteration 30, Loss: 0.021770499646663666\n",
      "Epoch 20, Iteration 40, Loss: 0.05547164008021355\n",
      "Epoch 20, Iteration 50, Loss: 0.029092619195580482\n",
      "Epoch 20, Iteration 60, Loss: 0.05452536419034004\n",
      "Epoch 20, Iteration 70, Loss: 0.03054840862751007\n",
      "Epoch 20, Iteration 80, Loss: 0.04321954399347305\n",
      "Epoch 20, Iteration 90, Loss: 0.04091805964708328\n",
      "Epoch 20, Iteration 100, Loss: 0.035199668258428574\n",
      "Epoch 20, Iteration 110, Loss: 0.036517247557640076\n",
      "Epoch 20, Iteration 120, Loss: 0.05608294531702995\n",
      "Epoch 20, Iteration 130, Loss: 0.028082311153411865\n",
      "Epoch 20, Iteration 140, Loss: 0.037096086889505386\n",
      "Epoch 20, Iteration 150, Loss: 0.043903034180402756\n",
      "Epoch 20, Iteration 160, Loss: 0.03216049447655678\n",
      "Epoch 20, Iteration 170, Loss: 0.03920341655611992\n",
      "Epoch 20, Iteration 180, Loss: 0.024245599284768105\n",
      "Epoch 20, Iteration 190, Loss: 0.03366768732666969\n",
      "Epoch 20, Iteration 200, Loss: 0.06478050351142883\n",
      "Epoch 20, Iteration 210, Loss: 0.03265543654561043\n",
      "Epoch 20, Iteration 220, Loss: 0.029549090191721916\n",
      "Epoch 20, Iteration 230, Loss: 0.05319465324282646\n",
      "Epoch 20, Iteration 240, Loss: 0.03483709692955017\n",
      "Epoch 20, Iteration 250, Loss: 0.03410785272717476\n",
      "Epoch 20, Iteration 260, Loss: 0.038871776312589645\n",
      "Epoch 20, Iteration 270, Loss: 0.04027453437447548\n",
      "Epoch 20, Iteration 280, Loss: 0.047059718519449234\n",
      "Epoch 20, Iteration 290, Loss: 0.04166568070650101\n",
      "Epoch 20, Iteration 300, Loss: 0.030322784557938576\n",
      "Epoch 20, Iteration 310, Loss: 0.05696798115968704\n",
      "Epoch 20, Iteration 320, Loss: 0.013091977685689926\n",
      "Epoch 20, Iteration 330, Loss: 0.043147869408130646\n",
      "Epoch 20, Iteration 340, Loss: 0.032551202923059464\n",
      "Epoch 20, Iteration 350, Loss: 0.04763129726052284\n",
      "Epoch 20, Iteration 360, Loss: 0.07052452117204666\n",
      "Epoch 20, Iteration 370, Loss: 0.03864069655537605\n",
      "Epoch 20, Iteration 380, Loss: 0.06680518388748169\n",
      "Epoch 20, Iteration 390, Loss: 0.05463927611708641\n",
      "Epoch 20, Iteration 400, Loss: 0.02197805792093277\n",
      "Epoch 20, Iteration 410, Loss: 0.026196368038654327\n",
      "Epoch 20, Iteration 420, Loss: 0.03335612267255783\n",
      "Epoch 20, Iteration 430, Loss: 0.04251231625676155\n",
      "Epoch 20, Iteration 440, Loss: 0.07650183886289597\n",
      "Epoch 20, Iteration 450, Loss: 0.0422750785946846\n",
      "Epoch 20, Iteration 460, Loss: 0.026895970106124878\n",
      "Epoch 20, Iteration 470, Loss: 0.04205235093832016\n",
      "Epoch 20, Iteration 480, Loss: 0.03826834261417389\n",
      "Epoch 20, Iteration 490, Loss: 0.0822581872344017\n",
      "Epoch 20, Iteration 500, Loss: 0.04212595522403717\n",
      "Epoch 20, Iteration 510, Loss: 0.03353062644600868\n",
      "Epoch 20, Iteration 520, Loss: 0.03217560052871704\n",
      "Epoch 20, Iteration 530, Loss: 0.03381427004933357\n",
      "Epoch 20, Iteration 540, Loss: 0.03629226237535477\n",
      "Epoch 20, Iteration 550, Loss: 0.04453076794743538\n",
      "Epoch 20, Iteration 560, Loss: 0.051231469959020615\n",
      "Epoch 20, Iteration 570, Loss: 0.027562640607357025\n",
      "Epoch 20, Iteration 580, Loss: 0.025160381570458412\n",
      "Epoch 20, Iteration 590, Loss: 0.03497951105237007\n",
      "Epoch 20, Iteration 600, Loss: 0.054072972387075424\n",
      "Epoch 20, Iteration 610, Loss: 0.02658887580037117\n",
      "Epoch 20, Iteration 620, Loss: 0.035536762326955795\n",
      "Epoch 20, Iteration 630, Loss: 0.06924840062856674\n",
      "Epoch 20, Iteration 640, Loss: 0.05957368016242981\n",
      "Epoch 20, Iteration 650, Loss: 0.024484332650899887\n",
      "Epoch 20, Iteration 660, Loss: 0.04979957640171051\n",
      "Epoch 20, Iteration 670, Loss: 0.045621518045663834\n",
      "Epoch 20, Iteration 680, Loss: 0.03437595069408417\n",
      "Epoch 20, Iteration 690, Loss: 0.05535709857940674\n",
      "Epoch 20, Iteration 700, Loss: 0.02945421077311039\n",
      "Epoch 20, Iteration 710, Loss: 0.08223439007997513\n",
      "Epoch 20, Iteration 720, Loss: 0.08790025115013123\n",
      "Epoch 20, Iteration 730, Loss: 0.03363923355937004\n",
      "Epoch 20, Validation Loss: 0.041265102376675473\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 21, Iteration 0, Loss: 0.035248227417469025\n",
      "Epoch 21, Iteration 10, Loss: 0.09729162603616714\n",
      "Epoch 21, Iteration 20, Loss: 0.03714296594262123\n",
      "Epoch 21, Iteration 30, Loss: 0.05149180814623833\n",
      "Epoch 21, Iteration 40, Loss: 0.04235725849866867\n",
      "Epoch 21, Iteration 50, Loss: 0.0494372621178627\n",
      "Epoch 21, Iteration 60, Loss: 0.04704225808382034\n",
      "Epoch 21, Iteration 70, Loss: 0.0337308831512928\n",
      "Epoch 21, Iteration 80, Loss: 0.0442606620490551\n",
      "Epoch 21, Iteration 90, Loss: 0.058919619768857956\n",
      "Epoch 21, Iteration 100, Loss: 0.04050592705607414\n",
      "Epoch 21, Iteration 110, Loss: 0.046514321118593216\n",
      "Epoch 21, Iteration 120, Loss: 0.03988637775182724\n",
      "Epoch 21, Iteration 130, Loss: 0.034974005073308945\n",
      "Epoch 21, Iteration 140, Loss: 0.028991715982556343\n",
      "Epoch 21, Iteration 150, Loss: 0.04164201393723488\n",
      "Epoch 21, Iteration 160, Loss: 0.03155126795172691\n",
      "Epoch 21, Iteration 170, Loss: 0.03813890367746353\n",
      "Epoch 21, Iteration 180, Loss: 0.047983501106500626\n",
      "Epoch 21, Iteration 190, Loss: 0.02704291231930256\n",
      "Epoch 21, Iteration 200, Loss: 0.039308514446020126\n",
      "Epoch 21, Iteration 210, Loss: 0.032022371888160706\n",
      "Epoch 21, Iteration 220, Loss: 0.021007750183343887\n",
      "Epoch 21, Iteration 230, Loss: 0.018391257151961327\n",
      "Epoch 21, Iteration 240, Loss: 0.03685860335826874\n",
      "Epoch 21, Iteration 250, Loss: 0.04693669453263283\n",
      "Epoch 21, Iteration 260, Loss: 0.027864031493663788\n",
      "Epoch 21, Iteration 270, Loss: 0.020889941602945328\n",
      "Epoch 21, Iteration 280, Loss: 0.035577964037656784\n",
      "Epoch 21, Iteration 290, Loss: 0.03594198450446129\n",
      "Epoch 21, Iteration 300, Loss: 0.01438764575868845\n",
      "Epoch 21, Iteration 310, Loss: 0.029625285416841507\n",
      "Epoch 21, Iteration 320, Loss: 0.05558786913752556\n",
      "Epoch 21, Iteration 330, Loss: 0.02014090307056904\n",
      "Epoch 21, Iteration 340, Loss: 0.05532455816864967\n",
      "Epoch 21, Iteration 350, Loss: 0.03723856434226036\n",
      "Epoch 21, Iteration 360, Loss: 0.036629047244787216\n",
      "Epoch 21, Iteration 370, Loss: 0.032141730189323425\n",
      "Epoch 21, Iteration 380, Loss: 0.021188462153077126\n",
      "Epoch 21, Iteration 390, Loss: 0.0425504706799984\n",
      "Epoch 21, Iteration 400, Loss: 0.023016469553112984\n",
      "Epoch 21, Iteration 410, Loss: 0.03948229178786278\n",
      "Epoch 21, Iteration 420, Loss: 0.016226837411522865\n",
      "Epoch 21, Iteration 430, Loss: 0.0900251492857933\n",
      "Epoch 21, Iteration 440, Loss: 0.025221724063158035\n",
      "Epoch 21, Iteration 450, Loss: 0.036880359053611755\n",
      "Epoch 21, Iteration 460, Loss: 0.04632280021905899\n",
      "Epoch 21, Iteration 470, Loss: 0.02799738384783268\n",
      "Epoch 21, Iteration 480, Loss: 0.04511934891343117\n",
      "Epoch 21, Iteration 490, Loss: 0.022415004670619965\n",
      "Epoch 21, Iteration 500, Loss: 0.01951529271900654\n",
      "Epoch 21, Iteration 510, Loss: 0.0356731079518795\n",
      "Epoch 21, Iteration 520, Loss: 0.032013218849897385\n",
      "Epoch 21, Iteration 530, Loss: 0.02566453255712986\n",
      "Epoch 21, Iteration 540, Loss: 0.039338164031505585\n",
      "Epoch 21, Iteration 550, Loss: 0.041467465460300446\n",
      "Epoch 21, Iteration 560, Loss: 0.032762836664915085\n",
      "Epoch 21, Iteration 570, Loss: 0.06610555201768875\n",
      "Epoch 21, Iteration 580, Loss: 0.03303857520222664\n",
      "Epoch 21, Iteration 590, Loss: 0.032800544053316116\n",
      "Epoch 21, Iteration 600, Loss: 0.026628462597727776\n",
      "Epoch 21, Iteration 610, Loss: 0.01928102597594261\n",
      "Epoch 21, Iteration 620, Loss: 0.031340938061475754\n",
      "Epoch 21, Iteration 630, Loss: 0.03046150505542755\n",
      "Epoch 21, Iteration 640, Loss: 0.038543451577425\n",
      "Epoch 21, Iteration 650, Loss: 0.06671028584241867\n",
      "Epoch 21, Iteration 660, Loss: 0.03411729633808136\n",
      "Epoch 21, Iteration 670, Loss: 0.04174506291747093\n",
      "Epoch 21, Iteration 680, Loss: 0.03922560438513756\n",
      "Epoch 21, Iteration 690, Loss: 0.05753953009843826\n",
      "Epoch 21, Iteration 700, Loss: 0.024183830246329308\n",
      "Epoch 21, Iteration 710, Loss: 0.05769069120287895\n",
      "Epoch 21, Iteration 720, Loss: 0.12343823164701462\n",
      "Epoch 21, Iteration 730, Loss: 0.03524888679385185\n",
      "Epoch 21, Validation Loss: 0.04125250331328615\n",
      "Validation loss decreased (0.041260 --> 0.041253). Saving model...\n",
      "Epoch 22, Iteration 0, Loss: 0.03707354515790939\n",
      "Epoch 22, Iteration 10, Loss: 0.031820908188819885\n",
      "Epoch 22, Iteration 20, Loss: 0.023586418479681015\n",
      "Epoch 22, Iteration 30, Loss: 0.053939152508974075\n",
      "Epoch 22, Iteration 40, Loss: 0.04655153304338455\n",
      "Epoch 22, Iteration 50, Loss: 0.03457288816571236\n",
      "Epoch 22, Iteration 60, Loss: 0.051461100578308105\n",
      "Epoch 22, Iteration 70, Loss: 0.03658227622509003\n",
      "Epoch 22, Iteration 80, Loss: 0.06237155571579933\n",
      "Epoch 22, Iteration 90, Loss: 0.05122048035264015\n",
      "Epoch 22, Iteration 100, Loss: 0.01878412812948227\n",
      "Epoch 22, Iteration 110, Loss: 0.04715992510318756\n",
      "Epoch 22, Iteration 120, Loss: 0.0648420974612236\n",
      "Epoch 22, Iteration 130, Loss: 0.09445875883102417\n",
      "Epoch 22, Iteration 140, Loss: 0.03624880313873291\n",
      "Epoch 22, Iteration 150, Loss: 0.023511776700615883\n",
      "Epoch 22, Iteration 160, Loss: 0.03070688620209694\n",
      "Epoch 22, Iteration 170, Loss: 0.03742754086852074\n",
      "Epoch 22, Iteration 180, Loss: 0.02991902083158493\n",
      "Epoch 22, Iteration 190, Loss: 0.07316241413354874\n",
      "Epoch 22, Iteration 200, Loss: 0.12696672976016998\n",
      "Epoch 22, Iteration 210, Loss: 0.02831805869936943\n",
      "Epoch 22, Iteration 220, Loss: 0.03467196598649025\n",
      "Epoch 22, Iteration 230, Loss: 0.054487474262714386\n",
      "Epoch 22, Iteration 240, Loss: 0.050233032554388046\n",
      "Epoch 22, Iteration 250, Loss: 0.058448418974876404\n",
      "Epoch 22, Iteration 260, Loss: 0.04726053401827812\n",
      "Epoch 22, Iteration 270, Loss: 0.07203957438468933\n",
      "Epoch 22, Iteration 280, Loss: 0.06470645219087601\n",
      "Epoch 22, Iteration 290, Loss: 0.029834484681487083\n",
      "Epoch 22, Iteration 300, Loss: 0.0397682711482048\n",
      "Epoch 22, Iteration 310, Loss: 0.037471722811460495\n",
      "Epoch 22, Iteration 320, Loss: 0.033158525824546814\n",
      "Epoch 22, Iteration 330, Loss: 0.04387065768241882\n",
      "Epoch 22, Iteration 340, Loss: 0.058484070003032684\n",
      "Epoch 22, Iteration 350, Loss: 0.02998499944806099\n",
      "Epoch 22, Iteration 360, Loss: 0.05283643677830696\n",
      "Epoch 22, Iteration 370, Loss: 0.04705999791622162\n",
      "Epoch 22, Iteration 380, Loss: 0.06652305275201797\n",
      "Epoch 22, Iteration 390, Loss: 0.029301531612873077\n",
      "Epoch 22, Iteration 400, Loss: 0.05101843923330307\n",
      "Epoch 22, Iteration 410, Loss: 0.04049559682607651\n",
      "Epoch 22, Iteration 420, Loss: 0.03813835605978966\n",
      "Epoch 22, Iteration 430, Loss: 0.035219840705394745\n",
      "Epoch 22, Iteration 440, Loss: 0.02346336841583252\n",
      "Epoch 22, Iteration 450, Loss: 0.030304869636893272\n",
      "Epoch 22, Iteration 460, Loss: 0.08701122552156448\n",
      "Epoch 22, Iteration 470, Loss: 0.039411235600709915\n",
      "Epoch 22, Iteration 480, Loss: 0.035235434770584106\n",
      "Epoch 22, Iteration 490, Loss: 0.03292055055499077\n",
      "Epoch 22, Iteration 500, Loss: 0.04884050041437149\n",
      "Epoch 22, Iteration 510, Loss: 0.04585171490907669\n",
      "Epoch 22, Iteration 520, Loss: 0.038844019174575806\n",
      "Epoch 22, Iteration 530, Loss: 0.023890437558293343\n",
      "Epoch 22, Iteration 540, Loss: 0.028758009895682335\n",
      "Epoch 22, Iteration 550, Loss: 0.048938848078250885\n",
      "Epoch 22, Iteration 560, Loss: 0.07634761929512024\n",
      "Epoch 22, Iteration 570, Loss: 0.06558966636657715\n",
      "Epoch 22, Iteration 580, Loss: 0.0603984110057354\n",
      "Epoch 22, Iteration 590, Loss: 0.02029990404844284\n",
      "Epoch 22, Iteration 600, Loss: 0.049468524754047394\n",
      "Epoch 22, Iteration 610, Loss: 0.032420117408037186\n",
      "Epoch 22, Iteration 620, Loss: 0.052893638610839844\n",
      "Epoch 22, Iteration 630, Loss: 0.023890577256679535\n",
      "Epoch 22, Iteration 640, Loss: 0.030840251594781876\n",
      "Epoch 22, Iteration 650, Loss: 0.02978726103901863\n",
      "Epoch 22, Iteration 660, Loss: 0.017772316932678223\n",
      "Epoch 22, Iteration 670, Loss: 0.040480319410562515\n",
      "Epoch 22, Iteration 680, Loss: 0.04990019276738167\n",
      "Epoch 22, Iteration 690, Loss: 0.036029305309057236\n",
      "Epoch 22, Iteration 700, Loss: 0.048215415328741074\n",
      "Epoch 22, Iteration 710, Loss: 0.04234788566827774\n",
      "Epoch 22, Iteration 720, Loss: 0.028246864676475525\n",
      "Epoch 22, Iteration 730, Loss: 0.054168701171875\n",
      "Epoch 22, Validation Loss: 0.04125264396324106\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 23, Iteration 0, Loss: 0.01878325827419758\n",
      "Epoch 23, Iteration 10, Loss: 0.04142560809850693\n",
      "Epoch 23, Iteration 20, Loss: 0.06618302315473557\n",
      "Epoch 23, Iteration 30, Loss: 0.049209896475076675\n",
      "Epoch 23, Iteration 40, Loss: 0.05288226902484894\n",
      "Epoch 23, Iteration 50, Loss: 0.032602954655885696\n",
      "Epoch 23, Iteration 60, Loss: 0.06493420153856277\n",
      "Epoch 23, Iteration 70, Loss: 0.04615730419754982\n",
      "Epoch 23, Iteration 80, Loss: 0.05133705958724022\n",
      "Epoch 23, Iteration 90, Loss: 0.039023011922836304\n",
      "Epoch 23, Iteration 100, Loss: 0.030662141740322113\n",
      "Epoch 23, Iteration 110, Loss: 0.03348635882139206\n",
      "Epoch 23, Iteration 120, Loss: 0.029539404436945915\n",
      "Epoch 23, Iteration 130, Loss: 0.03232421353459358\n",
      "Epoch 23, Iteration 140, Loss: 0.021295033395290375\n",
      "Epoch 23, Iteration 150, Loss: 0.04664225876331329\n",
      "Epoch 23, Iteration 160, Loss: 0.04431983083486557\n",
      "Epoch 23, Iteration 170, Loss: 0.029048625379800797\n",
      "Epoch 23, Iteration 180, Loss: 0.06592357903718948\n",
      "Epoch 23, Iteration 190, Loss: 0.07255437970161438\n",
      "Epoch 23, Iteration 200, Loss: 0.037283118814229965\n",
      "Epoch 23, Iteration 210, Loss: 0.023244405165314674\n",
      "Epoch 23, Iteration 220, Loss: 0.04757101461291313\n",
      "Epoch 23, Iteration 230, Loss: 0.049627624452114105\n",
      "Epoch 23, Iteration 240, Loss: 0.03487195074558258\n",
      "Epoch 23, Iteration 250, Loss: 0.03461143746972084\n",
      "Epoch 23, Iteration 260, Loss: 0.02851058915257454\n",
      "Epoch 23, Iteration 270, Loss: 0.027385549619793892\n",
      "Epoch 23, Iteration 280, Loss: 0.028287148103117943\n",
      "Epoch 23, Iteration 290, Loss: 0.019968904554843903\n",
      "Epoch 23, Iteration 300, Loss: 0.04626457765698433\n",
      "Epoch 23, Iteration 310, Loss: 0.03267945349216461\n",
      "Epoch 23, Iteration 320, Loss: 0.05419948697090149\n",
      "Epoch 23, Iteration 330, Loss: 0.03984412923455238\n",
      "Epoch 23, Iteration 340, Loss: 0.03582014515995979\n",
      "Epoch 23, Iteration 350, Loss: 0.05393514782190323\n",
      "Epoch 23, Iteration 360, Loss: 0.04844832420349121\n",
      "Epoch 23, Iteration 370, Loss: 0.04749481752514839\n",
      "Epoch 23, Iteration 380, Loss: 0.027775762602686882\n",
      "Epoch 23, Iteration 390, Loss: 0.036928702145814896\n",
      "Epoch 23, Iteration 400, Loss: 0.030403735116124153\n",
      "Epoch 23, Iteration 410, Loss: 0.05186636745929718\n",
      "Epoch 23, Iteration 420, Loss: 0.05293413996696472\n",
      "Epoch 23, Iteration 430, Loss: 0.022079065442085266\n",
      "Epoch 23, Iteration 440, Loss: 0.051730554550886154\n",
      "Epoch 23, Iteration 450, Loss: 0.021814152598381042\n",
      "Epoch 23, Iteration 460, Loss: 0.03428134694695473\n",
      "Epoch 23, Iteration 470, Loss: 0.04173174500465393\n",
      "Epoch 23, Iteration 480, Loss: 0.03347059339284897\n",
      "Epoch 23, Iteration 490, Loss: 0.029756279662251472\n",
      "Epoch 23, Iteration 500, Loss: 0.05429687350988388\n",
      "Epoch 23, Iteration 510, Loss: 0.05681678280234337\n",
      "Epoch 23, Iteration 520, Loss: 0.05165928229689598\n",
      "Epoch 23, Iteration 530, Loss: 0.029885530471801758\n",
      "Epoch 23, Iteration 540, Loss: 0.05832422897219658\n",
      "Epoch 23, Iteration 550, Loss: 0.07851144671440125\n",
      "Epoch 23, Iteration 560, Loss: 0.04595669358968735\n",
      "Epoch 23, Iteration 570, Loss: 0.026652395725250244\n",
      "Epoch 23, Iteration 580, Loss: 0.017340779304504395\n",
      "Epoch 23, Iteration 590, Loss: 0.05728118121623993\n",
      "Epoch 23, Iteration 600, Loss: 0.0852610245347023\n",
      "Epoch 23, Iteration 610, Loss: 0.07013218849897385\n",
      "Epoch 23, Iteration 620, Loss: 0.0486251600086689\n",
      "Epoch 23, Iteration 630, Loss: 0.03553777560591698\n",
      "Epoch 23, Iteration 640, Loss: 0.042669087648391724\n",
      "Epoch 23, Iteration 650, Loss: 0.05161755904555321\n",
      "Epoch 23, Iteration 660, Loss: 0.029706507921218872\n",
      "Epoch 23, Iteration 670, Loss: 0.024387193843722343\n",
      "Epoch 23, Iteration 680, Loss: 0.034090057015419006\n",
      "Epoch 23, Iteration 690, Loss: 0.033627577126026154\n",
      "Epoch 23, Iteration 700, Loss: 0.07123275846242905\n",
      "Epoch 23, Iteration 710, Loss: 0.036662518978118896\n",
      "Epoch 23, Iteration 720, Loss: 0.026269273832440376\n",
      "Epoch 23, Iteration 730, Loss: 0.04687248542904854\n",
      "Epoch 23, Validation Loss: 0.04124647694761339\n",
      "Validation loss decreased (0.041253 --> 0.041246). Saving model...\n",
      "Epoch 24, Iteration 0, Loss: 0.03298327699303627\n",
      "Epoch 24, Iteration 10, Loss: 0.04451420158147812\n",
      "Epoch 24, Iteration 20, Loss: 0.01580650359392166\n",
      "Epoch 24, Iteration 30, Loss: 0.052919402718544006\n",
      "Epoch 24, Iteration 40, Loss: 0.05970107764005661\n",
      "Epoch 24, Iteration 50, Loss: 0.05710326507687569\n",
      "Epoch 24, Iteration 60, Loss: 0.024112075567245483\n",
      "Epoch 24, Iteration 70, Loss: 0.033560365438461304\n",
      "Epoch 24, Iteration 80, Loss: 0.043161120265722275\n",
      "Epoch 24, Iteration 90, Loss: 0.039290137588977814\n",
      "Epoch 24, Iteration 100, Loss: 0.052547387778759\n",
      "Epoch 24, Iteration 110, Loss: 0.06339072436094284\n",
      "Epoch 24, Iteration 120, Loss: 0.0471748411655426\n",
      "Epoch 24, Iteration 130, Loss: 0.06336914747953415\n",
      "Epoch 24, Iteration 140, Loss: 0.09905338287353516\n",
      "Epoch 24, Iteration 150, Loss: 0.03537161275744438\n",
      "Epoch 24, Iteration 160, Loss: 0.024873806163668633\n",
      "Epoch 24, Iteration 170, Loss: 0.055092453956604004\n",
      "Epoch 24, Iteration 180, Loss: 0.049317050725221634\n",
      "Epoch 24, Iteration 190, Loss: 0.046416040509939194\n",
      "Epoch 24, Iteration 200, Loss: 0.037266772240400314\n",
      "Epoch 24, Iteration 210, Loss: 0.07498916238546371\n",
      "Epoch 24, Iteration 220, Loss: 0.026096327230334282\n",
      "Epoch 24, Iteration 230, Loss: 0.055341336876153946\n",
      "Epoch 24, Iteration 240, Loss: 0.06600486487150192\n",
      "Epoch 24, Iteration 250, Loss: 0.026981115341186523\n",
      "Epoch 24, Iteration 260, Loss: 0.048426102846860886\n",
      "Epoch 24, Iteration 270, Loss: 0.0159284770488739\n",
      "Epoch 24, Iteration 280, Loss: 0.030844176188111305\n",
      "Epoch 24, Iteration 290, Loss: 0.05528445914387703\n",
      "Epoch 24, Iteration 300, Loss: 0.037188854068517685\n",
      "Epoch 24, Iteration 310, Loss: 0.038310468196868896\n",
      "Epoch 24, Iteration 320, Loss: 0.04319896921515465\n",
      "Epoch 24, Iteration 330, Loss: 0.04444849118590355\n",
      "Epoch 24, Iteration 340, Loss: 0.04648292064666748\n",
      "Epoch 24, Iteration 350, Loss: 0.028394557535648346\n",
      "Epoch 24, Iteration 360, Loss: 0.032403528690338135\n",
      "Epoch 24, Iteration 370, Loss: 0.03038164973258972\n",
      "Epoch 24, Iteration 380, Loss: 0.04042699560523033\n",
      "Epoch 24, Iteration 390, Loss: 0.04960041865706444\n",
      "Epoch 24, Iteration 400, Loss: 0.034588124603033066\n",
      "Epoch 24, Iteration 410, Loss: 0.04768138378858566\n",
      "Epoch 24, Iteration 420, Loss: 0.03494380787014961\n",
      "Epoch 24, Iteration 430, Loss: 0.036633070558309555\n",
      "Epoch 24, Iteration 440, Loss: 0.03413025289773941\n",
      "Epoch 24, Iteration 450, Loss: 0.04030375927686691\n",
      "Epoch 24, Iteration 460, Loss: 0.04808459430932999\n",
      "Epoch 24, Iteration 470, Loss: 0.024080758914351463\n",
      "Epoch 24, Iteration 480, Loss: 0.037718515843153\n",
      "Epoch 24, Iteration 490, Loss: 0.0216179508715868\n",
      "Epoch 24, Iteration 500, Loss: 0.027625475078821182\n",
      "Epoch 24, Iteration 510, Loss: 0.03613375872373581\n",
      "Epoch 24, Iteration 520, Loss: 0.07999379187822342\n",
      "Epoch 24, Iteration 530, Loss: 0.033152710646390915\n",
      "Epoch 24, Iteration 540, Loss: 0.03942839428782463\n",
      "Epoch 24, Iteration 550, Loss: 0.03512869402766228\n",
      "Epoch 24, Iteration 560, Loss: 0.01712491549551487\n",
      "Epoch 24, Iteration 570, Loss: 0.03175028786063194\n",
      "Epoch 24, Iteration 580, Loss: 0.06001812592148781\n",
      "Epoch 24, Iteration 590, Loss: 0.028676079586148262\n",
      "Epoch 24, Iteration 600, Loss: 0.04901041090488434\n",
      "Epoch 24, Iteration 610, Loss: 0.021471325308084488\n",
      "Epoch 24, Iteration 620, Loss: 0.05231555178761482\n",
      "Epoch 24, Iteration 630, Loss: 0.04196112975478172\n",
      "Epoch 24, Iteration 640, Loss: 0.04869328439235687\n",
      "Epoch 24, Iteration 650, Loss: 0.030613046139478683\n",
      "Epoch 24, Iteration 660, Loss: 0.041230395436286926\n",
      "Epoch 24, Iteration 670, Loss: 0.03321048989892006\n",
      "Epoch 24, Iteration 680, Loss: 0.08056310564279556\n",
      "Epoch 24, Iteration 690, Loss: 0.01857755146920681\n",
      "Epoch 24, Iteration 700, Loss: 0.03831210359930992\n",
      "Epoch 24, Iteration 710, Loss: 0.0295735951513052\n",
      "Epoch 24, Iteration 720, Loss: 0.02910437248647213\n",
      "Epoch 24, Iteration 730, Loss: 0.04664053022861481\n",
      "Epoch 24, Validation Loss: 0.041254582470687834\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 25, Iteration 0, Loss: 0.05091920495033264\n",
      "Epoch 25, Iteration 10, Loss: 0.05022163689136505\n",
      "Epoch 25, Iteration 20, Loss: 0.047619037330150604\n",
      "Epoch 25, Iteration 30, Loss: 0.029787596315145493\n",
      "Epoch 25, Iteration 40, Loss: 0.030588356778025627\n",
      "Epoch 25, Iteration 50, Loss: 0.07829762995243073\n",
      "Epoch 25, Iteration 60, Loss: 0.06340327858924866\n",
      "Epoch 25, Iteration 70, Loss: 0.07396934926509857\n",
      "Epoch 25, Iteration 80, Loss: 0.06587601453065872\n",
      "Epoch 25, Iteration 90, Loss: 0.027678191661834717\n",
      "Epoch 25, Iteration 100, Loss: 0.06532616168260574\n",
      "Epoch 25, Iteration 110, Loss: 0.09457803517580032\n",
      "Epoch 25, Iteration 120, Loss: 0.031089959666132927\n",
      "Epoch 25, Iteration 130, Loss: 0.024252688512206078\n",
      "Epoch 25, Iteration 140, Loss: 0.030660850927233696\n",
      "Epoch 25, Iteration 150, Loss: 0.019281752407550812\n",
      "Epoch 25, Iteration 160, Loss: 0.03274413198232651\n",
      "Epoch 25, Iteration 170, Loss: 0.03915270417928696\n",
      "Epoch 25, Iteration 180, Loss: 0.051431529223918915\n",
      "Epoch 25, Iteration 190, Loss: 0.04142952337861061\n",
      "Epoch 25, Iteration 200, Loss: 0.038687482476234436\n",
      "Epoch 25, Iteration 210, Loss: 0.02455826848745346\n",
      "Epoch 25, Iteration 220, Loss: 0.047940514981746674\n",
      "Epoch 25, Iteration 230, Loss: 0.03177163377404213\n",
      "Epoch 25, Iteration 240, Loss: 0.03345049172639847\n",
      "Epoch 25, Iteration 250, Loss: 0.04197975993156433\n",
      "Epoch 25, Iteration 260, Loss: 0.04575565829873085\n",
      "Epoch 25, Iteration 270, Loss: 0.031836360692977905\n",
      "Epoch 25, Iteration 280, Loss: 0.03576431795954704\n",
      "Epoch 25, Iteration 290, Loss: 0.031853411346673965\n",
      "Epoch 25, Iteration 300, Loss: 0.04198690876364708\n",
      "Epoch 25, Iteration 310, Loss: 0.07581892609596252\n",
      "Epoch 25, Iteration 320, Loss: 0.047085344791412354\n",
      "Epoch 25, Iteration 330, Loss: 0.0579601414501667\n",
      "Epoch 25, Iteration 340, Loss: 0.03610702604055405\n",
      "Epoch 25, Iteration 350, Loss: 0.07086208462715149\n",
      "Epoch 25, Iteration 360, Loss: 0.1036163792014122\n",
      "Epoch 25, Iteration 370, Loss: 0.01578681170940399\n",
      "Epoch 25, Iteration 380, Loss: 0.08158928900957108\n",
      "Epoch 25, Iteration 390, Loss: 0.07364795356988907\n",
      "Epoch 25, Iteration 400, Loss: 0.03495374694466591\n",
      "Epoch 25, Iteration 410, Loss: 0.04002298787236214\n",
      "Epoch 25, Iteration 420, Loss: 0.0384097695350647\n",
      "Epoch 25, Iteration 430, Loss: 0.04739377275109291\n",
      "Epoch 25, Iteration 440, Loss: 0.08560056239366531\n",
      "Epoch 25, Iteration 450, Loss: 0.0275392085313797\n",
      "Epoch 25, Iteration 460, Loss: 0.08102095872163773\n",
      "Epoch 25, Iteration 470, Loss: 0.03239024430513382\n",
      "Epoch 25, Iteration 480, Loss: 0.03861800581216812\n",
      "Epoch 25, Iteration 490, Loss: 0.026511123403906822\n",
      "Epoch 25, Iteration 500, Loss: 0.027984654530882835\n",
      "Epoch 25, Iteration 510, Loss: 0.031985703855752945\n",
      "Epoch 25, Iteration 520, Loss: 0.032857585698366165\n",
      "Epoch 25, Iteration 530, Loss: 0.022972967475652695\n",
      "Epoch 25, Iteration 540, Loss: 0.03529971092939377\n",
      "Epoch 25, Iteration 550, Loss: 0.03988045081496239\n",
      "Epoch 25, Iteration 560, Loss: 0.014820855110883713\n",
      "Epoch 25, Iteration 570, Loss: 0.0401599183678627\n",
      "Epoch 25, Iteration 580, Loss: 0.05328989028930664\n",
      "Epoch 25, Iteration 590, Loss: 0.034399937838315964\n",
      "Epoch 25, Iteration 600, Loss: 0.01623539626598358\n",
      "Epoch 25, Iteration 610, Loss: 0.03815186023712158\n",
      "Epoch 25, Iteration 620, Loss: 0.03509211912751198\n",
      "Epoch 25, Iteration 630, Loss: 0.03964095190167427\n",
      "Epoch 25, Iteration 640, Loss: 0.04979797825217247\n",
      "Epoch 25, Iteration 650, Loss: 0.0374123714864254\n",
      "Epoch 25, Iteration 660, Loss: 0.06234056130051613\n",
      "Epoch 25, Iteration 670, Loss: 0.0249564778059721\n",
      "Epoch 25, Iteration 680, Loss: 0.0989823117852211\n",
      "Epoch 25, Iteration 690, Loss: 0.038756754249334335\n",
      "Epoch 25, Iteration 700, Loss: 0.03204484283924103\n",
      "Epoch 25, Iteration 710, Loss: 0.026067784056067467\n",
      "Epoch 25, Iteration 720, Loss: 0.04671594128012657\n",
      "Epoch 25, Iteration 730, Loss: 0.046119995415210724\n",
      "Epoch 25, Validation Loss: 0.041242685007012406\n",
      "Validation loss decreased (0.041246 --> 0.041243). Saving model...\n",
      "Epoch 26, Iteration 0, Loss: 0.030312394723296165\n",
      "Epoch 26, Iteration 10, Loss: 0.05421986058354378\n",
      "Epoch 26, Iteration 20, Loss: 0.030121691524982452\n",
      "Epoch 26, Iteration 30, Loss: 0.04075886309146881\n",
      "Epoch 26, Iteration 40, Loss: 0.031454384326934814\n",
      "Epoch 26, Iteration 50, Loss: 0.05228035897016525\n",
      "Epoch 26, Iteration 60, Loss: 0.0155217619612813\n",
      "Epoch 26, Iteration 70, Loss: 0.05112132430076599\n",
      "Epoch 26, Iteration 80, Loss: 0.04439760744571686\n",
      "Epoch 26, Iteration 90, Loss: 0.047005344182252884\n",
      "Epoch 26, Iteration 100, Loss: 0.05561980605125427\n",
      "Epoch 26, Iteration 110, Loss: 0.02053140290081501\n",
      "Epoch 26, Iteration 120, Loss: 0.030155053362250328\n",
      "Epoch 26, Iteration 130, Loss: 0.07570897042751312\n",
      "Epoch 26, Iteration 140, Loss: 0.0343630351126194\n",
      "Epoch 26, Iteration 150, Loss: 0.04114725813269615\n",
      "Epoch 26, Iteration 160, Loss: 0.033529575914144516\n",
      "Epoch 26, Iteration 170, Loss: 0.0338207371532917\n",
      "Epoch 26, Iteration 180, Loss: 0.0435493141412735\n",
      "Epoch 26, Iteration 190, Loss: 0.03811398893594742\n",
      "Epoch 26, Iteration 200, Loss: 0.04545680806040764\n",
      "Epoch 26, Iteration 210, Loss: 0.038526855409145355\n",
      "Epoch 26, Iteration 220, Loss: 0.03213602304458618\n",
      "Epoch 26, Iteration 230, Loss: 0.030604815110564232\n",
      "Epoch 26, Iteration 240, Loss: 0.04951877146959305\n",
      "Epoch 26, Iteration 250, Loss: 0.040374331176280975\n",
      "Epoch 26, Iteration 260, Loss: 0.042391400784254074\n",
      "Epoch 26, Iteration 270, Loss: 0.035425104200839996\n",
      "Epoch 26, Iteration 280, Loss: 0.0704117864370346\n",
      "Epoch 26, Iteration 290, Loss: 0.05087792128324509\n",
      "Epoch 26, Iteration 300, Loss: 0.03673086315393448\n",
      "Epoch 26, Iteration 310, Loss: 0.05795498564839363\n",
      "Epoch 26, Iteration 320, Loss: 0.035363513976335526\n",
      "Epoch 26, Iteration 330, Loss: 0.047294534742832184\n",
      "Epoch 26, Iteration 340, Loss: 0.05175894498825073\n",
      "Epoch 26, Iteration 350, Loss: 0.05122552439570427\n",
      "Epoch 26, Iteration 360, Loss: 0.04815008118748665\n",
      "Epoch 26, Iteration 370, Loss: 0.05413036420941353\n",
      "Epoch 26, Iteration 380, Loss: 0.025325441733002663\n",
      "Epoch 26, Iteration 390, Loss: 0.0551912821829319\n",
      "Epoch 26, Iteration 400, Loss: 0.04500994831323624\n",
      "Epoch 26, Iteration 410, Loss: 0.029155507683753967\n",
      "Epoch 26, Iteration 420, Loss: 0.026441417634487152\n",
      "Epoch 26, Iteration 430, Loss: 0.04715901240706444\n",
      "Epoch 26, Iteration 440, Loss: 0.03709730878472328\n",
      "Epoch 26, Iteration 450, Loss: 0.053719066083431244\n",
      "Epoch 26, Iteration 460, Loss: 0.05455430597066879\n",
      "Epoch 26, Iteration 470, Loss: 0.0358622670173645\n",
      "Epoch 26, Iteration 480, Loss: 0.04950419440865517\n",
      "Epoch 26, Iteration 490, Loss: 0.021244201809167862\n",
      "Epoch 26, Iteration 500, Loss: 0.030567031353712082\n",
      "Epoch 26, Iteration 510, Loss: 0.04071047157049179\n",
      "Epoch 26, Iteration 520, Loss: 0.024847041815519333\n",
      "Epoch 26, Iteration 530, Loss: 0.031008852645754814\n",
      "Epoch 26, Iteration 540, Loss: 0.023297792300581932\n",
      "Epoch 26, Iteration 550, Loss: 0.02593754231929779\n",
      "Epoch 26, Iteration 560, Loss: 0.022088589146733284\n",
      "Epoch 26, Iteration 570, Loss: 0.01792062260210514\n",
      "Epoch 26, Iteration 580, Loss: 0.03696677088737488\n",
      "Epoch 26, Iteration 590, Loss: 0.1167331263422966\n",
      "Epoch 26, Iteration 600, Loss: 0.06525016576051712\n",
      "Epoch 26, Iteration 610, Loss: 0.031164659187197685\n",
      "Epoch 26, Iteration 620, Loss: 0.03596416488289833\n",
      "Epoch 26, Iteration 630, Loss: 0.027924584224820137\n",
      "Epoch 26, Iteration 640, Loss: 0.07250961661338806\n",
      "Epoch 26, Iteration 650, Loss: 0.030156970024108887\n",
      "Epoch 26, Iteration 660, Loss: 0.033148497343063354\n",
      "Epoch 26, Iteration 670, Loss: 0.08980526775121689\n",
      "Epoch 26, Iteration 680, Loss: 0.030692243948578835\n",
      "Epoch 26, Iteration 690, Loss: 0.014060772024095058\n",
      "Epoch 26, Iteration 700, Loss: 0.01433530729264021\n",
      "Epoch 26, Iteration 710, Loss: 0.038512106984853745\n",
      "Epoch 26, Iteration 720, Loss: 0.05518067628145218\n",
      "Epoch 26, Iteration 730, Loss: 0.03141520172357559\n",
      "Epoch 26, Validation Loss: 0.04124795380250915\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 27, Iteration 0, Loss: 0.022783126682043076\n",
      "Epoch 27, Iteration 10, Loss: 0.05680306255817413\n",
      "Epoch 27, Iteration 20, Loss: 0.04780346900224686\n",
      "Epoch 27, Iteration 30, Loss: 0.018442122265696526\n",
      "Epoch 27, Iteration 40, Loss: 0.06074671447277069\n",
      "Epoch 27, Iteration 50, Loss: 0.042032498866319656\n",
      "Epoch 27, Iteration 60, Loss: 0.05045231059193611\n",
      "Epoch 27, Iteration 70, Loss: 0.05943642929196358\n",
      "Epoch 27, Iteration 80, Loss: 0.037527404725551605\n",
      "Epoch 27, Iteration 90, Loss: 0.056071795523166656\n",
      "Epoch 27, Iteration 100, Loss: 0.048700347542762756\n",
      "Epoch 27, Iteration 110, Loss: 0.05258045345544815\n",
      "Epoch 27, Iteration 120, Loss: 0.02759651467204094\n",
      "Epoch 27, Iteration 130, Loss: 0.0353209413588047\n",
      "Epoch 27, Iteration 140, Loss: 0.04244941473007202\n",
      "Epoch 27, Iteration 150, Loss: 0.03996483236551285\n",
      "Epoch 27, Iteration 160, Loss: 0.02936675027012825\n",
      "Epoch 27, Iteration 170, Loss: 0.023820869624614716\n",
      "Epoch 27, Iteration 180, Loss: 0.03148140758275986\n",
      "Epoch 27, Iteration 190, Loss: 0.036061715334653854\n",
      "Epoch 27, Iteration 200, Loss: 0.035408105701208115\n",
      "Epoch 27, Iteration 210, Loss: 0.04130731523036957\n",
      "Epoch 27, Iteration 220, Loss: 0.05273140221834183\n",
      "Epoch 27, Iteration 230, Loss: 0.11276320368051529\n",
      "Epoch 27, Iteration 240, Loss: 0.04105181619524956\n",
      "Epoch 27, Iteration 250, Loss: 0.048078861087560654\n",
      "Epoch 27, Iteration 260, Loss: 0.0335707813501358\n",
      "Epoch 27, Iteration 270, Loss: 0.039487291127443314\n",
      "Epoch 27, Iteration 280, Loss: 0.03999330475926399\n",
      "Epoch 27, Iteration 290, Loss: 0.03416368365287781\n",
      "Epoch 27, Iteration 300, Loss: 0.03262665122747421\n",
      "Epoch 27, Iteration 310, Loss: 0.06290449947118759\n",
      "Epoch 27, Iteration 320, Loss: 0.05937812477350235\n",
      "Epoch 27, Iteration 330, Loss: 0.06247434392571449\n",
      "Epoch 27, Iteration 340, Loss: 0.053041379898786545\n",
      "Epoch 27, Iteration 350, Loss: 0.027052946388721466\n",
      "Epoch 27, Iteration 360, Loss: 0.08818045258522034\n",
      "Epoch 27, Iteration 370, Loss: 0.0462423637509346\n",
      "Epoch 27, Iteration 380, Loss: 0.03773968294262886\n",
      "Epoch 27, Iteration 390, Loss: 0.03831286355853081\n",
      "Epoch 27, Iteration 400, Loss: 0.02431873045861721\n",
      "Epoch 27, Iteration 410, Loss: 0.03701401129364967\n",
      "Epoch 27, Iteration 420, Loss: 0.05802774429321289\n",
      "Epoch 27, Iteration 430, Loss: 0.03317360579967499\n",
      "Epoch 27, Iteration 440, Loss: 0.05661672353744507\n",
      "Epoch 27, Iteration 450, Loss: 0.06683725118637085\n",
      "Epoch 27, Iteration 460, Loss: 0.059185631573200226\n",
      "Epoch 27, Iteration 470, Loss: 0.05266662314534187\n",
      "Epoch 27, Iteration 480, Loss: 0.041765157133340836\n",
      "Epoch 27, Iteration 490, Loss: 0.053235068917274475\n",
      "Epoch 27, Iteration 500, Loss: 0.044576097279787064\n",
      "Epoch 27, Iteration 510, Loss: 0.018362699076533318\n",
      "Epoch 27, Iteration 520, Loss: 0.0446096807718277\n",
      "Epoch 27, Iteration 530, Loss: 0.027399873360991478\n",
      "Epoch 27, Iteration 540, Loss: 0.03517242521047592\n",
      "Epoch 27, Iteration 550, Loss: 0.045987606048583984\n",
      "Epoch 27, Iteration 560, Loss: 0.0209299735724926\n",
      "Epoch 27, Iteration 570, Loss: 0.048874348402023315\n",
      "Epoch 27, Iteration 580, Loss: 0.029316194355487823\n",
      "Epoch 27, Iteration 590, Loss: 0.08129209280014038\n",
      "Epoch 27, Iteration 600, Loss: 0.04736078530550003\n",
      "Epoch 27, Iteration 610, Loss: 0.03629451245069504\n",
      "Epoch 27, Iteration 620, Loss: 0.04800195246934891\n",
      "Epoch 27, Iteration 630, Loss: 0.06010067090392113\n",
      "Epoch 27, Iteration 640, Loss: 0.04344635456800461\n",
      "Epoch 27, Iteration 650, Loss: 0.027762310579419136\n",
      "Epoch 27, Iteration 660, Loss: 0.017663974314928055\n",
      "Epoch 27, Iteration 670, Loss: 0.03486873582005501\n",
      "Epoch 27, Iteration 680, Loss: 0.04311130940914154\n",
      "Epoch 27, Iteration 690, Loss: 0.04069448262453079\n",
      "Epoch 27, Iteration 700, Loss: 0.0503142885863781\n",
      "Epoch 27, Iteration 710, Loss: 0.027079127728939056\n",
      "Epoch 27, Iteration 720, Loss: 0.022875716909766197\n",
      "Epoch 27, Iteration 730, Loss: 0.031896717846393585\n",
      "Epoch 27, Validation Loss: 0.041246086814562266\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 28, Iteration 0, Loss: 0.0366629920899868\n",
      "Epoch 28, Iteration 10, Loss: 0.01921945810317993\n",
      "Epoch 28, Iteration 20, Loss: 0.0449603870511055\n",
      "Epoch 28, Iteration 30, Loss: 0.034506071358919144\n",
      "Epoch 28, Iteration 40, Loss: 0.03860894963145256\n",
      "Epoch 28, Iteration 50, Loss: 0.03517262637615204\n",
      "Epoch 28, Iteration 60, Loss: 0.04819146543741226\n",
      "Epoch 28, Iteration 70, Loss: 0.03480113297700882\n",
      "Epoch 28, Iteration 80, Loss: 0.05030037835240364\n",
      "Epoch 28, Iteration 90, Loss: 0.02063019573688507\n",
      "Epoch 28, Iteration 100, Loss: 0.030611757189035416\n",
      "Epoch 28, Iteration 110, Loss: 0.06190162152051926\n",
      "Epoch 28, Iteration 120, Loss: 0.030473217368125916\n",
      "Epoch 28, Iteration 130, Loss: 0.05380020663142204\n",
      "Epoch 28, Iteration 140, Loss: 0.05836443975567818\n",
      "Epoch 28, Iteration 150, Loss: 0.06328614056110382\n",
      "Epoch 28, Iteration 160, Loss: 0.04709456488490105\n",
      "Epoch 28, Iteration 170, Loss: 0.08812595158815384\n",
      "Epoch 28, Iteration 180, Loss: 0.030622441321611404\n",
      "Epoch 28, Iteration 190, Loss: 0.028989152982831\n",
      "Epoch 28, Iteration 200, Loss: 0.04552142322063446\n",
      "Epoch 28, Iteration 210, Loss: 0.037816811352968216\n",
      "Epoch 28, Iteration 220, Loss: 0.02731718309223652\n",
      "Epoch 28, Iteration 230, Loss: 0.052384018898010254\n",
      "Epoch 28, Iteration 240, Loss: 0.022041071206331253\n",
      "Epoch 28, Iteration 250, Loss: 0.019159823656082153\n",
      "Epoch 28, Iteration 260, Loss: 0.018286291509866714\n",
      "Epoch 28, Iteration 270, Loss: 0.06917217373847961\n",
      "Epoch 28, Iteration 280, Loss: 0.03745550662279129\n",
      "Epoch 28, Iteration 290, Loss: 0.048534151166677475\n",
      "Epoch 28, Iteration 300, Loss: 0.041198357939720154\n",
      "Epoch 28, Iteration 310, Loss: 0.051941294223070145\n",
      "Epoch 28, Iteration 320, Loss: 0.0541846863925457\n",
      "Epoch 28, Iteration 330, Loss: 0.04641730338335037\n",
      "Epoch 28, Iteration 340, Loss: 0.045159973204135895\n",
      "Epoch 28, Iteration 350, Loss: 0.06444911658763885\n",
      "Epoch 28, Iteration 360, Loss: 0.07482121884822845\n",
      "Epoch 28, Iteration 370, Loss: 0.02454104833304882\n",
      "Epoch 28, Iteration 380, Loss: 0.01775805838406086\n",
      "Epoch 28, Iteration 390, Loss: 0.04905775561928749\n",
      "Epoch 28, Iteration 400, Loss: 0.05672537162899971\n",
      "Epoch 28, Iteration 410, Loss: 0.02321344055235386\n",
      "Epoch 28, Iteration 420, Loss: 0.08120616525411606\n",
      "Epoch 28, Iteration 430, Loss: 0.026720037683844566\n",
      "Epoch 28, Iteration 440, Loss: 0.032081928104162216\n",
      "Epoch 28, Iteration 450, Loss: 0.036177411675453186\n",
      "Epoch 28, Iteration 460, Loss: 0.0413149856030941\n",
      "Epoch 28, Iteration 470, Loss: 0.03235640004277229\n",
      "Epoch 28, Iteration 480, Loss: 0.019695516675710678\n",
      "Epoch 28, Iteration 490, Loss: 0.06269604712724686\n",
      "Epoch 28, Iteration 500, Loss: 0.03894808888435364\n",
      "Epoch 28, Iteration 510, Loss: 0.06358719617128372\n",
      "Epoch 28, Iteration 520, Loss: 0.043579794466495514\n",
      "Epoch 28, Iteration 530, Loss: 0.048959776759147644\n",
      "Epoch 28, Iteration 540, Loss: 0.062085215002298355\n",
      "Epoch 28, Iteration 550, Loss: 0.0216158926486969\n",
      "Epoch 28, Iteration 560, Loss: 0.08304741233587265\n",
      "Epoch 28, Iteration 570, Loss: 0.04658028855919838\n",
      "Epoch 28, Iteration 580, Loss: 0.03808693215250969\n",
      "Epoch 28, Iteration 590, Loss: 0.023187266662716866\n",
      "Epoch 28, Iteration 600, Loss: 0.03977770358324051\n",
      "Epoch 28, Iteration 610, Loss: 0.0449315644800663\n",
      "Epoch 28, Iteration 620, Loss: 0.05229976773262024\n",
      "Epoch 28, Iteration 630, Loss: 0.04148988425731659\n",
      "Epoch 28, Iteration 640, Loss: 0.04062889888882637\n",
      "Epoch 28, Iteration 650, Loss: 0.08367059379816055\n",
      "Epoch 28, Iteration 660, Loss: 0.030019661411643028\n",
      "Epoch 28, Iteration 670, Loss: 0.04871908947825432\n",
      "Epoch 28, Iteration 680, Loss: 0.04410551115870476\n",
      "Epoch 28, Iteration 690, Loss: 0.021965328603982925\n",
      "Epoch 28, Iteration 700, Loss: 0.03809655085206032\n",
      "Epoch 28, Iteration 710, Loss: 0.032408569008111954\n",
      "Epoch 28, Iteration 720, Loss: 0.06086619570851326\n",
      "Epoch 28, Iteration 730, Loss: 0.020842602476477623\n",
      "Epoch 28, Validation Loss: 0.04124447175949488\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 29, Iteration 0, Loss: 0.040518954396247864\n",
      "Epoch 29, Iteration 10, Loss: 0.07962259650230408\n",
      "Epoch 29, Iteration 20, Loss: 0.08884093165397644\n",
      "Epoch 29, Iteration 30, Loss: 0.06503520160913467\n",
      "Epoch 29, Iteration 40, Loss: 0.0370405912399292\n",
      "Epoch 29, Iteration 50, Loss: 0.03061319887638092\n",
      "Epoch 29, Iteration 60, Loss: 0.06689715385437012\n",
      "Epoch 29, Iteration 70, Loss: 0.02549324743449688\n",
      "Epoch 29, Iteration 80, Loss: 0.038044530898332596\n",
      "Epoch 29, Iteration 90, Loss: 0.03618909791111946\n",
      "Epoch 29, Iteration 100, Loss: 0.0468754917383194\n",
      "Epoch 29, Iteration 110, Loss: 0.03287658467888832\n",
      "Epoch 29, Iteration 120, Loss: 0.05646000802516937\n",
      "Epoch 29, Iteration 130, Loss: 0.048089172691106796\n",
      "Epoch 29, Iteration 140, Loss: 0.044148288667201996\n",
      "Epoch 29, Iteration 150, Loss: 0.024807265028357506\n",
      "Epoch 29, Iteration 160, Loss: 0.0509079247713089\n",
      "Epoch 29, Iteration 170, Loss: 0.03357553482055664\n",
      "Epoch 29, Iteration 180, Loss: 0.04429401829838753\n",
      "Epoch 29, Iteration 190, Loss: 0.04512017220258713\n",
      "Epoch 29, Iteration 200, Loss: 0.05148477107286453\n",
      "Epoch 29, Iteration 210, Loss: 0.03357129916548729\n",
      "Epoch 29, Iteration 220, Loss: 0.04149720445275307\n",
      "Epoch 29, Iteration 230, Loss: 0.03145395591855049\n",
      "Epoch 29, Iteration 240, Loss: 0.0693700760602951\n",
      "Epoch 29, Iteration 250, Loss: 0.037858255207538605\n",
      "Epoch 29, Iteration 260, Loss: 0.06241665408015251\n",
      "Epoch 29, Iteration 270, Loss: 0.02598446048796177\n",
      "Epoch 29, Iteration 280, Loss: 0.042133208364248276\n",
      "Epoch 29, Iteration 290, Loss: 0.03643468767404556\n",
      "Epoch 29, Iteration 300, Loss: 0.03225279971957207\n",
      "Epoch 29, Iteration 310, Loss: 0.09296589344739914\n",
      "Epoch 29, Iteration 320, Loss: 0.034544918686151505\n",
      "Epoch 29, Iteration 330, Loss: 0.03825489804148674\n",
      "Epoch 29, Iteration 340, Loss: 0.05296790599822998\n",
      "Epoch 29, Iteration 350, Loss: 0.07509951293468475\n",
      "Epoch 29, Iteration 360, Loss: 0.0182204470038414\n",
      "Epoch 29, Iteration 370, Loss: 0.05319584161043167\n",
      "Epoch 29, Iteration 380, Loss: 0.016176806762814522\n",
      "Epoch 29, Iteration 390, Loss: 0.02967205084860325\n",
      "Epoch 29, Iteration 400, Loss: 0.06595414131879807\n",
      "Epoch 29, Iteration 410, Loss: 0.04555188864469528\n",
      "Epoch 29, Iteration 420, Loss: 0.028393475338816643\n",
      "Epoch 29, Iteration 430, Loss: 0.02350536920130253\n",
      "Epoch 29, Iteration 440, Loss: 0.06683871150016785\n",
      "Epoch 29, Iteration 450, Loss: 0.009610047563910484\n",
      "Epoch 29, Iteration 460, Loss: 0.023985201492905617\n",
      "Epoch 29, Iteration 470, Loss: 0.026529695838689804\n",
      "Epoch 29, Iteration 480, Loss: 0.03726916387677193\n",
      "Epoch 29, Iteration 490, Loss: 0.0462932325899601\n",
      "Epoch 29, Iteration 500, Loss: 0.06715109944343567\n",
      "Epoch 29, Iteration 510, Loss: 0.05673166364431381\n",
      "Epoch 29, Iteration 520, Loss: 0.025440523400902748\n",
      "Epoch 29, Iteration 530, Loss: 0.03684933856129646\n",
      "Epoch 29, Iteration 540, Loss: 0.09953420609235764\n",
      "Epoch 29, Iteration 550, Loss: 0.03318455442786217\n",
      "Epoch 29, Iteration 560, Loss: 0.05431473255157471\n",
      "Epoch 29, Iteration 570, Loss: 0.04580749571323395\n",
      "Epoch 29, Iteration 580, Loss: 0.056557029485702515\n",
      "Epoch 29, Iteration 590, Loss: 0.03938467428088188\n",
      "Epoch 29, Iteration 600, Loss: 0.05233781784772873\n",
      "Epoch 29, Iteration 610, Loss: 0.06268993020057678\n",
      "Epoch 29, Iteration 620, Loss: 0.02313343994319439\n",
      "Epoch 29, Iteration 630, Loss: 0.027836263179779053\n",
      "Epoch 29, Iteration 640, Loss: 0.04006846249103546\n",
      "Epoch 29, Iteration 650, Loss: 0.0633164644241333\n",
      "Epoch 29, Iteration 660, Loss: 0.0299389511346817\n",
      "Epoch 29, Iteration 670, Loss: 0.035263530910015106\n",
      "Epoch 29, Iteration 680, Loss: 0.018476800993084908\n",
      "Epoch 29, Iteration 690, Loss: 0.036613114178180695\n",
      "Epoch 29, Iteration 700, Loss: 0.040804892778396606\n",
      "Epoch 29, Iteration 710, Loss: 0.040002185851335526\n",
      "Epoch 29, Iteration 720, Loss: 0.019620852544903755\n",
      "Epoch 29, Iteration 730, Loss: 0.03690728172659874\n",
      "Epoch 29, Validation Loss: 0.04124893748160938\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 30, Iteration 0, Loss: 0.041985929012298584\n",
      "Epoch 30, Iteration 10, Loss: 0.10135205090045929\n",
      "Epoch 30, Iteration 20, Loss: 0.036424022167921066\n",
      "Epoch 30, Iteration 30, Loss: 0.02352817729115486\n",
      "Epoch 30, Iteration 40, Loss: 0.06139469891786575\n",
      "Epoch 30, Iteration 50, Loss: 0.036897581070661545\n",
      "Epoch 30, Iteration 60, Loss: 0.047731250524520874\n",
      "Epoch 30, Iteration 70, Loss: 0.0423092283308506\n",
      "Epoch 30, Iteration 80, Loss: 0.034367725253105164\n",
      "Epoch 30, Iteration 90, Loss: 0.023477870970964432\n",
      "Epoch 30, Iteration 100, Loss: 0.06458517909049988\n",
      "Epoch 30, Iteration 110, Loss: 0.0530909039080143\n",
      "Epoch 30, Iteration 120, Loss: 0.030895201489329338\n",
      "Epoch 30, Iteration 130, Loss: 0.027466313913464546\n",
      "Epoch 30, Iteration 140, Loss: 0.039135947823524475\n",
      "Epoch 30, Iteration 150, Loss: 0.061041638255119324\n",
      "Epoch 30, Iteration 160, Loss: 0.05293605104088783\n",
      "Epoch 30, Iteration 170, Loss: 0.04000480845570564\n",
      "Epoch 30, Iteration 180, Loss: 0.06425491720438004\n",
      "Epoch 30, Iteration 190, Loss: 0.052245739847421646\n",
      "Epoch 30, Iteration 200, Loss: 0.041320737451314926\n",
      "Epoch 30, Iteration 210, Loss: 0.04634959623217583\n",
      "Epoch 30, Iteration 220, Loss: 0.03194693848490715\n",
      "Epoch 30, Iteration 230, Loss: 0.015839708968997\n",
      "Epoch 30, Iteration 240, Loss: 0.07203428447246552\n",
      "Epoch 30, Iteration 250, Loss: 0.1352662593126297\n",
      "Epoch 30, Iteration 260, Loss: 0.039451371878385544\n",
      "Epoch 30, Iteration 270, Loss: 0.028066039085388184\n",
      "Epoch 30, Iteration 280, Loss: 0.035239771008491516\n",
      "Epoch 30, Iteration 290, Loss: 0.04345887526869774\n",
      "Epoch 30, Iteration 300, Loss: 0.03135565668344498\n",
      "Epoch 30, Iteration 310, Loss: 0.060519516468048096\n",
      "Epoch 30, Iteration 320, Loss: 0.043758612126111984\n",
      "Epoch 30, Iteration 330, Loss: 0.038466211408376694\n",
      "Epoch 30, Iteration 340, Loss: 0.052646879106760025\n",
      "Epoch 30, Iteration 350, Loss: 0.028632421046495438\n",
      "Epoch 30, Iteration 360, Loss: 0.029911158606410027\n",
      "Epoch 30, Iteration 370, Loss: 0.02129783295094967\n",
      "Epoch 30, Iteration 380, Loss: 0.0832945853471756\n",
      "Epoch 30, Iteration 390, Loss: 0.0377267561852932\n",
      "Epoch 30, Iteration 400, Loss: 0.08091847598552704\n",
      "Epoch 30, Iteration 410, Loss: 0.06361006945371628\n",
      "Epoch 30, Iteration 420, Loss: 0.08684766292572021\n",
      "Epoch 30, Iteration 430, Loss: 0.0583471804857254\n",
      "Epoch 30, Iteration 440, Loss: 0.05948459357023239\n",
      "Epoch 30, Iteration 450, Loss: 0.058285191655159\n",
      "Epoch 30, Iteration 460, Loss: 0.053381554782390594\n",
      "Epoch 30, Iteration 470, Loss: 0.048987239599227905\n",
      "Epoch 30, Iteration 480, Loss: 0.04259679839015007\n",
      "Epoch 30, Iteration 490, Loss: 0.0414375439286232\n",
      "Epoch 30, Iteration 500, Loss: 0.0378609225153923\n",
      "Epoch 30, Iteration 510, Loss: 0.050498493015766144\n",
      "Epoch 30, Iteration 520, Loss: 0.027672694995999336\n",
      "Epoch 30, Iteration 530, Loss: 0.019515490159392357\n",
      "Epoch 30, Iteration 540, Loss: 0.02150973491370678\n",
      "Epoch 30, Iteration 550, Loss: 0.0945885106921196\n",
      "Epoch 30, Iteration 560, Loss: 0.032567474991083145\n",
      "Epoch 30, Iteration 570, Loss: 0.06664524972438812\n",
      "Epoch 30, Iteration 580, Loss: 0.06806952506303787\n",
      "Epoch 30, Iteration 590, Loss: 0.045236214995384216\n",
      "Epoch 30, Iteration 600, Loss: 0.030944326892495155\n",
      "Epoch 30, Iteration 610, Loss: 0.04013517126441002\n",
      "Epoch 30, Iteration 620, Loss: 0.027071228250861168\n",
      "Epoch 30, Iteration 630, Loss: 0.03149567171931267\n",
      "Epoch 30, Iteration 640, Loss: 0.057135067880153656\n",
      "Epoch 30, Iteration 650, Loss: 0.025007443502545357\n",
      "Epoch 30, Iteration 660, Loss: 0.038687024265527725\n",
      "Epoch 30, Iteration 670, Loss: 0.03473130241036415\n",
      "Epoch 30, Iteration 680, Loss: 0.05409392714500427\n",
      "Epoch 30, Iteration 690, Loss: 0.03341302648186684\n",
      "Epoch 30, Iteration 700, Loss: 0.030637282878160477\n",
      "Epoch 30, Iteration 710, Loss: 0.0278927031904459\n",
      "Epoch 30, Iteration 720, Loss: 0.020261455327272415\n",
      "Epoch 30, Iteration 730, Loss: 0.029545964673161507\n",
      "Epoch 30, Validation Loss: 0.04124807353819842\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 31, Iteration 0, Loss: 0.04238814115524292\n",
      "Epoch 31, Iteration 10, Loss: 0.0868498831987381\n",
      "Epoch 31, Iteration 20, Loss: 0.04747415706515312\n",
      "Epoch 31, Iteration 30, Loss: 0.05872912332415581\n",
      "Epoch 31, Iteration 40, Loss: 0.026108548045158386\n",
      "Epoch 31, Iteration 50, Loss: 0.04307463765144348\n",
      "Epoch 31, Iteration 60, Loss: 0.039613474160432816\n",
      "Epoch 31, Iteration 70, Loss: 0.04990208521485329\n",
      "Epoch 31, Iteration 80, Loss: 0.0325414314866066\n",
      "Epoch 31, Iteration 90, Loss: 0.031447216868400574\n",
      "Epoch 31, Iteration 100, Loss: 0.028338082134723663\n",
      "Epoch 31, Iteration 110, Loss: 0.035107504576444626\n",
      "Epoch 31, Iteration 120, Loss: 0.04829464480280876\n",
      "Epoch 31, Iteration 130, Loss: 0.02739497646689415\n",
      "Epoch 31, Iteration 140, Loss: 0.0387435220181942\n",
      "Epoch 31, Iteration 150, Loss: 0.029868699610233307\n",
      "Epoch 31, Iteration 160, Loss: 0.02982184663414955\n",
      "Epoch 31, Iteration 170, Loss: 0.036988791078329086\n",
      "Epoch 31, Iteration 180, Loss: 0.03268257528543472\n",
      "Epoch 31, Iteration 190, Loss: 0.018686234951019287\n",
      "Epoch 31, Iteration 200, Loss: 0.037494223564863205\n",
      "Epoch 31, Iteration 210, Loss: 0.022906756028532982\n",
      "Epoch 31, Iteration 220, Loss: 0.03837939351797104\n",
      "Epoch 31, Iteration 230, Loss: 0.048619333654642105\n",
      "Epoch 31, Iteration 240, Loss: 0.02821304462850094\n",
      "Epoch 31, Iteration 250, Loss: 0.03776354342699051\n",
      "Epoch 31, Iteration 260, Loss: 0.04195554554462433\n",
      "Epoch 31, Iteration 270, Loss: 0.08562678098678589\n",
      "Epoch 31, Iteration 280, Loss: 0.037859123200178146\n",
      "Epoch 31, Iteration 290, Loss: 0.028150804340839386\n",
      "Epoch 31, Iteration 300, Loss: 0.06918038427829742\n",
      "Epoch 31, Iteration 310, Loss: 0.10045257210731506\n",
      "Epoch 31, Iteration 320, Loss: 0.039050426334142685\n",
      "Epoch 31, Iteration 330, Loss: 0.03149065002799034\n",
      "Epoch 31, Iteration 340, Loss: 0.040379010140895844\n",
      "Epoch 31, Iteration 350, Loss: 0.030761590227484703\n",
      "Epoch 31, Iteration 360, Loss: 0.03432345762848854\n",
      "Epoch 31, Iteration 370, Loss: 0.048922497779130936\n",
      "Epoch 31, Iteration 380, Loss: 0.02214067429304123\n",
      "Epoch 31, Iteration 390, Loss: 0.03285297006368637\n",
      "Epoch 31, Iteration 400, Loss: 0.05181894451379776\n",
      "Epoch 31, Iteration 410, Loss: 0.042129114270210266\n",
      "Epoch 31, Iteration 420, Loss: 0.01967986486852169\n",
      "Epoch 31, Iteration 430, Loss: 0.0806923434138298\n",
      "Epoch 31, Iteration 440, Loss: 0.045748498290777206\n",
      "Epoch 31, Iteration 450, Loss: 0.03697226941585541\n",
      "Epoch 31, Iteration 460, Loss: 0.11712028831243515\n",
      "Epoch 31, Iteration 470, Loss: 0.0350692979991436\n",
      "Epoch 31, Iteration 480, Loss: 0.026661058887839317\n",
      "Epoch 31, Iteration 490, Loss: 0.04338797926902771\n",
      "Epoch 31, Iteration 500, Loss: 0.029281456023454666\n",
      "Epoch 31, Iteration 510, Loss: 0.02256549336016178\n",
      "Epoch 31, Iteration 520, Loss: 0.043195512145757675\n",
      "Epoch 31, Iteration 530, Loss: 0.026745513081550598\n",
      "Epoch 31, Iteration 540, Loss: 0.021936744451522827\n",
      "Epoch 31, Iteration 550, Loss: 0.0350048691034317\n",
      "Epoch 31, Iteration 560, Loss: 0.050487492233514786\n",
      "Epoch 31, Iteration 570, Loss: 0.05742620676755905\n",
      "Epoch 31, Iteration 580, Loss: 0.03981095552444458\n",
      "Epoch 31, Iteration 590, Loss: 0.06827669590711594\n",
      "Epoch 31, Iteration 600, Loss: 0.026165511459112167\n",
      "Epoch 31, Iteration 610, Loss: 0.03420262411236763\n",
      "Epoch 31, Iteration 620, Loss: 0.018590513616800308\n",
      "Epoch 31, Iteration 630, Loss: 0.039833493530750275\n",
      "Epoch 31, Iteration 640, Loss: 0.0885312631726265\n",
      "Epoch 31, Iteration 650, Loss: 0.04498529061675072\n",
      "Epoch 31, Iteration 660, Loss: 0.058266159147024155\n",
      "Epoch 31, Iteration 670, Loss: 0.04083385691046715\n",
      "Epoch 31, Iteration 680, Loss: 0.030506499111652374\n",
      "Epoch 31, Iteration 690, Loss: 0.016593215987086296\n",
      "Epoch 31, Iteration 700, Loss: 0.04168441519141197\n",
      "Epoch 31, Iteration 710, Loss: 0.11013118922710419\n",
      "Epoch 31, Iteration 720, Loss: 0.027371907606720924\n",
      "Epoch 31, Iteration 730, Loss: 0.06829804182052612\n",
      "Epoch 31, Validation Loss: 0.041247263935435076\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch 32, Iteration 0, Loss: 0.052446819841861725\n",
      "Epoch 32, Iteration 10, Loss: 0.028947334736585617\n",
      "Epoch 32, Iteration 20, Loss: 0.044234320521354675\n",
      "Epoch 32, Iteration 30, Loss: 0.05313851684331894\n",
      "Epoch 32, Iteration 40, Loss: 0.05110263079404831\n",
      "Epoch 32, Iteration 50, Loss: 0.0437491275370121\n",
      "Epoch 32, Iteration 60, Loss: 0.03976401314139366\n",
      "Epoch 32, Iteration 70, Loss: 0.041708238422870636\n",
      "Epoch 32, Iteration 80, Loss: 0.045441050082445145\n",
      "Epoch 32, Iteration 90, Loss: 0.03765498101711273\n",
      "Epoch 32, Iteration 100, Loss: 0.11893031746149063\n",
      "Epoch 32, Iteration 110, Loss: 0.06080283224582672\n",
      "Epoch 32, Iteration 120, Loss: 0.03126344457268715\n",
      "Epoch 32, Iteration 130, Loss: 0.027881206944584846\n",
      "Epoch 32, Iteration 140, Loss: 0.03915542736649513\n",
      "Epoch 32, Iteration 150, Loss: 0.060433659702539444\n",
      "Epoch 32, Iteration 160, Loss: 0.04665222391486168\n",
      "Epoch 32, Iteration 170, Loss: 0.03460818901658058\n",
      "Epoch 32, Iteration 180, Loss: 0.04919036850333214\n",
      "Epoch 32, Iteration 190, Loss: 0.04401659220457077\n",
      "Epoch 32, Iteration 200, Loss: 0.036620404571294785\n",
      "Epoch 32, Iteration 210, Loss: 0.03412295877933502\n",
      "Epoch 32, Iteration 220, Loss: 0.047204870730638504\n",
      "Epoch 32, Iteration 230, Loss: 0.028765644878149033\n",
      "Epoch 32, Iteration 240, Loss: 0.03234857693314552\n",
      "Epoch 32, Iteration 250, Loss: 0.04003866761922836\n",
      "Epoch 32, Iteration 260, Loss: 0.03151461109519005\n",
      "Epoch 32, Iteration 270, Loss: 0.07800500094890594\n",
      "Epoch 32, Iteration 280, Loss: 0.03328277915716171\n",
      "Epoch 32, Iteration 290, Loss: 0.04071814939379692\n",
      "Epoch 32, Iteration 300, Loss: 0.04260735586285591\n",
      "Epoch 32, Iteration 310, Loss: 0.041369203478097916\n",
      "Epoch 32, Iteration 320, Loss: 0.030204668641090393\n",
      "Epoch 32, Iteration 330, Loss: 0.04304005578160286\n",
      "Epoch 32, Iteration 340, Loss: 0.07411713898181915\n",
      "Epoch 32, Iteration 350, Loss: 0.044754866510629654\n",
      "Epoch 32, Iteration 360, Loss: 0.056359972804784775\n",
      "Epoch 32, Iteration 370, Loss: 0.043929699808359146\n",
      "Epoch 32, Iteration 380, Loss: 0.03599429130554199\n",
      "Epoch 32, Iteration 390, Loss: 0.028097979724407196\n",
      "Epoch 32, Iteration 400, Loss: 0.05060896649956703\n",
      "Epoch 32, Iteration 410, Loss: 0.07002939283847809\n",
      "Epoch 32, Iteration 420, Loss: 0.04954824224114418\n",
      "Epoch 32, Iteration 430, Loss: 0.04936207830905914\n",
      "Epoch 32, Iteration 440, Loss: 0.05343765765428543\n",
      "Epoch 32, Iteration 450, Loss: 0.04231378808617592\n",
      "Epoch 32, Iteration 460, Loss: 0.055037979036569595\n",
      "Epoch 32, Iteration 470, Loss: 0.027657536789774895\n",
      "Epoch 32, Iteration 480, Loss: 0.04255630075931549\n",
      "Epoch 32, Iteration 490, Loss: 0.04560772702097893\n",
      "Epoch 32, Iteration 500, Loss: 0.031850650906562805\n",
      "Epoch 32, Iteration 510, Loss: 0.029066259041428566\n",
      "Epoch 32, Iteration 520, Loss: 0.038624975830316544\n",
      "Epoch 32, Iteration 530, Loss: 0.09054498374462128\n",
      "Epoch 32, Iteration 540, Loss: 0.028529547154903412\n",
      "Epoch 32, Iteration 550, Loss: 0.025809701532125473\n",
      "Epoch 32, Iteration 560, Loss: 0.045605309307575226\n",
      "Epoch 32, Iteration 570, Loss: 0.04613509401679039\n",
      "Epoch 32, Iteration 580, Loss: 0.03963708505034447\n",
      "Epoch 32, Iteration 590, Loss: 0.04015966132283211\n",
      "Epoch 32, Iteration 600, Loss: 0.03373619168996811\n",
      "Epoch 32, Iteration 610, Loss: 0.06365350633859634\n",
      "Epoch 32, Iteration 620, Loss: 0.025577090680599213\n",
      "Epoch 32, Iteration 630, Loss: 0.026559380814433098\n",
      "Epoch 32, Iteration 640, Loss: 0.05267169699072838\n",
      "Epoch 32, Iteration 650, Loss: 0.0475381501019001\n",
      "Epoch 32, Iteration 660, Loss: 0.08047617226839066\n",
      "Epoch 32, Iteration 670, Loss: 0.042965661734342575\n",
      "Epoch 32, Iteration 680, Loss: 0.023032071068882942\n",
      "Epoch 32, Iteration 690, Loss: 0.047263480722904205\n",
      "Epoch 32, Iteration 700, Loss: 0.03445019945502281\n",
      "Epoch 32, Iteration 710, Loss: 0.03710019960999489\n",
      "Epoch 32, Iteration 720, Loss: 0.0531630665063858\n",
      "Epoch 32, Iteration 730, Loss: 0.04377611726522446\n",
      "Epoch 32, Validation Loss: 0.04124703953730995\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch 33, Iteration 0, Loss: 0.07550457864999771\n",
      "Epoch 33, Iteration 10, Loss: 0.03993341699242592\n",
      "Epoch 33, Iteration 20, Loss: 0.07305727154016495\n",
      "Epoch 33, Iteration 30, Loss: 0.02770310640335083\n",
      "Epoch 33, Iteration 40, Loss: 0.03291339799761772\n",
      "Epoch 33, Iteration 50, Loss: 0.02475876733660698\n",
      "Epoch 33, Iteration 60, Loss: 0.05704628676176071\n",
      "Epoch 33, Iteration 70, Loss: 0.06198880448937416\n",
      "Epoch 33, Iteration 80, Loss: 0.05514971911907196\n",
      "Epoch 33, Iteration 90, Loss: 0.038612250238657\n",
      "Epoch 33, Iteration 100, Loss: 0.024908289313316345\n",
      "Epoch 33, Iteration 110, Loss: 0.037990208715200424\n",
      "Epoch 33, Iteration 120, Loss: 0.03913310915231705\n",
      "Epoch 33, Iteration 130, Loss: 0.027349166572093964\n",
      "Epoch 33, Iteration 140, Loss: 0.06665515154600143\n",
      "Epoch 33, Iteration 150, Loss: 0.09049708396196365\n",
      "Epoch 33, Iteration 160, Loss: 0.05334992706775665\n",
      "Epoch 33, Iteration 170, Loss: 0.03295851871371269\n",
      "Epoch 33, Iteration 180, Loss: 0.03196863457560539\n",
      "Epoch 33, Iteration 190, Loss: 0.09622728824615479\n",
      "Epoch 33, Iteration 200, Loss: 0.04481888934969902\n",
      "Epoch 33, Iteration 210, Loss: 0.09478899836540222\n",
      "Epoch 33, Iteration 220, Loss: 0.05907914787530899\n",
      "Epoch 33, Iteration 230, Loss: 0.032738447189331055\n",
      "Epoch 33, Iteration 240, Loss: 0.0370502732694149\n",
      "Epoch 33, Iteration 250, Loss: 0.025045014917850494\n",
      "Epoch 33, Iteration 260, Loss: 0.04857788234949112\n",
      "Epoch 33, Iteration 270, Loss: 0.03480100631713867\n",
      "Epoch 33, Iteration 280, Loss: 0.07832559198141098\n",
      "Epoch 33, Iteration 290, Loss: 0.02128000184893608\n",
      "Epoch 33, Iteration 300, Loss: 0.0428922101855278\n",
      "Epoch 33, Iteration 310, Loss: 0.01402562391012907\n",
      "Epoch 33, Iteration 320, Loss: 0.05099082365632057\n",
      "Epoch 33, Iteration 330, Loss: 0.05506156384944916\n",
      "Epoch 33, Iteration 340, Loss: 0.061198703944683075\n",
      "Epoch 33, Iteration 350, Loss: 0.03561410307884216\n",
      "Epoch 33, Iteration 360, Loss: 0.03299792855978012\n",
      "Epoch 33, Iteration 370, Loss: 0.01786208711564541\n",
      "Epoch 33, Iteration 380, Loss: 0.029917500913143158\n",
      "Epoch 33, Iteration 390, Loss: 0.04872805252671242\n",
      "Epoch 33, Iteration 400, Loss: 0.027337584644556046\n",
      "Epoch 33, Iteration 410, Loss: 0.09230136126279831\n",
      "Epoch 33, Iteration 420, Loss: 0.055544108152389526\n",
      "Epoch 33, Iteration 430, Loss: 0.04070613160729408\n",
      "Epoch 33, Iteration 440, Loss: 0.04054303094744682\n",
      "Epoch 33, Iteration 450, Loss: 0.03359729424118996\n",
      "Epoch 33, Iteration 460, Loss: 0.047843772917985916\n",
      "Epoch 33, Iteration 470, Loss: 0.08379363268613815\n",
      "Epoch 33, Iteration 480, Loss: 0.015701519325375557\n",
      "Epoch 33, Iteration 490, Loss: 0.03537720814347267\n",
      "Epoch 33, Iteration 500, Loss: 0.06077386438846588\n",
      "Epoch 33, Iteration 510, Loss: 0.04001818597316742\n",
      "Epoch 33, Iteration 520, Loss: 0.03189028799533844\n",
      "Epoch 33, Iteration 530, Loss: 0.028080321848392487\n",
      "Epoch 33, Iteration 540, Loss: 0.018547287210822105\n",
      "Epoch 33, Iteration 550, Loss: 0.04660532996058464\n",
      "Epoch 33, Iteration 560, Loss: 0.03699025884270668\n",
      "Epoch 33, Iteration 570, Loss: 0.027986956760287285\n",
      "Epoch 33, Iteration 580, Loss: 0.037308599799871445\n",
      "Epoch 33, Iteration 590, Loss: 0.031337182968854904\n",
      "Epoch 33, Iteration 600, Loss: 0.041767459362745285\n",
      "Epoch 33, Iteration 610, Loss: 0.013055422343313694\n",
      "Epoch 33, Iteration 620, Loss: 0.03824590891599655\n",
      "Epoch 33, Iteration 630, Loss: 0.0334109403192997\n",
      "Epoch 33, Iteration 640, Loss: 0.04699478670954704\n",
      "Epoch 33, Iteration 650, Loss: 0.0506247915327549\n",
      "Epoch 33, Iteration 660, Loss: 0.03707023710012436\n",
      "Epoch 33, Iteration 670, Loss: 0.0467577688395977\n",
      "Epoch 33, Iteration 680, Loss: 0.05159924924373627\n",
      "Epoch 33, Iteration 690, Loss: 0.028858497738838196\n",
      "Epoch 33, Iteration 700, Loss: 0.05110364407300949\n",
      "Epoch 33, Iteration 710, Loss: 0.04108351841568947\n",
      "Epoch 33, Iteration 720, Loss: 0.012767206877470016\n",
      "Epoch 33, Iteration 730, Loss: 0.03219269588589668\n",
      "Epoch 33, Validation Loss: 0.04124680464155972\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch 34, Iteration 0, Loss: 0.027674224227666855\n",
      "Epoch 34, Iteration 10, Loss: 0.06904886662960052\n",
      "Epoch 34, Iteration 20, Loss: 0.043608393520116806\n",
      "Epoch 34, Iteration 30, Loss: 0.047300733625888824\n",
      "Epoch 34, Iteration 40, Loss: 0.06447653472423553\n",
      "Epoch 34, Iteration 50, Loss: 0.04627154394984245\n",
      "Epoch 34, Iteration 60, Loss: 0.06279382854700089\n",
      "Epoch 34, Iteration 70, Loss: 0.024352043867111206\n",
      "Epoch 34, Iteration 80, Loss: 0.0374441035091877\n",
      "Epoch 34, Iteration 90, Loss: 0.03963388130068779\n",
      "Epoch 34, Iteration 100, Loss: 0.03630766645073891\n",
      "Epoch 34, Iteration 110, Loss: 0.02534565143287182\n",
      "Epoch 34, Iteration 120, Loss: 0.024794448167085648\n",
      "Epoch 34, Iteration 130, Loss: 0.0696573257446289\n",
      "Epoch 34, Iteration 140, Loss: 0.04459662735462189\n",
      "Epoch 34, Iteration 150, Loss: 0.029884085059165955\n",
      "Epoch 34, Iteration 160, Loss: 0.02211863175034523\n",
      "Epoch 34, Iteration 170, Loss: 0.06866801530122757\n",
      "Epoch 34, Iteration 180, Loss: 0.0904640480875969\n",
      "Epoch 34, Iteration 190, Loss: 0.04539412260055542\n",
      "Epoch 34, Iteration 200, Loss: 0.024235013872385025\n",
      "Epoch 34, Iteration 210, Loss: 0.038421567529439926\n",
      "Epoch 34, Iteration 220, Loss: 0.04217308759689331\n",
      "Epoch 34, Iteration 230, Loss: 0.030383968725800514\n",
      "Epoch 34, Iteration 240, Loss: 0.025091232731938362\n",
      "Epoch 34, Iteration 250, Loss: 0.02637668326497078\n",
      "Epoch 34, Iteration 260, Loss: 0.01991354487836361\n",
      "Epoch 34, Iteration 270, Loss: 0.028133241459727287\n",
      "Epoch 34, Iteration 280, Loss: 0.044066619127988815\n",
      "Epoch 34, Iteration 290, Loss: 0.0642196536064148\n",
      "Epoch 34, Iteration 300, Loss: 0.014663792215287685\n",
      "Epoch 34, Iteration 310, Loss: 0.06325781345367432\n",
      "Epoch 34, Iteration 320, Loss: 0.04786110669374466\n",
      "Epoch 34, Iteration 330, Loss: 0.025781020522117615\n",
      "Epoch 34, Iteration 340, Loss: 0.04117364436388016\n",
      "Epoch 34, Iteration 350, Loss: 0.04162026196718216\n",
      "Epoch 34, Iteration 360, Loss: 0.03388852998614311\n",
      "Epoch 34, Iteration 370, Loss: 0.046124253422021866\n",
      "Epoch 34, Iteration 380, Loss: 0.028776127845048904\n",
      "Epoch 34, Iteration 390, Loss: 0.026313982903957367\n",
      "Epoch 34, Iteration 400, Loss: 0.041611410677433014\n",
      "Epoch 34, Iteration 410, Loss: 0.038125861436128616\n",
      "Epoch 34, Iteration 420, Loss: 0.02431492879986763\n",
      "Epoch 34, Iteration 430, Loss: 0.017593756318092346\n",
      "Epoch 34, Iteration 440, Loss: 0.027298811823129654\n",
      "Epoch 34, Iteration 450, Loss: 0.03121214173734188\n",
      "Epoch 34, Iteration 460, Loss: 0.03325382620096207\n",
      "Epoch 34, Iteration 470, Loss: 0.04427690804004669\n",
      "Epoch 34, Iteration 480, Loss: 0.053826432675123215\n",
      "Epoch 34, Iteration 490, Loss: 0.1008119285106659\n",
      "Epoch 34, Iteration 500, Loss: 0.03233158960938454\n",
      "Epoch 34, Iteration 510, Loss: 0.03230154886841774\n",
      "Epoch 34, Iteration 520, Loss: 0.035096146166324615\n",
      "Epoch 34, Iteration 530, Loss: 0.04228571802377701\n",
      "Epoch 34, Iteration 540, Loss: 0.031012939289212227\n",
      "Epoch 34, Iteration 550, Loss: 0.06889766454696655\n",
      "Epoch 34, Iteration 560, Loss: 0.04697694629430771\n",
      "Epoch 34, Iteration 570, Loss: 0.07942458242177963\n",
      "Epoch 34, Iteration 580, Loss: 0.041799504309892654\n",
      "Epoch 34, Iteration 590, Loss: 0.03685661777853966\n",
      "Epoch 34, Iteration 600, Loss: 0.040204212069511414\n",
      "Epoch 34, Iteration 610, Loss: 0.028808264061808586\n",
      "Epoch 34, Iteration 620, Loss: 0.027979783713817596\n",
      "Epoch 34, Iteration 630, Loss: 0.017777318134903908\n",
      "Epoch 34, Iteration 640, Loss: 0.023671183735132217\n",
      "Epoch 34, Iteration 650, Loss: 0.025139261037111282\n",
      "Epoch 34, Iteration 660, Loss: 0.06059372425079346\n",
      "Epoch 34, Iteration 670, Loss: 0.026277432218194008\n",
      "Epoch 34, Iteration 680, Loss: 0.026396160945296288\n",
      "Epoch 34, Iteration 690, Loss: 0.04222891852259636\n",
      "Epoch 34, Iteration 700, Loss: 0.04740091785788536\n",
      "Epoch 34, Iteration 710, Loss: 0.041410528123378754\n",
      "Epoch 34, Iteration 720, Loss: 0.038960907608270645\n",
      "Epoch 34, Iteration 730, Loss: 0.04324021935462952\n",
      "Epoch 34, Validation Loss: 0.04124683793634176\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Epoch 35, Iteration 0, Loss: 0.04711543023586273\n",
      "Epoch 35, Iteration 10, Loss: 0.039780303835868835\n",
      "Epoch 35, Iteration 20, Loss: 0.03316059336066246\n",
      "Epoch 35, Iteration 30, Loss: 0.019598478451371193\n",
      "Epoch 35, Iteration 40, Loss: 0.04230291768908501\n",
      "Epoch 35, Iteration 50, Loss: 0.04365001246333122\n",
      "Epoch 35, Iteration 60, Loss: 0.03098456561565399\n",
      "Epoch 35, Iteration 70, Loss: 0.03814898803830147\n",
      "Epoch 35, Iteration 80, Loss: 0.0337551049888134\n",
      "Epoch 35, Iteration 90, Loss: 0.022618643939495087\n",
      "Epoch 35, Iteration 100, Loss: 0.041745830327272415\n",
      "Epoch 35, Iteration 110, Loss: 0.022272605448961258\n",
      "Epoch 35, Iteration 120, Loss: 0.03820604085922241\n",
      "Epoch 35, Iteration 130, Loss: 0.05127871036529541\n",
      "Epoch 35, Iteration 140, Loss: 0.06759130954742432\n",
      "Epoch 35, Iteration 150, Loss: 0.030611449852585793\n",
      "Epoch 35, Iteration 160, Loss: 0.03539653122425079\n",
      "Epoch 35, Iteration 170, Loss: 0.03183523938059807\n",
      "Epoch 35, Iteration 180, Loss: 0.08785862475633621\n",
      "Epoch 35, Iteration 190, Loss: 0.05191940814256668\n",
      "Epoch 35, Iteration 200, Loss: 0.04982129856944084\n",
      "Epoch 35, Iteration 210, Loss: 0.025318002328276634\n",
      "Epoch 35, Iteration 220, Loss: 0.08703890442848206\n",
      "Epoch 35, Iteration 230, Loss: 0.08391744643449783\n",
      "Epoch 35, Iteration 240, Loss: 0.035157762467861176\n",
      "Epoch 35, Iteration 250, Loss: 0.050028346478939056\n",
      "Epoch 35, Iteration 260, Loss: 0.02799559198319912\n",
      "Epoch 35, Iteration 270, Loss: 0.04611855372786522\n",
      "Epoch 35, Iteration 280, Loss: 0.030434144660830498\n",
      "Epoch 35, Iteration 290, Loss: 0.021614257246255875\n",
      "Epoch 35, Iteration 300, Loss: 0.017919359728693962\n",
      "Epoch 35, Iteration 310, Loss: 0.058217599987983704\n",
      "Epoch 35, Iteration 320, Loss: 0.03473377600312233\n",
      "Epoch 35, Iteration 330, Loss: 0.02457604371011257\n",
      "Epoch 35, Iteration 340, Loss: 0.038475532084703445\n",
      "Epoch 35, Iteration 350, Loss: 0.06173628568649292\n",
      "Epoch 35, Iteration 360, Loss: 0.04383257403969765\n",
      "Epoch 35, Iteration 370, Loss: 0.04851515591144562\n",
      "Epoch 35, Iteration 380, Loss: 0.03726299852132797\n",
      "Epoch 35, Iteration 390, Loss: 0.031234312802553177\n",
      "Epoch 35, Iteration 400, Loss: 0.04405427351593971\n",
      "Epoch 35, Iteration 410, Loss: 0.03245970234274864\n",
      "Epoch 35, Iteration 420, Loss: 0.052879441529512405\n",
      "Epoch 35, Iteration 430, Loss: 0.0356193482875824\n",
      "Epoch 35, Iteration 440, Loss: 0.04458262398838997\n",
      "Epoch 35, Iteration 450, Loss: 0.04202065244317055\n",
      "Epoch 35, Iteration 460, Loss: 0.04698023945093155\n",
      "Epoch 35, Iteration 470, Loss: 0.03314490243792534\n",
      "Epoch 35, Iteration 480, Loss: 0.08670078963041306\n",
      "Epoch 35, Iteration 490, Loss: 0.03782697394490242\n",
      "Epoch 35, Iteration 500, Loss: 0.027165627107024193\n",
      "Epoch 35, Iteration 510, Loss: 0.037660785019397736\n",
      "Epoch 35, Iteration 520, Loss: 0.015890270471572876\n",
      "Epoch 35, Iteration 530, Loss: 0.0450298897922039\n",
      "Epoch 35, Iteration 540, Loss: 0.04396509379148483\n",
      "Epoch 35, Iteration 550, Loss: 0.05293520539999008\n",
      "Epoch 35, Iteration 560, Loss: 0.055171385407447815\n",
      "Epoch 35, Iteration 570, Loss: 0.017158079892396927\n",
      "Epoch 35, Iteration 580, Loss: 0.03542278707027435\n",
      "Epoch 35, Iteration 590, Loss: 0.05087684467434883\n",
      "Epoch 35, Iteration 600, Loss: 0.03379723057150841\n",
      "Epoch 35, Iteration 610, Loss: 0.05126006901264191\n",
      "Epoch 35, Iteration 620, Loss: 0.022228341549634933\n",
      "Epoch 35, Iteration 630, Loss: 0.10034991800785065\n",
      "Epoch 35, Iteration 640, Loss: 0.030152294784784317\n",
      "Epoch 35, Iteration 650, Loss: 0.028614753857254982\n",
      "Epoch 35, Iteration 660, Loss: 0.06142553687095642\n",
      "Epoch 35, Iteration 670, Loss: 0.0641193613409996\n",
      "Epoch 35, Iteration 680, Loss: 0.04894835129380226\n",
      "Epoch 35, Iteration 690, Loss: 0.05563558265566826\n",
      "Epoch 35, Iteration 700, Loss: 0.03976128622889519\n",
      "Epoch 35, Iteration 710, Loss: 0.02865339070558548\n",
      "Epoch 35, Iteration 720, Loss: 0.029335591942071915\n",
      "Epoch 35, Iteration 730, Loss: 0.046757422387599945\n",
      "Epoch 35, Validation Loss: 0.04124638499975528\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from audio_process import *\n",
    "\n",
    "samplerate = 16000\n",
    "\n",
    "# load data\n",
    "SRP_audio_path = r'F:\\audio\\SRP_segmented\\Voice'\n",
    "SRP_egg_path = r'F:\\audio\\SRP_segmented\\EGG'\n",
    "VRP_audio_path = r'F:\\audio\\VRP_segmented\\Voice'\n",
    "VRP_egg_path = r'F:\\audio\\VRP_segmented\\EGG'\n",
    "audio_list = os.listdir(audio_path)\n",
    "egg_list = os.listdir(egg_path)\n",
    "\n",
    "class AudioEGGDataset(Dataset):\n",
    "    def __init__(self, audio_path, egg_path, transform=None):\n",
    "        self.audio_path = audio_path\n",
    "        self.egg_path = egg_path\n",
    "        self.audio_list = os.listdir(audio_path)\n",
    "        self.egg_list = os.listdir(egg_path)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            audio_file = os.path.join(self.audio_path, self.audio_list[idx])\n",
    "            egg_file = os.path.join(self.egg_path, self.egg_list[idx])\n",
    "\n",
    "            # Load audio and EGG data\n",
    "            audio, sr = librosa.load(audio_file, sr=samplerate)  # None for native sampling rate, or replace with specific rate\n",
    "            egg, _ = librosa.load(egg_file, sr=samplerate)      # Assume same sample rate as audio\n",
    "\n",
    "            # Find the maximum length in the dataset or a predetermined max length\n",
    "            max_length = samplerate * 10  # This could also be dynamically calculated or set based on your data\n",
    "            # Pad or truncate to the maximum length\n",
    "            audio = librosa.util.fix_length(audio, size=max_length)\n",
    "            egg = librosa.util.fix_length(egg, size=max_length)\n",
    "\n",
    "            # pre-processing\n",
    "            audio = voice_preprocessing(audio)\n",
    "            egg = egg_preprocessing(egg)\n",
    "\n",
    "            # Apply transformations if available\n",
    "            if self.transform:\n",
    "                audio = self.transform(audio)\n",
    "                egg = self.transform(egg)\n",
    "\n",
    "            # divide by max value to normalize\n",
    "            audio = audio / np.max(np.abs(audio))\n",
    "            egg = egg / np.max(np.abs(egg))\n",
    "\n",
    "            # Convert to PyTorch tensors and add channel dimension\n",
    "            audio = torch.from_numpy(audio).float().unsqueeze(0)  # Add channel dimension\n",
    "            egg = torch.from_numpy(egg).float().unsqueeze(0)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {audio_file} and {egg_file}: {e}\")\n",
    "            return None\n",
    "\n",
    "        return audio, egg\n",
    "\n",
    "dataset = AudioEGGDataset(audio_path, egg_path)\n",
    "# Create train and validation and test sets\n",
    "batch_size = 2  # Adjust as necessary\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, input_channels, dilation_channels):\n",
    "        super(WaveNet, self).__init__()\n",
    "        self.dilation_channels = dilation_channels\n",
    "        self.receptive_field_size = 1\n",
    "        self.dilated_convs = nn.ModuleList()\n",
    "\n",
    "        dilations = [2**i for i in range(6)]\n",
    "        self.dilated_convs.append(nn.Conv1d(input_channels, 2 * dilation_channels, kernel_size=3, padding=dilations[0]))\n",
    "        for dilation in dilations[1:]:\n",
    "            padding = dilation * (3 - 1) // 2\n",
    "            self.dilated_convs.append(nn.Conv1d(dilation_channels, 2 * dilation_channels, kernel_size=3, padding=padding, dilation=dilation))\n",
    "            self.receptive_field_size += dilation * 2\n",
    "\n",
    "        self.output_conv = nn.Conv1d(dilation_channels, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv in self.dilated_convs:\n",
    "            out = conv(x)\n",
    "            # Splitting the output of the convolution into filter and gate parts\n",
    "            filter, gate = torch.split(out, self.dilation_channels, dim=1)  # Correct dimension for splitting is 1 (channels)\n",
    "            x = torch.tanh(filter) * torch.sigmoid(gate)\n",
    "\n",
    "        return self.output_conv(x)\n",
    "\n",
    "# Instantiate the model\n",
    "channels = 32  # You may need to tune this based on your dataset\n",
    "model = WaveNet(input_channels=1, dilation_channels=channels)\n",
    "\n",
    "\n",
    "# cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Early Stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "\n",
    "for epoch in range(100):  # Adjust the number of epochs based on your needs\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader):\n",
    "        audio, egg = data\n",
    "        audio = audio.to(device)\n",
    "        egg = egg.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(audio)\n",
    "        loss = criterion(output, egg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 10 == 0:  # Log every 10 batches\n",
    "            print(f'Epoch {epoch}, Iteration {i}, Loss: {loss.item()}')\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            audio, egg = data\n",
    "            audio = audio.to(device)\n",
    "            egg = egg.to(device)\n",
    "            output = model(audio)\n",
    "            loss = criterion(output, egg)\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "    val_loss = val_running_loss / len(val_dataloader)\n",
    "    print(f'Epoch {epoch}, Validation Loss: {val_loss}')\n",
    "\n",
    "    # Early stopping and saving best model based on validation loss\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "    # Save checkpoint\n",
    "    if epoch % 10 == 0:  # Save every 10 epochs in chkpt folder\n",
    "        checkpoint_path = os.path.join('chkpt', f'checkpoint_{epoch}.pt')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': running_loss / len(dataloader),\n",
    "            'val_loss': val_loss,\n",
    "        }, checkpoint_path)\n",
    "\n",
    "    # Save the best model\n",
    "    if val_loss < early_stopping.val_loss_min:\n",
    "        best_model_path = 'WaveNetbest_model.pt'\n",
    "        torch.save(model.state_dict(), best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        audio, egg = data\n",
    "        audio = audio.to(device)\n",
    "        egg = egg.to(device)\n",
    "        output = model(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'WaveNet.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "egg = egg.cpu()\n",
    "output = output.cpu()\n",
    "# Plot the first sample\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(egg[0].squeeze()[3000:5000], label='Ground Truth')\n",
    "plt.plot(output[0].squeeze()[3000:5000], label='Prediction')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "# save the first predicted EGG as wav\n",
    "output_wav = output[0]\n",
    "# save wav in the current folder using soundfile\n",
    "\n",
    "sf.write('output.wav', output_wav.squeeze().numpy(), samplerate)\n",
    "\n",
    "# save the first ground truth EGG as wav\n",
    "egg_wav = egg[0]\n",
    "sf.write('egg.wav', egg_wav.squeeze().numpy(), samplerate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
